<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="robots" content="index, archive" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="description" content="Master machine learning with Scikit-learn. Learn classification, regression, clustering, pipelines, and model evaluation. Part 4 of Python Data Science Series." />
    <meta name="author" content="Wasil Zafar" />
    <meta name="keywords" content="Scikit-learn, Machine Learning, Python, Classification, Regression, Clustering, Model Evaluation, Pipelines, Data Science" />
    <meta property="og:title" content="Python Data Science Series Part 4: Machine Learning with Scikit-learn" />
    <meta property="og:description" content="Master machine learning with Scikit-learn. Build classification, regression, and clustering models with a consistent API." />
    <meta property="og:type" content="article" />
    <meta property="article:published_time" content="2025-12-27" />
    <meta property="article:author" content="Wasil Zafar" />
    <meta property="article:section" content="Technology" />
    
    <title>Python Data Science Series Part 4: Machine Learning with Scikit-learn - Wasil Zafar</title>

    <!-- Bootstrap 5 CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    
    <!-- Font Awesome Icons -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet" />

    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=DM+Sans:wght@400;500;600;700&family=Poppins:wght@300;400;500;600;700&family=Playfair+Display:wght@600;700&display=swap" rel="stylesheet" />

    <!-- Custom Styles -->
    <link rel="stylesheet" href="../../../css/main.css" type="text/css" />

    <!-- Prism.js Syntax Highlighting -->
    <!-- Multiple themes for dynamic switching -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" id="prism-theme" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" id="prism-default" disabled />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-dark.min.css" id="prism-dark" disabled />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-twilight.min.css" id="prism-twilight" disabled />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-okaidia.min.css" id="prism-okaidia" disabled />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-solarizedlight.min.css" id="prism-solarizedlight" disabled />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/toolbar/prism-toolbar.min.css" />

    <!-- Favicon -->
    <link rel="apple-touch-icon" sizes="180x180" href="../../../images/favicon_io/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../../../images/favicon_io/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../../../images/favicon_io/favicon-16x16.png">
    <link rel="manifest" href="../../../images/favicon_io/site.webmanifest">

    <!-- Google Consent Mode v2 -->
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        
        gtag('consent', 'default', {
            'ad_storage': 'denied',
            'ad_user_data': 'denied',
            'ad_personalization': 'denied',
            'analytics_storage': 'denied',
            'region': ['AT','BE','BG','HR','CY','CZ','DK','EE','FI','FR','DE','GR','HU','IE','IT','LV','LT','LU','MT','NL','PL','PT','RO','SK','SI','ES','SE']
        });
        
        gtag('consent', 'default', {
            'ad_storage': 'granted',
            'ad_user_data': 'granted',
            'ad_personalization': 'granted',
            'analytics_storage': 'granted'
        });
        
        gtag('set', 'url_passthrough', true);
    </script>

    <!-- Google Tag Manager -->
    <script>
        (function(w, d, s, l, i) {
            w[l] = w[l] || [];
            w[l].push({
                'gtm.start': new Date().getTime(),
                event: 'gtm.js'
            });
            var f = d.getElementsByTagName(s)[0],
                j = d.createElement(s),
                dl = l != 'dataLayer' ? '&l=' + l : '';
            j.async = true;
            j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
            f.parentNode.insertBefore(j, f);
        })(window, document, 'script', 'dataLayer', 'GTM-PBS8M2JR');
    </script>

    <style>
        /* Blog Post Specific Styles */
        .blog-hero {
            background: linear-gradient(135deg, var(--color-navy) 0%, var(--color-blue) 100%);
            color: white;
            padding: 80px 0;
        }

        .blog-header {
            margin-bottom: 2rem;
        }

        .blog-meta {
            font-size: 0.95rem;
            color: var(--color-teal);
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
            flex-wrap: wrap;
            gap: 1rem;
        }

        .blog-meta span {
            margin-right: 0.5rem;
        }

        .print-btn {
            background: var(--color-teal);
            color: white;
            border: none;
            padding: 0.4rem 1rem;
            border-radius: 4px;
            font-size: 0.9rem;
            cursor: pointer;
            transition: all 0.3s ease;
            display: inline-flex;
            align-items: center;
            gap: 0.5rem;
        }

        .print-btn:hover {
            background: var(--color-crimson);
            transform: translateY(-1px);
        }

        @media print {
            /* Hide print button and navigation */
            .print-btn,
            nav,
            .navbar,
            footer,
            .back-link,
            .related-posts,
            .scroll-to-top,
            .toc-toggle-btn,
            .sidenav-toc,
            .sidenav-overlay { 
                display: none !important; 
            }
            
            /* Force color printing */
            * {
                -webkit-print-color-adjust: exact !important;
                print-color-adjust: exact !important;
                color-adjust: exact !important;
            }
            
            /* Preserve header colors */
            .blog-content h2 {
                color: var(--color-navy) !important;
                border-bottom: 3px solid var(--color-teal) !important;
                page-break-after: avoid;
            }
            
            .blog-content h3 {
                color: var(--color-blue) !important;
                page-break-after: avoid;
            }
            
            .blog-content h4 {
                color: var(--color-crimson) !important;
                page-break-after: avoid;
            }
            
            /* Preserve strong text color */
            .blog-content strong {
                color: var(--color-crimson) !important;
            }
            
            /* Preserve highlight boxes */
            .highlight-box {
                background: rgba(59, 151, 151, 0.1) !important;
                border-left: 4px solid var(--color-teal) !important;
                page-break-inside: avoid;
            }
            
            /* Preserve experiment cards */
            .experiment-card {
                border: 1px solid #ddd !important;
                page-break-inside: avoid;
            }
            
            .experiment-card h4 {
                color: var(--color-crimson) !important;
            }
            
            /* Preserve badges */
            .badge {
                -webkit-print-color-adjust: exact !important;
                print-color-adjust: exact !important;
            }
            
            .bg-teal {
                background-color: var(--color-teal) !important;
                color: white !important;
            }
            
            .bg-crimson {
                background-color: var(--color-crimson) !important;
                color: white !important;
            }
            
            /* Preserve TOC box */
            .toc-box {
                border: 2px solid var(--color-teal) !important;
                page-break-inside: avoid;
            }
            
            .toc-box h3 {
                color: var(--color-navy) !important;
            }
            
            .toc-box a {
                color: var(--color-blue) !important;
            }
            
            /* Code blocks */
            pre[class*="language-"] {
                page-break-inside: avoid;
                border: 1px solid #ddd !important;
            }
            
            /* Reading time badge */
            .reading-time {
                background: var(--color-crimson) !important;
                color: white !important;
            }
            
            /* Page breaks */
            .blog-content h2 {
                page-break-before: auto;
            }
            
            /* Ensure good spacing */
            body {
                font-size: 12pt;
                line-height: 1.6;
            }
        }

        .blog-content {
            max-width: 900px;
            margin: 0 auto;
            font-size: 1.05rem;
            line-height: 1.8;
            color: #333;
        }

        .blog-content h2 {
            font-size: 1.8rem;
            font-weight: 700;
            margin-top: 2.5rem;
            margin-bottom: 1.5rem;
            color: var(--color-navy);
            border-bottom: 3px solid var(--color-teal);
            padding-bottom: 0.5rem;
        }

        .blog-content h3 {
            font-size: 1.3rem;
            font-weight: 600;
            margin-top: 2rem;
            margin-bottom: 1rem;
            color: var(--color-blue);
        }

        .blog-content p {
            margin-bottom: 1.2rem;
            text-align: justify;
        }

        .blog-content strong {
            color: var(--color-crimson);
        }

        .highlight-box {
            background: rgba(59, 151, 151, 0.1);
            border-left: 4px solid var(--color-teal);
            padding: 1.5rem;
            margin: 2rem 0;
            border-radius: 4px;
        }

        .experiment-card {
            background: #f8f9fa;
            border: 1px solid #ddd;
            border-radius: 8px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
            transition: all 0.3s ease;
        }

        .experiment-card:hover {
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
            transform: translateY(-2px);
        }

        .experiment-card h4 {
            color: var(--color-crimson);
            font-weight: 700;
            margin-bottom: 0.5rem;
        }

        .experiment-card .card-meta {
            font-size: 0.9rem;
            color: var(--color-blue);
            margin-bottom: 1rem;
            font-style: italic;
        }

        .card-meta .badge {
            font-size: 0.85rem;
            font-weight: 600;
            padding: 0.5rem 1rem;
            margin-right: 0.5rem;
            letter-spacing: 0.3px;
        }

        .bg-teal {
            background-color: var(--color-teal) !important;
        }

        .bg-crimson {
            background-color: var(--color-crimson) !important;
        }

        /* Side Navigation Table of Contents (Modern Overlay Style) */
        /* Toggle Button */
        .toc-toggle-btn {
            position: fixed;
            bottom: 2rem;
            left: 2rem;
            width: 50px;
            height: 50px;
            background: var(--color-teal);
            color: white;
            border: none;
            border-radius: 50%;
            font-size: 1.2rem;
            cursor: pointer;
            box-shadow: 0 4px 12px rgba(59, 151, 151, 0.4);
            transition: all 0.3s ease;
            z-index: 1049;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .toc-toggle-btn:hover {
            background: var(--color-crimson);
            transform: scale(1.1);
            box-shadow: 0 6px 16px rgba(191, 9, 47, 0.5);
        }

        .toc-toggle-btn:active {
            transform: scale(0.95);
        }

        /* Side Navigation Overlay */
        .sidenav-toc {
            height: calc(100% - 64px);
            width: 0;
            position: fixed;
            z-index: 1050;
            top: 64px;
            left: 0;
            background: linear-gradient(135deg, var(--color-navy) 0%, var(--color-blue) 100%);
            overflow-x: hidden;
            overflow-y: auto;
            transition: width 0.4s ease;
            padding-top: 30px;
            box-shadow: 4px 0 15px rgba(0, 0, 0, 0.3);
        }

        .sidenav-toc.open {
            width: 350px;
        }

        /* Header row with close button and title */
        .sidenav-toc .toc-header {
            display: flex;
            align-items: center;
            justify-content: space-between;
            padding: 20px 30px;
            margin-bottom: 20px;
            border-bottom: 2px solid var(--color-teal);
            opacity: 0;
            visibility: hidden;
            transition: all 0.3s ease;
        }

        .sidenav-toc.open .toc-header {
            opacity: 1;
            visibility: visible;
        }

        .sidenav-toc .closebtn {
            font-size: 32px;
            color: white;
            background: transparent;
            border: none;
            cursor: pointer;
            transition: all 0.3s ease;
            line-height: 1;
            padding: 0;
            margin: 0;
        }

        .sidenav-toc .closebtn:hover {
            color: var(--color-crimson);
            transform: rotate(90deg);
        }

        .sidenav-toc h3 {
            color: white;
            margin: 0;
            padding: 0;
            font-weight: 700;
            font-size: 1.3rem;
            flex-grow: 1;
        }

        .sidenav-toc ol {
            list-style: decimal;
            padding: 0;
            padding-left: 30px;
            margin: 0;
            color: rgba(255, 255, 255, 0.9);
        }

        .sidenav-toc ol li {
            margin: 0;
            margin-bottom: 8px;
        }

        .sidenav-toc ul {
            list-style-type: lower-alpha;
            padding-left: 30px;
            margin-top: 8px;
            margin-bottom: 8px;
        }

        .sidenav-toc ul li {
            margin-bottom: 6px;
        }

        .sidenav-toc a {
            padding: 12px 30px;
            text-decoration: none;
            font-size: 0.95rem;
            color: rgba(255, 255, 255, 0.85);
            display: block;
            transition: all 0.3s ease;
            border-left: 4px solid transparent;
            position: relative;
        }

        .sidenav-toc a:hover {
            color: white;
            background: rgba(59, 151, 151, 0.2);
            border-left-color: var(--color-teal);
            padding-left: 35px;
        }

        .sidenav-toc a.active {
            color: white;
            background: rgba(191, 9, 47, 0.3);
            border-left-color: var(--color-crimson);
            font-weight: 600;
        }

        .sidenav-toc a.active::before {
            content: '▶';
            position: absolute;
            left: 15px;
            font-size: 0.7rem;
            color: var(--color-crimson);
        }

        /* Overlay backdrop */
        .sidenav-overlay {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.5);
            z-index: 1049;
            transition: opacity 0.4s ease;
        }

        .sidenav-overlay.show {
            display: block;
        }

        /* Responsive adjustments */
        @media (max-width: 768px) {
            .sidenav-toc.open {
                width: 280px;
            }
            
            .toc-toggle-btn {
                width: 50px;
                height: 50px;
                font-size: 1.2rem;
                left: 15px;
            }
        }

        /* Smooth scroll behavior */
        html {
            scroll-behavior: smooth;
        }

        .reading-time {
            display: inline-block;
            background: var(--color-crimson);
            color: white;
            padding: 0.3rem 0.8rem;
            border-radius: 4px;
            font-size: 0.9rem;
        }

        .back-link {
            display: inline-block;
            color: white;
            text-decoration: none;
            transition: all 0.3s ease;
            margin-bottom: 1rem;
            opacity: 0.9;
        }

        .back-link:hover {
            color: var(--color-teal);
            opacity: 1;
            transform: translateX(-5px);
        }

        .related-posts {
            background: #f8f9fa;
            border-radius: 8px;
            padding: 2rem;
            margin-top: 3rem;
        }

        .related-posts h3 {
            color: var(--color-navy);
            margin-bottom: 1.5rem;
        }

        .related-post-item {
            padding: 1rem;
            border-left: 3px solid var(--color-teal);
            margin-bottom: 1rem;
            transition: all 0.3s ease;
        }

        .related-post-item:hover {
            background: white;
            border-left-color: var(--color-crimson);
        }

        .related-post-item a {
            color: var(--color-blue);
            text-decoration: none;
            font-weight: 600;
        }

        .related-post-item a:hover {
            color: var(--color-crimson);
        }

        /* Code Block Styles */
        pre[class*="language-"] {
            position: relative;
            margin: 1.5rem 0;
            padding-top: 3rem;
            border-radius: 8px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
        }

        code[class*="language-"] {
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
        }

        /* Toolbar styling */
        div.code-toolbar > .toolbar {
            opacity: 1;
            display: flex;
            gap: 0.5rem;
        }

        div.code-toolbar > .toolbar > .toolbar-item > button {
            background: var(--color-teal);
            color: white;
            border: none;
            padding: 0.4rem 0.8rem;
            border-radius: 4px;
            font-size: 0.85rem;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        div.code-toolbar > .toolbar > .toolbar-item > button:hover {
            background: var(--color-blue);
            transform: translateY(-1px);
        }

        div.code-toolbar > .toolbar > .toolbar-item > button:focus {
            outline: 2px solid var(--color-teal);
            outline-offset: 2px;
        }

        /* Theme switcher dropdown */
        div.code-toolbar > .toolbar > .toolbar-item > select {
            background: var(--color-navy);
            color: white;
            border: 1px solid var(--color-teal);
            padding: 0.4rem 0.8rem;
            border-radius: 4px;
            font-size: 0.85rem;
            cursor: pointer;
            transition: all 0.3s ease;
            outline: none;
        }

        div.code-toolbar > .toolbar > .toolbar-item > select:hover {
            background: var(--color-blue);
            border-color: var(--color-crimson);
        }

        div.code-toolbar > .toolbar > .toolbar-item > select:focus {
            outline: 2px solid var(--color-teal);
            outline-offset: 2px;
        }

        /* Style select options */
        div.code-toolbar > .toolbar > .toolbar-item > select option {
            background: var(--color-navy);
            color: white;
        }

        /* Scroll-to-Top Button */
        .scroll-to-top {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            width: 50px;
            height: 50px;
            background: var(--color-teal);
            color: white;
            border: none;
            border-radius: 50%;
            font-size: 1.2rem;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            opacity: 0;
            visibility: hidden;
            transition: all 0.3s ease;
            box-shadow: 0 4px 12px rgba(59, 151, 151, 0.3);
            z-index: 999;
        }

        .scroll-to-top.show {
            opacity: 1;
            visibility: visible;
        }

        .scroll-to-top:hover {
            background: var(--color-crimson);
            transform: translateY(-3px);
            box-shadow: 0 6px 16px rgba(191, 9, 47, 0.4);
        }

        .scroll-to-top:active {
            transform: translateY(-1px);
        }

        @media (max-width: 768px) {
            .scroll-to-top {
                bottom: 1rem;
                right: 1rem;
                width: 45px;
                height: 45px;
                font-size: 1rem;
            }
        }
    </style>
</head>
<body>
    <!-- Google Tag Manager (noscript) -->
    <noscript>
        <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-PBS8M2JR" height="0" width="0" style="display:none;visibility:hidden"></iframe>
    </noscript>

    <!-- GDPR Cookie Consent Banner -->
    <div id="cookieBanner" class="light display-bottom" style="display: none;">
        <div id="closeIcon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512">
                <path fill="currentColor" d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm121.6 313.1c4.7 4.7 4.7 12.3 0 17L338 377.6c-4.7 4.7-12.3 4.7-17 0L256 312l-65.1 65.6c-4.7 4.7-12.3 4.7-17 0L134.4 338c-4.7-4.7-4.7-12.3 0-17l65.6-65-65.6-65.1c-4.7-4.7-4.7-12.3 0-17l39.6-39.6c4.7-4.7 12.3-4.7 17 0l65 65.7 65.1-65.6c4.7-4.7 12.3-4.7 17 0l39.6 39.6c4.7 4.7 4.7 12.3 0 17L312 256l65.6 65.1z"></path>
            </svg>
        </div>
        
        <div class="content-wrap">
            <div class="msg-wrap">
                <div class="title-wrap">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" width="20" height="20">
                        <path fill="#3B9797" d="M510.52 255.82c-69.97-.85-126.47-57.69-126.47-127.86-70.17 0-127-56.49-127.86-126.45-27.26-4.14-55.13.3-79.72 12.82l-69.13 35.22a132.221 132.221 0 0 0-57.79 57.81l-35.1 68.88a132.645 132.645 0 0 0-12.82 80.95l12.08 76.27a132.521 132.521 0 0 0 37.16 70.37l54.64 54.64a132.036 132.036 0 0 0 70.37 37.16l76.27 12.15c27.51 4.36 55.7-.11 80.95-12.8l68.88-35.08a132.166 132.166 0 0 0 57.79-57.81l35.1-68.88c12.56-24.64 17.01-52.58 12.91-79.91zM176 368c-17.67 0-32-14.33-32-32s14.33-32 32-32 32 14.33 32 32-14.33 32-32 32zm32-160c-17.67 0-32-14.33-32-32s14.33-32 32-32 32 14.33 32 32-14.33 32-32 32zm160 128c-17.67 0-32-14.33-32-32s14.33-32 32-32 32 14.33 32 32-14.33 32-32 32z"></path>
                    </svg>
                    <h4 style="margin: 0; font-size: 18px; color: var(--color-navy); font-weight: 700;">Cookie Consent</h4>
                </div>
                <p style="font-size: 14px; line-height: 1.6; color: var(--color-navy); margin-bottom: 15px;">
                    We use cookies to enhance your browsing experience, serve personalized content, and analyze our traffic. 
                    By clicking "Accept All", you consent to our use of cookies. See our 
                    <a href="/privacy-policy.html" style="color: var(--color-teal); border-bottom: 1px dotted var(--color-teal);">Privacy Policy</a> 
                    for more information.
                </p>
                
                <div id="cookieSettings" style="display: none;">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" width="14" height="14">
                        <path fill="currentColor" d="M487.4 315.7l-42.6-24.6c4.3-23.2 4.3-47 0-70.2l42.6-24.6c4.9-2.8 7.1-8.6 5.5-14-11.1-35.6-30-67.8-54.7-94.6-3.8-4.1-10-5.1-14.8-2.3L380.8 110c-17.9-15.4-38.5-27.3-60.8-35.1V25.8c0-5.6-3.9-10.5-9.4-11.7-36.7-8.2-74.3-7.8-109.2 0-5.5 1.2-9.4 6.1-9.4 11.7V75c-22.2 7.9-42.8 19.8-60.8 35.1L88.7 85.5c-4.9-2.8-11-1.9-14.8 2.3-24.7 26.7-43.6 58.9-54.7 94.6-1.7 5.4.6 11.2 5.5 14L67.3 221c-4.3 23.2-4.3 47 0 70.2l-42.6 24.6c-4.9 2.8-7.1 8.6-5.5 14 11.1 35.6 30 67.8 54.7 94.6 3.8 4.1 10 5.1 14.8 2.3l42.6-24.6c17.9 15.4 38.5 27.3 60.8 35.1v49.2c0 5.6 3.9 10.5 9.4 11.7 36.7 8.2 74.3 7.8 109.2 0 5.5-1.2 9.4-6.1 9.4-11.7v-49.2c22.2-7.9 42.8-19.8 60.8-35.1l42.6 24.6c4.9 2.8 11 1.9 14.8-2.3 24.7-26.7 43.6-58.9 54.7-94.6 1.5-5.5-.7-11.3-5.6-14.1zM256 336c-44.1 0-80-35.9-80-80s35.9-80 80-80 80 35.9 80 80-35.9 80-80 80z"></path>
                    </svg>
                    <span style="margin-left: 5px; font-size: 12px; font-weight: 600; color: var(--color-navy);">Customize Settings</span>
                </div>
                
                <div id="cookieTypes" style="display: none; margin-top: 15px; padding-top: 15px; border-top: 1px solid rgba(59, 151, 151, 0.2);">
                    <h5 style="font-size: 12px; font-weight: 700; color: var(--color-navy); margin-bottom: 10px; text-transform: uppercase;">Cookie Preferences</h5>
                    
                    <div style="margin-bottom: 12px;">
                        <label style="display: flex; align-items: start; cursor: pointer;">
                            <input type="checkbox" checked disabled style="margin-top: 2px; margin-right: 8px; cursor: not-allowed;">
                            <div>
                                <strong style="font-size: 13px; color: var(--color-navy); display: block; margin-bottom: 2px;">Essential Cookies (Required)</strong>
                                <span style="font-size: 12px; color: #666;">Necessary for the website to function properly.</span>
                            </div>
                        </label>
                    </div>
                    
                    <div style="margin-bottom: 12px;">
                        <label style="display: flex; align-items: start; cursor: pointer;">
                            <input type="checkbox" id="analyticsCookies" checked style="margin-top: 2px; margin-right: 8px;">
                            <div>
                                <strong style="font-size: 13px; color: var(--color-navy); display: block; margin-bottom: 2px;">Analytics Cookies</strong>
                                <span style="font-size: 12px; color: #666;">Help us understand how you interact with the website.</span>
                            </div>
                        </label>
                    </div>
                    
                    <div style="margin-bottom: 12px;">
                        <label style="display: flex; align-items: start; cursor: pointer;">
                            <input type="checkbox" id="marketingCookies" style="margin-top: 2px; margin-right: 8px;">
                            <div>
                                <strong style="font-size: 13px; color: var(--color-navy); display: block; margin-bottom: 2px;">Marketing Cookies</strong>
                                <span style="font-size: 12px; color: #666;">Used to deliver relevant advertisements.</span>
                            </div>
                        </label>
                    </div>
                </div>
            </div>
            
            <div class="btn-wrap">
                <button id="cookieAccept" style="background: var(--color-teal); color: white; font-weight: 600;">Accept All</button>
                <button id="cookieReject" style="background: transparent; color: var(--color-navy); border: 2px solid var(--color-teal); font-weight: 600;">Reject All</button>
                <button id="cookieSave" style="background: var(--color-blue); color: white; font-weight: 600; display: none;">Save Preferences</button>
            </div>
        </div>
    </div>

    <!-- Navigation Bar -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark shadow-sm">
        <div class="container-fluid">
            <a class="navbar-brand fw-bold" href="/">
                <span class="gradient-text">Wasil Zafar</span>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="/">Home</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="/#about">About</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="/#skills">Skills</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="/#certifications">Certifications</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="/#interests">Interests</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Hero Section -->
    <section class="blog-hero">
        <div class="container py-5">
            <div class="blog-header">
                <a href="/pages/categories/technology.html" class="back-link">
                    <i class="fas fa-arrow-left me-2"></i>Back to Technology
                </a>
                <h1 class="display-4 fw-bold mb-3">Python Data Science Series Part 4: Machine Learning with Scikit-learn</h1>
                <div class="blog-meta">
                    <span><i class="fas fa-calendar me-2"></i>December 27, 2025</span>
                    <span><i class="fas fa-user me-2"></i>Wasil Zafar</span>
                    <span class="reading-time"><i class="fas fa-clock me-1"></i>35 min read</span>
                    <button onclick="window.print()" class="print-btn" title="Print this article">
                        <i class="fas fa-print"></i> Print
                    </button>
                </div>
                <p class="lead">Complete your data science journey by mastering Scikit-learn—Python's premier machine learning library. Learn classification, regression, clustering, pipelines, and model evaluation with a consistent, intuitive API.</p>
            </div>
        </div>
    </section>

    <!-- Table of Contents Toggle Button -->
    <button class="toc-toggle-btn" onclick="openNav()" title="Table of Contents" aria-label="Open Table of Contents">
        <i class="fas fa-list"></i>
    </button>

    <!-- Side Navigation Overlay -->
    <div id="tocSidenav" class="sidenav-toc">
        <div class="toc-header">
            <h3><i class="fas fa-list me-2"></i>Table of Contents</h3>
            <button class="closebtn" onclick="closeNav()" aria-label="Close Table of Contents">&times;</button>
        </div>
        <ol>
            <li><a href="#introduction" onclick="closeNav()">Introduction to Scikit-learn</a></li>
            <li><a href="#terminology" onclick="closeNav()">ML Terminology Explained</a></li>
            <li><a href="#workflow" onclick="closeNav()">The ML Workflow</a></li>
            <li><a href="#datasets-intro" onclick="closeNav()">Built-in Datasets (Quick Introduction)</a></li>
            <li><a href="#dataset-loaders" onclick="closeNav()">Real-World Dataset Loaders</a></li>
            <li><a href="#sample-generators" onclick="closeNav()">Synthetic Dataset Generators</a></li>
            <li><a href="#preprocessing" onclick="closeNav()">Data Preprocessing</a></li>
            <li><a href="#classification" onclick="closeNav()">Classification Models</a></li>
            <li><a href="#regression" onclick="closeNav()">Regression Models</a></li>
            <li><a href="#clustering" onclick="closeNav()">Clustering</a></li>
            <li><a href="#evaluation" onclick="closeNav()">Model Evaluation</a></li>
            <li><a href="#pipelines" onclick="closeNav()">Pipelines & Automation</a></li>
            <li><a href="#tuning" onclick="closeNav()">Hyperparameter Tuning</a></li>
            <li><a href="#datasets" onclick="closeNav()">Complete Workflow Examples with Datasets</a>
                <ul style="list-style-type: lower-alpha; margin-top: 0.5rem;">
                    <li><a href="#iris-dataset" onclick="closeNav()">Iris Dataset (Classification)</a></li>
                    <li><a href="#wine-dataset" onclick="closeNav()">Wine Dataset (Classification)</a></li>
                    <li><a href="#digits-dataset" onclick="closeNav()">Digits Dataset (Image Classification)</a></li>
                    <li><a href="#breast-cancer-dataset" onclick="closeNav()">Breast Cancer Dataset (Binary Classification)</a></li>
                    <li><a href="#diabetes-dataset" onclick="closeNav()">Diabetes Dataset (Regression)</a></li>
                    <li><a href="#california-housing-dataset" onclick="closeNav()">California Housing Dataset (Regression)</a></li>
                </ul>
            </li>
            <li><a href="#best-practices" onclick="closeNav()">Best Practices & Summary</a></li>
        </ol>
    </div>

    <!-- Overlay Backdrop -->
    <div id="tocOverlay" class="sidenav-overlay" onclick="closeNav()"></div>

    <!-- Main Content -->
    <section class="py-5">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 mx-auto">

                    <!-- Introduction -->
                    <div id="introduction" class="blog-content">
                        <h2><i class="fas fa-robot me-2 text-teal"></i>Introduction to Scikit-learn</h2>
                        
                        <div class="highlight-box" style="background: rgba(191, 9, 47, 0.1); border-left-color: var(--color-crimson);">
                            <i class="fas fa-tools me-2"></i>
                            <strong>Prerequisites:</strong> Before running the code examples in this tutorial, make sure you have Python and Jupyter notebooks properly set up. If you haven't configured your development environment yet, check out our <a href="python-setup-notebooks-guide.html" style="color: var(--color-crimson); font-weight: 600;">complete setup guide for VS Code, PyCharm, Jupyter, and Colab</a>.
                        </div>
                        
                        <p>You've learned NumPy (arrays), Pandas (data manipulation), and visualization. Now it's time for <strong>machine learning</strong>—using data to make predictions and discover patterns.</p>

                        <div class="highlight-box">
                            <i class="fas fa-lightbulb"></i>
                            <strong>Why Scikit-learn:</strong> Scikit-learn provides a simple, consistent API for hundreds of ML algorithms. Whether you're doing classification, regression, or clustering, the workflow is always: <code>fit()</code> to train, <code>predict()</code> to infer, <code>score()</code> to evaluate.
                        </div>

                        <div class="experiment-card">
                            <h4><i class="fas fa-map-signs me-2"></i>Complete Series Navigation</h4>
                            <div class="meta mb-2">
                                <span class="badge bg-teal me-2">11-Part Series</span>
                                <span class="badge bg-crimson">Data Science Mastery</span>
                            </div>
                            <div class="content">
                                <ol>
                                    <li><a href="python-setup-notebooks-guide.html">Python Setup & Notebooks</a> - IDE setup, Jupyter, virtual environments</li>
                                    <li><a href="python-data-science-numpy-foundations.html">NumPy Foundations</a> - Arrays, broadcasting, linear algebra</li>
                                    <li><a href="python-data-science-pandas-analysis.html">Pandas Data Analysis</a> - DataFrames, cleaning, manipulation</li>
                                    <li><a href="python-data-science-visualization.html">Data Visualization</a> - Matplotlib, Seaborn, Plotly</li>
                                    <li><strong>Machine Learning with Scikit-learn (This Guide)</strong> - Classification, regression, clustering</li>
                                    <li><a href="../series/artificial-intelligence/machine-learning-mathematics-statistics-foundations.html">ML Mathematics & Statistics</a> - Linear algebra, calculus, probability</li>
                                    <li><a href="../series/artificial-intelligence/artificial-neural-networks-guide.html">Artificial Neural Networks</a> - Perceptrons, backpropagation, architectures</li>
                                    <li><a href="../series/artificial-intelligence/computer-vision-fundamentals-guide.html">Computer Vision Fundamentals</a> - CNNs, image processing, object detection</li>
                                    <li><a href="../series/artificial-intelligence/pytorch-deep-learning-guide.html">PyTorch Deep Learning</a> - Tensors, autograd, model training</li>
                                    <li><a href="../series/artificial-intelligence/tensorflow-deep-learning-guide.html">TensorFlow & Keras</a> - Sequential models, callbacks, deployment</li>
                                    <li><a href="../series/artificial-intelligence/attention-is-all-you-need-transformer-explained.html">Transformers & Attention</a> - Self-attention, BERT, GPT architecture</li>
                                </ol>
                            </div>
                        </div>

                        <h3>Key Features</h3>
                        <ul>
                            <li><strong>Consistent API:</strong> All models follow the same estimator interface</li>
                            <li><strong>Comprehensive:</strong> Classification, regression, clustering, dimensionality reduction</li>
                            <li><strong>Preprocessing tools:</strong> Scaling, encoding, feature selection</li>
                            <li><strong>Model evaluation:</strong> Cross-validation, metrics, confusion matrices</li>
                            <li><strong>Pipelines:</strong> Chain preprocessing and modeling steps</li>
                            <li><strong>Well-documented:</strong> Excellent examples and user guide</li>
                        </ul>

                        <pre><code class="language-bash"># Installation
pip install scikit-learn

# Import convention
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import pandas as pd
import numpy as np</code></pre>
                    </div>

                    <!-- ML Terminology -->
                    <div id="terminology" class="blog-content mt-5">
                        <h2><i class="fas fa-book me-2 text-teal"></i>ML Terminology Explained</h2>
                        
                        <p>Before diving into code, let's clarify the key terms you'll see throughout this tutorial. Understanding these concepts will make everything that follows much clearer.</p>

                        <div class="row mt-4">
                            <!-- Data Terms -->
                            <div class="col-md-6 mb-4">
                                <div class="experiment-card">
                                    <div class="card-meta mb-2">
                                        <span class="badge bg-navy text-dark">Data Terms</span>
                                    </div>
                                    <div class="card-content">
                                        <p><strong><code>Features (X)</code>:</strong> The input variables used to make predictions. Think of them as the "questions" you ask.</p>
                                        <ul class="small mb-3">
                                            <li>Also called: predictors, independent variables, attributes</li>
                                            <li>Example: For house prices → square footage, bedrooms, location</li>
                                            <li>Notation: Capital <code>X</code> (matrix of shape: samples × features)</li>
                                        </ul>

                                        <p><strong><code>Labels/Target (y)</code>:</strong> The output variable you want to predict. The "answer" you're looking for.</p>
                                        <ul class="small mb-3">
                                            <li>Also called: response, dependent variable, outcome</li>
                                            <li>Example: For house prices → actual price in dollars</li>
                                            <li>Notation: Lowercase <code>y</code> (array of shape: samples)</li>
                                        </ul>

                                        <p><strong><code>Samples</code>:</strong> Individual data points (rows in your dataset).</p>
                                        <ul class="small">
                                            <li>Also called: observations, instances, examples</li>
                                            <li>Example: Each house in your dataset is one sample</li>
                                        </ul>
                                    </div>
                                </div>
                            </div>

                            <!-- Train/Test Terms -->
                            <div class="col-md-6 mb-4">
                                <div class="experiment-card">
                                    <div class="card-meta mb-2">
                                        <span class="badge bg-teal text-white">Train/Test Terms</span>
                                    </div>
                                    <div class="card-content">
                                        <p><strong><code>Training Set</code>:</strong> Data used to teach the model. The model sees both features (X) and labels (y).</p>
                                        <ul class="small mb-3">
                                            <li>Typical size: 70-80% of total data</li>
                                            <li>Variables: <code>X_train</code>, <code>y_train</code></li>
                                            <li>Purpose: Learn patterns and relationships</li>
                                        </ul>

                                        <p><strong><code>Test Set</code>:</strong> Data used to evaluate the model. Model has never seen these samples during training.</p>
                                        <ul class="small mb-3">
                                            <li>Typical size: 20-30% of total data</li>
                                            <li>Variables: <code>X_test</code>, <code>y_test</code></li>
                                            <li>Purpose: Measure real-world performance</li>
                                        </ul>

                                        <p><strong><code>Split</code>:</strong> The process of dividing data into training and test sets.</p>
                                        <ul class="small">
                                            <li>Function: <code>train_test_split()</code></li>
                                            <li>Why: Prevents overfitting—ensures model works on new data</li>
                                        </ul>
                                    </div>
                                </div>
                            </div>

                            <!-- Model Training Terms -->
                            <div class="col-md-6 mb-4">
                                <div class="experiment-card">
                                    <div class="card-meta mb-2">
                                        <span class="badge bg-crimson text-white">Model Training Terms</span>
                                    </div>
                                    <div class="card-content">
                                        <p><strong><code>fit()</code>:</strong> Train the model on data. The model learns patterns from X_train and y_train.</p>
                                        <ul class="small mb-3">
                                            <li>Usage: <code>model.fit(X_train, y_train)</code></li>
                                            <li>What happens: Model adjusts internal parameters (weights) to minimize errors</li>
                                            <li>Analogy: Student studying for an exam (seeing questions + answers)</li>
                                        </ul>

                                        <p><strong><code>predict()</code>:</strong> Make predictions on new data. Model outputs predictions based on what it learned.</p>
                                        <ul class="small mb-3">
                                            <li>Usage: <code>y_pred = model.predict(X_test)</code></li>
                                            <li>Input: Only features (X), no labels needed</li>
                                            <li>Analogy: Student taking the exam (answering new questions)</li>
                                        </ul>

                                        <p><strong><code>score()</code>:</strong> Evaluate model performance. Compares predictions to actual labels.</p>
                                        <ul class="small">
                                            <li>Usage: <code>accuracy = model.score(X_test, y_test)</code></li>
                                            <li>Output: Performance metric (e.g., 0.95 = 95% accuracy)</li>
                                            <li>Analogy: Grading the exam (checking answers)</li>
                                        </ul>
                                    </div>
                                </div>
                            </div>

                            <!-- Preprocessing Terms -->
                            <div class="col-md-6 mb-4">
                                <div class="experiment-card">
                                    <div class="card-meta mb-2">
                                        <span class="badge bg-blue text-dark">Preprocessing Terms</span>
                                    </div>
                                    <div class="card-content">
                                        <p><strong><code>fit_transform()</code>:</strong> Learn preprocessing parameters from data AND apply the transformation.</p>
                                        <ul class="small mb-3">
                                            <li>Usage: <code>X_train_scaled = scaler.fit_transform(X_train)</code></li>
                                            <li>Use on: <strong>Training data only</strong></li>
                                            <li>What it does: Calculates mean/std (or min/max) from training data, then scales</li>
                                            <li>Example: StandardScaler learns mean=50, std=10, then applies scaling</li>
                                        </ul>

                                        <p><strong><code>transform()</code>:</strong> Apply previously learned preprocessing to new data.</p>
                                        <ul class="small mb-3">
                                            <li>Usage: <code>X_test_scaled = scaler.transform(X_test)</code></li>
                                            <li>Use on: <strong>Test data (or any new data)</strong></li>
                                            <li>What it does: Uses training mean/std to scale test data</li>
                                            <li>⚠️ Critical: Never use <code>fit_transform()</code> on test data—causes data leakage!</li>
                                        </ul>

                                        <p><strong>Why separate fit and transform?</strong></p>
                                        <ul class="small">
                                            <li>Training: Model should only learn from training data</li>
                                            <li>Testing: Apply same transformation to test data (using training stats)</li>
                                            <li>Real-world: New data gets transformed using original training parameters</li>
                                        </ul>
                                    </div>
                                </div>
                            </div>

                            <!-- Evaluation Terms -->
                            <div class="col-md-6 mb-4">
                                <div class="experiment-card">
                                    <div class="card-meta mb-2">
                                        <span class="badge bg-teal text-white">Evaluation Terms</span>
                                    </div>
                                    <div class="card-content">
                                        <p><strong><code>Accuracy</code>:</strong> Percentage of correct predictions.</p>
                                        <ul class="small mb-3">
                                            <li>Formula: (Correct predictions) / (Total predictions)</li>
                                            <li>Range: 0.0 to 1.0 (0% to 100%)</li>
                                            <li>Example: 0.95 = 95 out of 100 predictions were correct</li>
                                        </ul>

                                        <p><strong><code>Precision</code>:</strong> Of all positive predictions, how many were actually correct?</p>
                                        <ul class="small mb-3">
                                            <li>Formula: True Positives / (True Positives + False Positives)</li>
                                            <li>Use when: False positives are costly (e.g., spam detection)</li>
                                        </ul>

                                        <p><strong><code>Recall</code>:</strong> Of all actual positives, how many did we catch?</p>
                                        <ul class="small mb-3">
                                            <li>Formula: True Positives / (True Positives + False Negatives)</li>
                                            <li>Use when: Missing positives is costly (e.g., cancer detection)</li>
                                        </ul>

                                        <p><strong><code>F1 Score</code>:</strong> Harmonic mean of precision and recall.</p>
                                        <ul class="small">
                                            <li>Range: 0.0 to 1.0 (higher is better)</li>
                                            <li>Use when: Need balance between precision and recall</li>
                                        </ul>
                                    </div>
                                </div>
                            </div>

                            <!-- Common Pitfalls -->
                            <div class="col-md-6 mb-4">
                                <div class="experiment-card" style="border: 2px solid var(--color-crimson);">
                                    <div class="card-meta mb-2">
                                        <span class="badge bg-crimson text-white">⚠️ Common Mistakes</span>
                                    </div>
                                    <div class="card-content">
                                        <p><strong>1. Data Leakage:</strong> Test data "leaking" into training.</p>
                                        <ul class="small mb-3">
                                            <li>❌ Wrong: <code>scaler.fit_transform(X_test)</code></li>
                                            <li>✅ Right: <code>scaler.transform(X_test)</code></li>
                                            <li>Why: Test data should remain unseen during training</li>
                                        </ul>

                                        <p><strong>2. Training on Test Data:</strong> Using test set for training.</p>
                                        <ul class="small mb-3">
                                            <li>❌ Wrong: <code>model.fit(X_test, y_test)</code></li>
                                            <li>✅ Right: <code>model.fit(X_train, y_train)</code></li>
                                            <li>Why: Inflates performance metrics artificially</li>
                                        </ul>

                                        <p><strong>3. Forgetting to Split:</strong> Evaluating on training data.</p>
                                        <ul class="small mb-3">
                                            <li>❌ Wrong: <code>model.score(X_train, y_train)</code></li>
                                            <li>✅ Right: <code>model.score(X_test, y_test)</code></li>
                                            <li>Why: Model has memorized training data (overfitting)</li>
                                        </ul>

                                        <p><strong>4. Wrong Order:</strong> Transform before split.</p>
                                        <ul class="small">
                                            <li>❌ Wrong: Scale data → then split</li>
                                            <li>✅ Right: Split data → then scale training → transform test</li>
                                            <li>Why: Scaler would learn from entire dataset (including test)</li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <div class="highlight-box mt-4">
                            <i class="fas fa-graduation-cap"></i>
                            <strong>Quick Reference:</strong> Throughout this tutorial, you'll see these terms in action. Whenever you see <code>X</code> and <code>y</code>, remember: X = features (what you know), y = labels (what you want to predict). The pattern is always: <code>fit()</code> on training data, <code>predict()</code> on test data, <code>score()</code> to evaluate.
                        </div>
                    </div>

                    <!-- Workflow -->
                    <div id="workflow" class="blog-content mt-5">
                        <h2><i class="fas fa-project-diagram me-2 text-teal"></i>The ML Workflow</h2>
                        
                        <p>Every machine learning project follows these steps:</p>

                        <div class="experiment-card">
                            <div class="card-meta mb-2">
                                <span class="badge bg-teal text-white">Standard ML Workflow</span>
                            </div>
                            <div class="card-content">
                                <ol>
                                    <li><strong>Load data:</strong> Import from CSV, database, or API</li>
                                    <li><strong>Explore:</strong> Visualize distributions, check for missing values</li>
                                    <li><strong>Split:</strong> Separate into training and test sets</li>
                                    <li><strong>Preprocess:</strong> Scale features, encode categoricals</li>
                                    <li><strong>Choose model:</strong> Select algorithm based on problem type</li>
                                    <li><strong>Train:</strong> Fit model on training data</li>
                                    <li><strong>Evaluate:</strong> Test on held-out data</li>
                                    <li><strong>Tune:</strong> Optimize hyperparameters</li>
                                    <li><strong>Deploy:</strong> Save model for production use</li>
                                </ol>
                            </div>
                        </div>

                        <div class="highlight-box">
                            <i class="fas fa-info-circle"></i>
                            <strong>What's Next:</strong> In the following sections, we'll learn each step of this workflow in detail—from preprocessing data to evaluating models. Then we'll put it all together with complete examples using Scikit-learn's built-in datasets.
                        </div>
                    </div>

                    <!-- Built-in Datasets Introduction -->
                    <div id="datasets-intro" class="blog-content mt-5">
                        <h2><i class="fas fa-database me-2 text-teal"></i>Built-in Datasets (Quick Introduction)</h2>
                        
                        <p>Before diving into ML techniques, let's get familiar with Scikit-learn's built-in datasets. These are perfect for learning and experimentation—no need to download external files.</p>

                        <div class="experiment-card">
                            <div class="card-meta mb-2">
                                <span class="badge bg-teal text-white">Available Datasets</span>
                            </div>
                            <div class="card-content">
                                <ul>
                                    <li><strong>Classification:</strong> Iris (flowers), Wine (quality), Digits (handwritten), Breast Cancer (diagnosis)</li>
                                    <li><strong>Regression:</strong> Diabetes (disease progression), California Housing (prices)</li>
                                    <li><strong>Toy Datasets:</strong> Small, clean datasets perfect for quick experiments</li>
                                    <li><strong>Real-world Data:</strong> Based on actual research and applications</li>
                                </ul>
                            </div>
                        </div>

                        <h3>Loading and Exploring Datasets</h3>
                        <p>All dataset loading functions follow the same pattern and return a Bunch object (dictionary-like) with consistent structure:</p>

                        <div class="highlight-box mb-3">
                            <i class="fas fa-info-circle"></i>
                            <strong>Understanding X and y:</strong> In machine learning, we use <code>X</code> (uppercase) for features and <code>y</code> (lowercase) for labels. This convention comes from mathematics where X is a matrix (2D array) and y is a vector (1D array). Every code example follows this pattern.
                        </div>

                        <pre><code class="language-python"># Import dataset loaders
from sklearn.datasets import load_iris, load_wine, load_digits
import pandas as pd  # For DataFrame display

# Load the Iris dataset (most famous ML dataset)
iris = load_iris()

# Bunch object contains:
# - data: FEATURES (X) - the input measurements used for predictions
# - target: LABELS (y) - the output we want to predict
# - feature_names: descriptive names for each feature column
# - target_names: descriptive names for each class/category
# - DESCR: full description of dataset (origin, usage, references)

print("Keys in dataset:", iris.keys())
# Output: dict_keys(['data', 'target', 'feature_names', 'target_names', 'DESCR'])

# CRITICAL CONVENTION: Assign data to X (features) and target to y (labels)
X = iris.data  # Features: measurements like sepal length, petal width
                # Shape: (150 samples, 4 features) = 150 rows × 4 columns
                
y = iris.target  # Labels: species class (0, 1, or 2)
                 # Shape: (150,) = one label per sample

print(f"Shape of features (X): {X.shape}")  # (150, 4) - 2D array (matrix)
print(f"Shape of labels (y): {y.shape}")    # (150,) - 1D array (vector)
print(f"Feature names: {iris.feature_names}")
# ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']
print(f"Target names: {iris.target_names}")  
# ['setosa', 'versicolor', 'virginica'] - the 3 species we're classifying</code></pre>

                        <div class="highlight-box mb-3">
                            <i class="fas fa-lightbulb"></i>
                            <strong>Think of it this way:</strong> Features (X) = "What do we know about each flower?" (measurements). Labels (y) = "What species is it?" (answer we're trying to predict). The model learns the relationship between X and y.
                        </div>

                        <pre><code class="language-python"># Import for data exploration
import pandas as pd
import numpy as np
from sklearn.datasets import load_iris

# Load dataset
iris = load_iris()

# Convert to DataFrame for easy viewing
# Create DataFrame from feature matrix with feature names as columns
df = pd.DataFrame(iris.data, columns=iris.feature_names)
# Add target column with species names
df['species'] = iris.target_names[iris.target]

# Display first few rows
print(df.head())
#    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm) species
# 0                5.1               3.5                1.4               0.2  setosa
# 1                4.9               3.0                1.4               0.2  setosa
# ...

# Statistical summary
print(df.describe())
# Shows count, mean, std, min, quartiles, max for each feature

# Check class distribution
print(df['species'].value_counts())
# setosa        50
# versicolor    50
# virginica     50
# Perfect balance—50 samples per class!</code></pre>

                        <pre><code class="language-python"># Reading the full dataset description
from sklearn.datasets import load_iris

iris = load_iris()

# DESCR contains detailed information about the dataset
print(iris.DESCR)
# Includes:
# - Dataset characteristics (number of samples, features, classes)
# - Attribute information (feature descriptions)
# - Creator and source
# - References to relevant papers

# This is helpful for understanding what you're working with!</code></pre>

                        <div class="highlight-box mt-4">
                            <i class="fas fa-lightbulb"></i>
                            <strong>Key Takeaway:</strong> All Scikit-learn datasets use the same structure (<code>data</code>, <code>target</code>, <code>feature_names</code>, <code>target_names</code>, <code>DESCR</code>). Learn one, and you know them all! In later sections, we'll use these datasets to demonstrate complete ML workflows with classification, regression, and more.
                        </div>
                    </div>

                    <!-- Real-World Dataset Loaders -->
                    <div id="dataset-loaders" class="blog-content mt-5">
                        <h2><i class="fas fa-database me-2 text-teal"></i>Real-World Dataset Loaders</h2>
                        
                        <p>Scikit-learn provides several real-world datasets from published research and applications. These are perfect for learning ML techniques without downloading external data.</p>

                        <h3>Classification Datasets</h3>

                        <div class="experiment-card">
                            <h4><i class="fas fa-flower me-2"></i>Iris Dataset (Multi-class Classification)</h4>
                            <div class="card-meta">
                                <span class="badge bg-teal">Classification</span>
                                <span class="badge bg-crimson">3 Classes</span>
                            </div>
                            <div class="card-content">
                                <p><strong>Description:</strong> Classic dataset containing measurements of 3 iris flower species. Most famous ML dataset, published by Ronald Fisher in 1936.</p>
                                <ul>
                                    <li><strong>Samples:</strong> 150 (50 per class)</li>
                                    <li><strong>Features:</strong> 4 (sepal length/width, petal length/width in cm)</li>
                                    <li><strong>Classes:</strong> 3 (Setosa, Versicolor, Virginica)</li>
                                    <li><strong>Use Cases:</strong> Perfect for beginners, testing classification algorithms</li>
                                </ul>
                            </div>
                        </div>

                        <pre><code class="language-python">from sklearn.datasets import load_iris
import pandas as pd
import numpy as np

# Load dataset
iris = load_iris()
X, y = iris.data, iris.target

print(f"Dataset shape: {X.shape}")  # (150, 4)
print(f"Classes: {iris.target_names}")  # ['setosa' 'versicolor' 'virginica']
print(f"Feature names: {iris.feature_names}")

# Class distribution
unique, counts = np.unique(y, return_counts=True)
print("\nClass distribution:")
for name, count in zip(iris.target_names, counts):
    print(f"  {name}: {count} samples")

# Convert to DataFrame for easy viewing
df = pd.DataFrame(X, columns=iris.feature_names)
df['species'] = iris.target_names[y]
print("\nFirst 5 samples:")
print(df.head())</code></pre>

                        <div class="experiment-card">
                            <h4><i class="fas fa-wine-glass me-2"></i>Wine Dataset (Multi-class Classification)</h4>
                            <div class="card-meta">
                                <span class="badge bg-teal">Classification</span>
                                <span class="badge bg-crimson">3 Classes</span>
                            </div>
                            <div class="card-content">
                                <p><strong>Description:</strong> Chemical analysis of wines from Italy. Predict wine cultivar based on 13 chemical measurements.</p>
                                <ul>
                                    <li><strong>Samples:</strong> 178</li>
                                    <li><strong>Features:</strong> 13 (alcohol, malic acid, ash, alkalinity, magnesium, phenols, etc.)</li>
                                    <li><strong>Classes:</strong> 3 wine cultivars</li>
                                    <li><strong>Use Cases:</strong> Feature scaling demos, multi-class classification</li>
                                </ul>
                            </div>
                        </div>

                        <pre><code class="language-python">from sklearn.datasets import load_wine
import pandas as pd

# Load dataset
wine = load_wine()
X, y = wine.data, wine.target

print(f"Dataset shape: {X.shape}")  # (178, 13)
print(f"\nFirst 3 feature names: {wine.feature_names[:3]}")
# ['alcohol', 'malic_acid', 'ash']

# Check feature ranges (important for scaling!)
df = pd.DataFrame(X, columns=wine.feature_names)
print("\nFeature statistics:")
print(df.describe()[['alcohol', 'malic_acid', 'proline']])
# Notice: features have very different scales!
# alcohol: 11-15, malic_acid: 0-6, proline: 278-1680
# This dataset needs scaling before use with distance-based algorithms</code></pre>

                        <div class="experiment-card">
                            <h4><i class="fas fa-hand-paper me-2"></i>Digits Dataset (Image Classification)</h4>
                            <div class="card-meta">
                                <span class="badge bg-teal">Classification</span>
                                <span class="badge bg-crimson">10 Classes</span>
                            </div>
                            <div class="card-content">
                                <p><strong>Description:</strong> Handwritten digit images (0-9). Simplified version of MNIST with 8×8 grayscale images.</p>
                                <ul>
                                    <li><strong>Samples:</strong> 1,797</li>
                                    <li><strong>Features:</strong> 64 (8×8 pixel intensities, values 0-16)</li>
                                    <li><strong>Classes:</strong> 10 (digits 0-9)</li>
                                    <li><strong>Use Cases:</strong> Image classification, neural networks, dimensionality reduction</li>
                                </ul>
                            </div>
                        </div>

                        <pre><code class="language-python">from sklearn.datasets import load_digits
import matplotlib.pyplot as plt
import numpy as np

# Load dataset
digits = load_digits()
X, y = digits.data, digits.target

print(f"Dataset shape: {X.shape}")  # (1797, 64)
print(f"Each sample: 8x8 = 64 pixel values")
print(f"Classes: {np.unique(y)}")  # [0 1 2 3 4 5 6 7 8 9]

# Visualize first 10 digits
fig, axes = plt.subplots(2, 5, figsize=(12, 5))
for i, ax in enumerate(axes.flat):
    # Reshape 64-length vector to 8×8 image
    image = digits.images[i]
    ax.imshow(image, cmap='gray')
    ax.set_title(f"Label: {digits.target[i]}")
    ax.axis('off')
plt.tight_layout()
plt.show()

# Pixel intensity range
print(f"\nPixel value range: {X.min():.0f} to {X.max():.0f}")
print("0 = white background, 16 = black digit")</code></pre>

                        <div class="experiment-card">
                            <h4><i class="fas fa-user-md me-2"></i>Breast Cancer Dataset (Binary Classification)</h4>
                            <div class="card-meta">
                                <span class="badge bg-teal">Classification</span>
                                <span class="badge bg-crimson">2 Classes</span>
                            </div>
                            <div class="card-content">
                                <p><strong>Description:</strong> Features computed from breast mass images. Predict malignant vs benign tumors.</p>
                                <ul>
                                    <li><strong>Samples:</strong> 569</li>
                                    <li><strong>Features:</strong> 30 (radius, texture, perimeter, area, smoothness, compactness, concavity, etc.)</li>
                                    <li><strong>Classes:</strong> 2 (malignant=0, benign=1)</li>
                                    <li><strong>Use Cases:</strong> Binary classification, medical diagnosis, feature importance analysis</li>
                                </ul>
                            </div>
                        </div>

                        <pre><code class="language-python">from sklearn.datasets import load_breast_cancer
import pandas as pd
import numpy as np

# Load dataset
cancer = load_breast_cancer()
X, y = cancer.data, cancer.target

print(f"Dataset shape: {X.shape}")  # (569, 30)
print(f"Classes: {cancer.target_names}")  # ['malignant' 'benign']

# Class distribution
unique, counts = np.unique(y, return_counts=True)
for name, count in zip(cancer.target_names, counts):
    print(f"{name}: {count} samples ({count/len(y)*100:.1f}%)")
# malignant: 212 (37.3%)
# benign: 357 (62.7%)
# Slightly imbalanced—benign tumors are more common

# Feature groups
print("\nFeature groups (first 5 of each):")
print("Mean features:", cancer.feature_names[:5])
print("SE features:", cancer.feature_names[10:15])
print("Worst features:", cancer.feature_names[20:25])</code></pre>

                        <h3>Regression Datasets</h3>

                        <div class="experiment-card">
                            <h4><i class="fas fa-heart me-2"></i>Diabetes Dataset (Regression)</h4>
                            <div class="card-meta">
                                <span class="badge bg-teal">Regression</span>
                            </div>
                            <div class="card-content">
                                <p><strong>Description:</strong> Predict disease progression one year after baseline. Classic medical regression dataset.</p>
                                <ul>
                                    <li><strong>Samples:</strong> 442</li>
                                    <li><strong>Features:</strong> 10 (age, sex, BMI, blood pressure, 6 blood serum measurements)</li>
                                    <li><strong>Target:</strong> Quantitative measure of disease progression</li>
                                    <li><strong>Use Cases:</strong> Regression, feature selection, regularization demos</li>
                                </ul>
                            </div>
                        </div>

                        <pre><code class="language-python">from sklearn.datasets import load_diabetes
import pandas as pd
import matplotlib.pyplot as plt

# Load dataset
diabetes = load_diabetes()
X, y = diabetes.data, diabetes.target

print(f"Dataset shape: {X.shape}")  # (442, 10)
print(f"Feature names: {diabetes.feature_names}")
# ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']

print(f"\nTarget statistics:")
print(f"  Min: {y.min():.1f}")
print(f"  Max: {y.max():.1f}")
print(f"  Mean: {y.mean():.1f}")
print(f"  Std: {y.std():.1f}")

# Visualize target distribution
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.hist(y, bins=30, edgecolor='black', alpha=0.7)
plt.xlabel('Disease Progression')
plt.ylabel('Frequency')
plt.title('Target Distribution')

plt.subplot(1, 2, 2)
plt.scatter(X[:, 2], y, alpha=0.5)  # BMI vs progression
plt.xlabel('BMI (normalized)')
plt.ylabel('Disease Progression')
plt.title('BMI vs Disease Progression')
plt.tight_layout()
plt.show()</code></pre>

                        <div class="experiment-card">
                            <h4><i class="fas fa-home me-2"></i>California Housing Dataset (Regression)</h4>
                            <div class="card-meta">
                                <span class="badge bg-teal">Regression</span>
                            </div>
                            <div class="card-content">
                                <p><strong>Description:</strong> Predict median house prices in California districts. Based on 1990 census data.</p>
                                <ul>
                                    <li><strong>Samples:</strong> 20,640</li>
                                    <li><strong>Features:</strong> 8 (median income, house age, avg rooms, avg bedrooms, population, avg occupancy, latitude, longitude)</li>
                                    <li><strong>Target:</strong> Median house value (in $100,000s)</li>
                                    <li><strong>Use Cases:</strong> Regression, spatial data, larger dataset for performance testing</li>
                                </ul>
                            </div>
                        </div>

                        <pre><code class="language-python">from sklearn.datasets import fetch_california_housing
import pandas as pd
import numpy as np

# Load dataset (uses fetch_ because it downloads data)
housing = fetch_california_housing()
X, y = housing.data, housing.target

print(f"Dataset shape: {X.shape}")  # (20640, 8)
print(f"Feature names: {housing.feature_names}")
# ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']

print(f"\nTarget statistics (in $100,000s):")
print(f"  Min: ${y.min()*100000:.0f}")
print(f"  Max: ${y.max()*100000:.0f}")
print(f"  Median: ${np.median(y)*100000:.0f}")

# Geographic distribution
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
plt.scatter(X[:, 7], X[:, 6], c=y, cmap='viridis', alpha=0.3, s=10)
plt.colorbar(label='Median House Value ($100k)')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.title('California Housing Prices by Location')
plt.show()
# You can see the shape of California!</code></pre>

                        <div class="highlight-box mt-4">
                            <i class="fas fa-info-circle"></i>
                            <strong>Dataset Loading Patterns:</strong> Most datasets use <code>load_*()</code> functions (data included with scikit-learn). Larger datasets like California Housing use <code>fetch_*()</code> (downloads data on first use and caches it).
                        </div>
                    </div>

                    <!-- Synthetic Dataset Generators -->
                    <div id="sample-generators" class="blog-content mt-5">
                        <h2><i class="fas fa-flask me-2 text-teal"></i>Synthetic Dataset Generators</h2>
                        
                        <p>Scikit-learn provides powerful generators to create synthetic datasets with known properties. These are invaluable for testing algorithms, debugging models, and understanding how different patterns affect performance.</p>

                        <h3>Classification Generators</h3>

                        <div class="experiment-card">
                            <h4><i class="fas fa-shapes me-2"></i>make_classification()</h4>
                            <div class="card-meta">
                                <span class="badge bg-teal">Classification</span>
                                <span class="badge bg-crimson">Customizable</span>
                            </div>
                            <div class="card-content">
                                <p><strong>Purpose:</strong> Generate random n-class classification problems with configurable complexity.</p>
                                <p><strong>Key Parameters:</strong></p>
                                <ul>
                                    <li><code>n_samples</code>: Number of samples to generate</li>
                                    <li><code>n_features</code>: Total number of features</li>
                                    <li><code>n_informative</code>: Features that are useful for prediction</li>
                                    <li><code>n_redundant</code>: Features that are linear combinations of informative features</li>
                                    <li><code>n_classes</code>: Number of classes (labels)</li>
                                    <li><code>class_sep</code>: Separation between classes (higher = easier)</li>
                                    <li><code>random_state</code>: Seed for reproducibility</li>
                                </ul>
                            </div>
                        </div>

                        <pre><code class="language-python">from sklearn.datasets import make_classification
import matplotlib.pyplot as plt
import numpy as np

# Generate a simple 2-class problem
X, y = make_classification(
    n_samples=1000,      # 1000 data points
    n_features=2,        # 2 features (easy to visualize)
    n_informative=2,     # Both features are useful
    n_redundant=0,       # No redundant features
    n_classes=2,         # Binary classification
    class_sep=1.5,       # Moderate separation
    random_state=42
)

print(f"X shape: {X.shape}")  # (1000, 2)
print(f"y unique values: {np.unique(y)}")  # [0 1]
print(f"Class 0: {np.sum(y==0)} samples")
print(f"Class 1: {np.sum(y==1)} samples")

# Visualize
plt.figure(figsize=(8, 6))
plt.scatter(X[y==0, 0], X[y==0, 1], label='Class 0', alpha=0.6, edgecolors='k')
plt.scatter(X[y==1, 0], X[y==1, 1], label='Class 1', alpha=0.6, edgecolors='k')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('Generated Classification Data')
plt.legend()
plt.show()</code></pre>

                        <pre><code class="language-python">from sklearn.datasets import make_classification
import numpy as np

# Generate a HARDER problem (more realistic)
X, y = make_classification(
    n_samples=500,
    n_features=20,        # 20 total features
    n_informative=15,     # 15 are useful
    n_redundant=3,        # 3 are redundant (linear combos)
    n_repeated=0,         # No duplicated features
    n_classes=3,          # Multi-class problem
    n_clusters_per_class=2,  # Each class has 2 clusters
    class_sep=0.8,        # Classes overlap slightly (harder)
    flip_y=0.05,          # 5% label noise (realistic!)
    random_state=42
)

print(f"Dataset shape: {X.shape}")  # (500, 20)
print(f"Classes: {np.unique(y)}")
print("\nClass distribution:")
for cls in np.unique(y):
    print(f"  Class {cls}: {np.sum(y==cls)} samples")

# This dataset is perfect for testing:
# - Feature selection (which of 20 features matter?)
# - Handling label noise
# - Multi-class classification</code></pre>

                        <div class="experiment-card">
                            <h4><i class="fas fa-circle me-2"></i>make_blobs()</h4>
                            <div class="card-meta">
                                <span class="badge bg-teal">Clustering & Classification</span>
                            </div>
                            <div class="card-content">
                                <p><strong>Purpose:</strong> Generate isotropic Gaussian blobs (clusters). Perfect for clustering algorithm demos.</p>
                                <p><strong>Key Parameters:</strong></p>
                                <ul>
                                    <li><code>n_samples</code>: Total samples (distributed across centers)</li>
                                    <li><code>n_features</code>: Number of features</li>
                                    <li><code>centers</code>: Number of centers/clusters or explicit center coordinates</li>
                                    <li><code>cluster_std</code>: Standard deviation of clusters (controls spread)</li>
                                    <li><code>center_box</code>: Bounding box for cluster centers</li>
                                </ul>
                            </div>
                        </div>

                        <pre><code class="language-python">from sklearn.datasets import make_blobs
import matplotlib.pyplot as plt
import numpy as np

# Generate 3 well-separated clusters
X, y = make_blobs(
    n_samples=300,       # 300 points total
    n_features=2,        # 2D for visualization
    centers=3,           # 3 cluster centers
    cluster_std=0.5,     # Tight clusters
    random_state=42
)

print(f"X shape: {X.shape}")  # (300, 2)
print(f"Cluster labels: {np.unique(y)}")

plt.figure(figsize=(8, 6))
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', edgecolors='k', alpha=0.7)
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('Generated Blobs (3 Clusters)')
plt.colorbar(label='Cluster')
plt.show()</code></pre>

                        <pre><code class="language-python">from sklearn.datasets import make_blobs
import matplotlib.pyplot as plt
import numpy as np

# Custom cluster centers (explicit positioning)
centers = np.array([
    [0, 0],      # Cluster 1 at origin
    [5, 5],      # Cluster 2 at (5, 5)
    [0, 5]       # Cluster 3 at (0, 5)
])

X, y = make_blobs(
    n_samples=600,
    centers=centers,     # Use our custom centers
    cluster_std=[0.4, 1.0, 0.7],  # Different spread per cluster!
    random_state=42
)

print(f"Generated {len(X)} samples")
print(f"Center 0 samples: {np.sum(y==0)}")
print(f"Center 1 samples: {np.sum(y==1)}")
print(f"Center 2 samples: {np.sum(y==2)}")

plt.figure(figsize=(8, 6))
plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', alpha=0.6, edgecolors='k')
plt.scatter(centers[:, 0], centers[:, 1], marker='X', s=200, c='red', edgecolors='black', linewidths=2, label='Centers')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('Blobs with Custom Centers and Variable Spread')
plt.legend()
plt.show()</code></pre>

                        <div class="experiment-card">
                            <h4><i class="fas fa-moon me-2"></i>make_moons() & make_circles()</h4>
                            <div class="card-meta">
                                <span class="badge bg-teal">Non-linear Classification</span>
                            </div>
                            <div class="card-content">
                                <p><strong>Purpose:</strong> Generate non-linearly separable datasets. Perfect for demonstrating kernel methods, neural networks, and testing linear vs non-linear classifiers.</p>
                                <p><strong>Key Parameters:</strong></p>
                                <ul>
                                    <li><code>n_samples</code>: Number of samples to generate</li>
                                    <li><code>noise</code>: Standard deviation of Gaussian noise (0.0 = perfect, 0.1 = realistic)</li>
                                    <li><code>random_state</code>: Seed for reproducibility</li>
                                    <li><code>factor</code> (circles only): Scale factor between inner and outer circle</li>
                                </ul>
                            </div>
                        </div>

                        <pre><code class="language-python">from sklearn.datasets import make_moons, make_circles
import matplotlib.pyplot as plt

# Generate moons
X_moons, y_moons = make_moons(n_samples=300, noise=0.1, random_state=42)

# Generate circles
X_circles, y_circles = make_circles(n_samples=300, noise=0.05, factor=0.5, random_state=42)

# Visualize both
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

axes[0].scatter(X_moons[:, 0], X_moons[:, 1], c=y_moons, cmap='viridis', edgecolors='k', alpha=0.7)
axes[0].set_title('Moons Dataset (Non-linear Boundary)')
axes[0].set_xlabel('Feature 1')
axes[0].set_ylabel('Feature 2')

axes[1].scatter(X_circles[:, 0], X_circles[:, 1], c=y_circles, cmap='viridis', edgecolors='k', alpha=0.7)
axes[1].set_title('Circles Dataset (Concentric Classes)')
axes[1].set_xlabel('Feature 1')
axes[1].set_ylabel('Feature 2')

plt.tight_layout()
plt.show()

print("These datasets CANNOT be separated by a straight line!")
print("Linear classifiers (like Logistic Regression) will fail.")
print("Non-linear models (SVM with RBF kernel, neural nets) will succeed.")</code></pre>

                        <h3>Regression Generators</h3>

                        <div class="experiment-card">
                            <h4><i class="fas fa-chart-line me-2"></i>make_regression()</h4>
                            <div class="card-meta">
                                <span class="badge bg-teal">Regression</span>
                            </div>
                            <div class="card-content">
                                <p><strong>Purpose:</strong> Generate random regression problems with known ground truth.</p>
                                <p><strong>Key Parameters:</strong></p>
                                <ul>
                                    <li><code>n_samples</code>: Number of samples</li>
                                    <li><code>n_features</code>: Total features</li>
                                    <li><code>n_informative</code>: Useful features (others are noise)</li>
                                    <li><code>noise</code>: Standard deviation of Gaussian noise</li>
                                    <li><code>bias</code>: Constant term added to output</li>
                                    <li><code>coef</code>: If True, returns true coefficients</li>
                                </ul>
                            </div>
                        </div>

                        <pre><code class="language-python">from sklearn.datasets import make_regression
import matplotlib.pyplot as plt
import numpy as np

# Simple 1D regression for visualization
X, y = make_regression(
    n_samples=200,
    n_features=1,        # Single feature (easy to plot)
    noise=20,            # Add realistic noise
    random_state=42
)

print(f"X shape: {X.shape}")  # (200, 1)
print(f"y shape: {y.shape}")  # (200,)
print(f"y range: [{y.min():.1f}, {y.max():.1f}]")

plt.figure(figsize=(8, 6))
plt.scatter(X, y, alpha=0.6, edgecolors='k')
plt.xlabel('Feature')
plt.ylabel('Target')
plt.title('Generated Regression Data (1 feature)')
plt.show()</code></pre>

                        <pre><code class="language-python">from sklearn.datasets import make_regression
import numpy as np

# Multi-feature regression with known coefficients
X, y, coef = make_regression(
    n_samples=500,
    n_features=10,        # 10 total features
    n_informative=5,      # Only 5 actually matter
    noise=10,
    coef=True,            # Return true coefficients
    random_state=42
)

print(f"Dataset shape: {X.shape}")  # (500, 10)
print(f"\nTrue coefficients (first 5):")
print(coef[:5])
print("\nNon-informative features have coefficients ≈ 0:")
print(coef[5:])
print("\nUse this to test if your model identifies important features!")</code></pre>

                        <h3>Advanced Generators</h3>

                        <div class="experiment-card">
                            <h4><i class="fas fa-project-diagram me-2"></i>Other Useful Generators</h4>
                            <div class="card-content">
                                <ul>
                                    <li><strong>make_multilabel_classification():</strong> Multi-label problems (each sample has multiple labels)</li>
                                    <li><strong>make_hastie_10_2():</strong> Binary classification with 10 features (from Elements of Statistical Learning)</li>
                                    <li><strong>make_gaussian_quantiles():</strong> Gaussian distributions divided into quantiles</li>
                                    <li><strong>make_swiss_roll():</strong> 3D manifold for dimensionality reduction demos</li>
                                    <li><strong>make_s_curve():</strong> S-shaped 3D manifold</li>
                                    <li><strong>make_low_rank_matrix():</strong> Low-rank matrices for matrix factorization</li>
                                </ul>
                            </div>
                        </div>

                        <pre><code class="language-python">from sklearn.datasets import make_multilabel_classification
import numpy as np

# Multi-label classification (e.g., image tags: "cat", "outdoor", "sunny")
X, y = make_multilabel_classification(
    n_samples=200,
    n_features=10,
    n_classes=5,          # 5 possible labels
    n_labels=2,           # Each sample has ~2 labels on average
    random_state=42
)

print(f"X shape: {X.shape}")  # (200, 10)
print(f"y shape: {y.shape}")  # (200, 5) - binary matrix!
print(f"\nFirst sample features: {X[0]}")
print(f"First sample labels: {y[0]}")
# [1 0 1 0 0] means this sample has labels 0 and 2</code></pre>

                        <pre><code class="language-python">from sklearn.datasets import make_swiss_roll
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np

# Generate Swiss roll (3D manifold)
X, color = make_swiss_roll(n_samples=1500, noise=0.1, random_state=42)

print(f"X shape: {X.shape}")  # (1500, 3)
print("This is a 3D dataset that lies on a 2D manifold!")
print("Perfect for testing dimensionality reduction (t-SNE, PCA, Isomap)")

# Visualize in 3D
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=color, cmap='viridis', s=10)
ax.set_title('Swiss Roll 3D Manifold')
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
plt.show()</code></pre>

                        <div class="highlight-box mt-4">
                            <i class="fas fa-lightbulb"></i>
                            <strong>When to Use Synthetic Data:</strong>
                            <ul style="margin-bottom: 0;">
                                <li><strong>Algorithm Testing:</strong> Verify your implementation works on known data</li>
                                <li><strong>Performance Comparison:</strong> Compare algorithms on controlled problems</li>
                                <li><strong>Debugging:</strong> Start simple (make_blobs) before tackling real data</li>
                                <li><strong>Education:</strong> Demonstrate concepts (e.g., non-linear boundaries with make_moons)</li>
                                <li><strong>Scaling Tests:</strong> Generate large datasets to test performance</li>
                            </ul>
                        </div>

                        <div class="highlight-box mt-3">
                            <i class="fas fa-exclamation-triangle"></i>
                            <strong>Important:</strong> Always set <code>random_state</code> for reproducibility! This ensures you get the same dataset across runs, making debugging and comparison easier.
                        </div>
                    </div>

                    <!-- Preprocessing -->
                    <div id="preprocessing" class="blog-content mt-5">
                        <h2><i class="fas fa-wrench me-2 text-teal"></i>Data Preprocessing</h2>
                        
                        <p>Preprocessing transforms raw data into a format suitable for ML algorithms. This is critical—garbage in, garbage out.</p>

                        <h3>Feature Scaling</h3>
                        <p>Many algorithms (SVM, neural networks, k-NN) require features on similar scales:</p>

                        <pre><code class="language-python">import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Load sample data
iris = load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# StandardScaler: mean=0, std=1
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)  # Use training stats!
print("Scaled training data (first 2 samples):")
print(X_scaled[:2])
print(f"Mean: {X_scaled.mean():.3f}, Std: {X_scaled.std():.3f}")

# MinMaxScaler: scale to [0, 1]
minmax = MinMaxScaler()
X_minmax = minmax.fit_transform(X_train)
print("\nMinMax scaled data (first 2 samples):")
print(X_minmax[:2])
print(f"Min: {X_minmax.min():.3f}, Max: {X_minmax.max():.3f}")</code></pre>

                        <h3>Encoding Categorical Variables</h3>
                        <pre><code class="language-python">from sklearn.preprocessing import LabelEncoder, OneHotEncoder
import numpy as np

# LabelEncoder: convert strings to integers
le = LabelEncoder()
animal_names = ['cat', 'dog', 'cat', 'bird']
y_encoded = le.fit_transform(animal_names)  # [0, 1, 0, 2]
print("LabelEncoder mapping:")
for i, label in enumerate(le.classes_):
    print(f"  {label}: {i}")
print(f"Encoded result: {y_encoded}")

# OneHotEncoder: create binary columns
ohe = OneHotEncoder(sparse_output=False)  # sparse_output replaces sparse in newer scikit-learn
colors = np.array(['red', 'blue', 'green']).reshape(-1, 1)
encoded = ohe.fit_transform(colors)
print("\nOneHotEncoder result:")
print(encoded)
print(f"Feature names: {ohe.get_feature_names_out(['color'])}")</code></pre>

                        <div class="highlight-box">
                            <i class="fas fa-exclamation-triangle"></i>
                            <strong>Critical:</strong> Always <code>fit()</code> on training data, then <code>transform()</code> on both train and test. Never <code>fit()</code> on test data—this causes data leakage!
                        </div>
                    </div>

                    <!-- Classification -->
                    <div id="classification" class="blog-content mt-5">
                        <h2><i class="fas fa-tags me-2 text-teal"></i>Classification Models</h2>
                        
                        <p>Classification predicts categorical outcomes (spam/not spam, disease/healthy, customer churn).</p>

                        <h3>Common Classifiers</h3>
                        <pre><code class="language-python">from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Load sample data
iris = load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Logistic Regression (linear boundary)
log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_train, y_train)
print(f"Logistic Regression accuracy: {log_reg.score(X_test, y_test):.3f}")

# Random Forest (ensemble of decision trees)
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
print(f"Random Forest accuracy: {rf.score(X_test, y_test):.3f}")

# Support Vector Machine (complex boundaries)
svm = SVC(kernel='rbf')
svm.fit(X_train, y_train)
print(f"SVM accuracy: {svm.score(X_test, y_test):.3f}")

# k-Nearest Neighbors (instance-based)
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
print(f"KNN accuracy: {knn.score(X_test, y_test):.3f}")</code></pre>

                        <div class="experiment-card">
                            <div class="card-meta mb-2">
                                <span class="badge bg-teal text-white">Choosing an Algorithm</span>
                            </div>
                            <div class="card-content">
                                <ul>
                                    <li><strong>Logistic Regression:</strong> Fast, interpretable, works well for linearly separable data</li>
                                    <li><strong>Random Forest:</strong> Handles non-linear relationships, robust to outliers, good default choice</li>
                                    <li><strong>SVM:</strong> Powerful for complex boundaries, sensitive to feature scaling</li>
                                    <li><strong>k-NN:</strong> Simple, no training phase, good for small datasets</li>
                                </ul>
                                <p><strong>Rule of thumb:</strong> Start with Logistic Regression (fast baseline), then try Random Forest if you need more complexity.</p>
                            </div>
                        </div>
                    </div>

                    <!-- Regression -->
                    <div id="regression" class="blog-content mt-5">
                        <h2><i class="fas fa-chart-line me-2 text-teal"></i>Regression Models</h2>
                        
                        <p>Regression predicts continuous values (house prices, temperatures, sales).</p>

                        <pre><code class="language-python">from sklearn.linear_model import LinearRegression, Ridge
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split

# Generate synthetic data
from sklearn.datasets import make_regression
X_reg, y_reg = make_regression(n_samples=200, n_features=3, noise=10, random_state=42)
X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)

# Linear Regression
lin_reg = LinearRegression()
lin_reg.fit(X_train_r, y_train_r)
y_pred = lin_reg.predict(X_test_r)
print(f"Linear - RMSE: {mean_squared_error(y_test_r, y_pred):.2f}")
print(f"Linear - R²: {r2_score(y_test_r, y_pred):.3f}")

# Ridge Regression (with L2 regularization)
ridge = Ridge(alpha=1.0)
ridge.fit(X_train_r, y_train_r)
y_pred_ridge = ridge.predict(X_test_r)
print(f"Ridge - R²: {r2_score(y_test_r, y_pred_ridge):.3f}")

# Random Forest Regressor
rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)
rf_reg.fit(X_train_r, y_train_r)
print(f"RF - R²: {r2_score(y_test_r, rf_reg.predict(X_test_r)):.3f}")</code></pre>
                    </div>

                    <!-- Clustering -->
                    <div id="clustering" class="blog-content mt-5">
                        <h2><i class="fas fa-circle-notch me-2 text-teal"></i>Clustering</h2>
                        
                        <p>Clustering finds groups in unlabeled data (customer segmentation, anomaly detection).</p>

                        <pre><code class="language-python">from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# Generate blob data
from sklearn.datasets import make_blobs
X_blob, y_true = make_blobs(n_samples=300, centers=4, cluster_std=1.0, random_state=42)

# K-Means clustering
kmeans = KMeans(n_clusters=4, random_state=42)
labels = kmeans.fit_predict(X_blob)

print(f"Cluster centers: {kmeans.cluster_centers_.shape}")
print(f"Silhouette score: {silhouette_score(X_blob, labels):.3f}")

# Visualize (assuming 2D data)
import matplotlib.pyplot as plt
plt.scatter(X_blob[:, 0], X_blob[:, 1], c=labels, cmap='viridis')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], 
            marker='X', s=200, c='red', label='Centroids')
plt.legend()
plt.title('K-Means Clustering')
plt.show()</code></pre>

                        <div class="highlight-box">
                            <i class="fas fa-info-circle"></i>
                            <strong>Silhouette Score:</strong> Ranges from -1 to 1. Values near 1 indicate well-separated clusters, near 0 means overlapping clusters, negative values suggest misclassification.
                        </div>
                    </div>

                    <!-- Evaluation -->
                    <div id="evaluation" class="blog-content mt-5">
                        <h2><i class="fas fa-check-square me-2 text-teal"></i>Model Evaluation</h2>
                        
                        <h3>Classification Metrics</h3>
                        <pre><code class="language-python">from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Load data
iris = load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Metrics
print(f"Accuracy: {accuracy_score(y_test, y_pred):.3f}")
print(f"Precision: {precision_score(y_test, y_pred, average='weighted'):.3f}")
print(f"Recall: {recall_score(y_test, y_pred, average='weighted'):.3f}")
print(f"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.3f}")

# Confusion Matrix
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Classification Report (comprehensive)
print("\nClassification Report:")
print(classification_report(y_test, y_pred))</code></pre>

                        <h3>Cross-Validation</h3>
                        <p>A single train/test split can be misleading—your model might get "lucky" or "unlucky" depending on which samples end up in the test set. Cross-validation solves this by testing your model on multiple different splits of the data.</p>

                        <div class="highlight-box">
                            <i class="fas fa-info-circle text-info me-2"></i>
                            <strong>What is Cross-Validation?</strong><br>
                            Cross-validation is a technique that evaluates model performance by:
                            <ol>
                                <li><strong>Splitting data into K folds</strong> (e.g., 5 equal parts)</li>
                                <li><strong>Training K times</strong>: Each time, use K-1 folds for training and 1 fold for testing</li>
                                <li><strong>Rotating the test fold</strong>: Every fold gets to be the test set exactly once</li>
                                <li><strong>Averaging results</strong>: Final score is the mean of all K test scores</li>
                            </ol>
                            This gives a more reliable estimate of how your model will perform on unseen data, using all your data for both training and testing (but never at the same time).
                        </div>

                        <h4>Why Cross-Validation Matters</h4>
                        <ul>
                            <li><strong>Reduces Variance:</strong> Single split might be lucky/unlucky—CV averages over multiple splits</li>
                            <li><strong>Uses All Data:</strong> Every sample is used for both training and testing (in different iterations)</li>
                            <li><strong>Detects Overfitting:</strong> Large gap between train and CV scores indicates overfitting</li>
                            <li><strong>Model Selection:</strong> Compare different models or hyperparameters fairly</li>
                            <li><strong>Small Dataset Friendly:</strong> Maximizes use of limited data (unlike holding out large test set)</li>
                        </ul>

                        <h4>K-Fold Cross-Validation Example</h4>
                        <p>Let's see how 5-fold CV works step-by-step:</p>

                        <pre><code class="language-python">from sklearn.model_selection import cross_val_score, KFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris

# Load data
iris = load_iris()
X, y = iris.data, iris.target

# Create model
model = RandomForestClassifier(n_estimators=100, random_state=42)

# 5-fold cross-validation
scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
print(f"CV scores: {scores}")
print(f"Mean: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})")

# Custom K-Fold
kf = KFold(n_splits=10, shuffle=True, random_state=42)
fold_scores = []
for i, (train_idx, test_idx) in enumerate(kf.split(X)):
    X_train_fold, X_test_fold = X[train_idx], X[test_idx]
    y_train_fold, y_test_fold = y[train_idx], y[test_idx]
    model.fit(X_train_fold, y_train_fold)
    fold_score = model.score(X_test_fold, y_test_fold)
    fold_scores.append(fold_score)
    print(f"Fold {i+1} accuracy: {fold_score:.3f}")
print(f"Mean fold accuracy: {sum(fold_scores)/len(fold_scores):.3f}")</code></pre>

                        <div class="experiment-card">
                            <div class="card-meta mb-2">
                                <span class="badge bg-teal text-white">Understanding the CV Process</span>
                            </div>
                            <div class="card-content">
                                <h4>5-Fold Cross-Validation Breakdown</h4>
                                <p>With 150 samples divided into 5 folds (30 samples each):</p>
                                <ul>
                                    <li><strong>Fold 1:</strong> Train on folds 2-5 (120 samples), test on fold 1 (30 samples) → Score 1</li>
                                    <li><strong>Fold 2:</strong> Train on folds 1,3-5 (120 samples), test on fold 2 (30 samples) → Score 2</li>
                                    <li><strong>Fold 3:</strong> Train on folds 1-2,4-5 (120 samples), test on fold 3 (30 samples) → Score 3</li>
                                    <li><strong>Fold 4:</strong> Train on folds 1-3,5 (120 samples), test on fold 4 (30 samples) → Score 4</li>
                                    <li><strong>Fold 5:</strong> Train on folds 1-4 (120 samples), test on fold 5 (30 samples) → Score 5</li>
                                </ul>
                                <p><strong>Final Score:</strong> Average of all 5 scores ± standard deviation (shows variability)</p>
                                <p><strong>Key Insight:</strong> Every sample is used for testing exactly once, and for training 4 times!</p>
                            </div>
                        </div>

                        <h4>Cross-Validation Strategies</h4>
                        <pre><code class="language-python">from sklearn.model_selection import (
    KFold,           # Standard k-fold
    StratifiedKFold, # Maintains class distribution in each fold
    ShuffleSplit,    # Random train/test splits
    LeaveOneOut      # Each sample is test set once (n_splits = n_samples)
)
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris
import numpy as np

# Load data
iris = load_iris()
X, y = iris.data, iris.target

model = RandomForestClassifier(n_estimators=100, random_state=42)

# 1. Standard KFold - splits data sequentially
kf = KFold(n_splits=5, shuffle=False)
print("KFold (no shuffle):")
for i, (train_idx, test_idx) in enumerate(kf.split(X)):
    print(f"  Fold {i+1}: Train size={len(train_idx)}, Test size={len(test_idx)}")

# 2. Shuffled KFold - randomizes before splitting (recommended!)
kf_shuffle = KFold(n_splits=5, shuffle=True, random_state=42)
from sklearn.model_selection import cross_val_score
scores = cross_val_score(model, X, y, cv=kf_shuffle, scoring='accuracy')
print(f"\nShuffled KFold: {scores.mean():.3f} ± {scores.std():.3f}")

# 3. StratifiedKFold - maintains class proportions (best for classification!)
from sklearn.model_selection import StratifiedKFold
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores_strat = cross_val_score(model, X, y, cv=skf, scoring='accuracy')
print(f"Stratified KFold: {scores_strat.mean():.3f} ± {scores_strat.std():.3f}")

# Check class distribution in folds
print("\nClass distribution in each fold:")
for i, (train_idx, test_idx) in enumerate(skf.split(X, y)):
    test_classes = np.bincount(y[test_idx])
    print(f"  Fold {i+1} test set: {test_classes} (balanced!)")

# 4. LeaveOneOut - extreme CV, very slow but uses maximum data
from sklearn.model_selection import LeaveOneOut
loo = LeaveOneOut()
print(f"\nLeaveOneOut: {loo.get_n_splits(X)} splits (one per sample)")
# Too slow for large datasets, but useful for tiny datasets (< 100 samples)</code></pre>

                        <div class="highlight-box">
                            <i class="fas fa-star text-warning me-2"></i>
                            <strong>Best Practice for Classification:</strong> Always use <code>StratifiedKFold</code> instead of regular <code>KFold</code>. It ensures each fold has the same class distribution as the original dataset, preventing biased folds (e.g., a fold with mostly one class).
                        </div>

                        <h4>Cross-Validation Parameters Explained</h4>
                        <pre><code class="language-python">from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris

iris = load_iris()
X, y = iris.data, iris.target
model = RandomForestClassifier(n_estimators=100, random_state=42)

# cross_val_score(estimator, X, y, cv=5, scoring=None, n_jobs=None)
# Parameters:
#   estimator: model - The model to evaluate
#   X: array - Features
#   y: array - Target labels
#   cv: int or CV object - Number of folds or CV strategy (default: 5)
#   scoring: str - Metric to use ('accuracy', 'f1', 'roc_auc', etc.)
#   n_jobs: int - Number of parallel jobs (-1 = use all cores)

# Example: F1 score with 10-fold CV using all CPU cores
scores_f1 = cross_val_score(
    model, X, y, 
    cv=10,              # 10-fold cross-validation
    scoring='f1_macro', # F1 score (macro-averaged for multi-class)
    n_jobs=-1           # Use all available CPU cores
)
print(f"10-fold CV F1: {scores_f1.mean():.3f} ± {scores_f1.std():.3f}")
print(f"Individual fold scores: {scores_f1}")</code></pre>

                        <div class="experiment-card">
                            <div class="card-meta mb-2">
                                <span class="badge bg-crimson text-white">Common Cross-Validation Mistakes</span>
                            </div>
                            <div class="card-content">
                                <h4>Avoid These Pitfalls</h4>
                                <ul>
                                    <li><strong>❌ Fitting preprocessing on entire dataset before CV:</strong> Causes data leakage!
                                        <pre><code class="language-python"># WRONG - scaling before CV leaks info from test folds into training
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)  # Uses info from ALL data
scores = cross_val_score(model, X_scaled, y, cv=5)  # Test folds saw training data!</code></pre>
                                    </li>
                                    <li><strong>✅ Use pipelines to ensure preprocessing happens inside each fold:</strong>
                                        <pre><code class="language-python"># CORRECT - scaling happens separately for each fold
from sklearn.pipeline import Pipeline
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('model', RandomForestClassifier())
])
scores = cross_val_score(pipeline, X, y, cv=5)  # Scaling done per fold!</code></pre>
                                    </li>
                                    <li><strong>❌ Using KFold instead of StratifiedKFold for classification:</strong> Can create imbalanced folds</li>
                                    <li><strong>❌ Too many folds on small datasets:</strong> Each fold has too few test samples (high variance)</li>
                                    <li><strong>❌ Too few folds on large datasets:</strong> Wastes data and underestimates performance</li>
                                    <li><strong>❌ Not shuffling data before KFold:</strong> If data is ordered by class, folds will be biased</li>
                                </ul>
                            </div>
                        </div>

                        <div class="experiment-card">
                            <div class="card-meta mb-2">
                                <span class="badge bg-crimson text-white">Metric Selection</span>
                            </div>
                            <div class="card-content">
                                <ul>
                                    <li><strong>Accuracy:</strong> Good for balanced datasets</li>
                                    <li><strong>Precision:</strong> Important when false positives are costly (spam detection)</li>
                                    <li><strong>Recall:</strong> Critical when false negatives are costly (disease detection)</li>
                                    <li><strong>F1 Score:</strong> Harmonic mean of precision and recall—good for imbalanced data</li>
                                    <li><strong>ROC-AUC:</strong> Measures model's ability to distinguish classes (0.5 = random, 1.0 = perfect)</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <!-- Pipelines -->
                    <div id="pipelines" class="blog-content mt-5">
                        <h2><i class="fas fa-stream me-2 text-teal"></i>Pipelines & Automation</h2>
                        
                        <p>Pipelines chain preprocessing and modeling steps, preventing data leakage and simplifying code. They ensure transformations are applied consistently and in the correct order.</p>

                        <div class="highlight-box">
                            <i class="fas fa-lightbulb text-warning me-2"></i>
                            <strong>Why Pipelines?</strong><br>
                            <ul>
                                <li><strong>Prevent Data Leakage:</strong> Ensure test data never influences preprocessing (fit only on train)</li>
                                <li><strong>Reproducibility:</strong> Same transformations applied to train, validation, and test sets</li>
                                <li><strong>Cleaner Code:</strong> Replace dozens of lines with a single pipeline.fit()</li>
                                <li><strong>Easy Cross-Validation:</strong> Pass entire pipeline to cross_val_score()</li>
                                <li><strong>Hyperparameter Tuning:</strong> Tune preprocessing and model parameters together in GridSearchCV</li>
                            </ul>
                        </div>

                        <h3>Pipeline Constructor & Basic Usage</h3>
                        <p>The Pipeline constructor takes a list of (name, transformer) tuples. All steps except the last must be transformers (have fit/transform methods). The last step can be a transformer or estimator.</p>

                        <pre><code class="language-python">from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Load sample data
iris = load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create pipeline: list of (name, object) tuples
# Names are arbitrary but should be descriptive
pipeline = Pipeline([
    ('scaler', StandardScaler()),  # Step 1: Scale features
    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))  # Step 2: Classify
])

# Alternative syntax using make_pipeline (auto-generates names)
from sklearn.pipeline import make_pipeline
pipeline_auto = make_pipeline(
    StandardScaler(),  # Name: 'standardscaler'
    RandomForestClassifier(n_estimators=100, random_state=42)  # Name: 'randomforestclassifier'
)

# Fit entire pipeline: fits scaler on X_train, transforms X_train, then fits classifier
pipeline.fit(X_train, y_train)

# Predict: transforms X_test using fitted scaler, then predicts using fitted classifier
y_pred = pipeline.predict(X_test)
print(f"Pipeline accuracy: {pipeline.score(X_test, y_test):.3f}")

# Cross-validate entire pipeline (CORRECT way - no data leakage)
scores = cross_val_score(pipeline, X, y, cv=5)
print(f"CV mean: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})")</code></pre>

                        <h3>Pipeline Methods & Attributes</h3>
                        <p>Pipelines expose the same methods as the final estimator, plus additional pipeline-specific functionality:</p>

                        <pre><code class="language-python">from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Load data
iris = load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create multi-step pipeline
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('pca', PCA(n_components=2)),
    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
])

# Key Pipeline Methods:
# 1. fit(X, y) - Fit all transformers and final estimator
pipeline.fit(X_train, y_train)

# 2. predict(X) - Transform data through pipeline and predict
predictions = pipeline.predict(X_test)

# 3. predict_proba(X) - Get class probabilities (if final estimator supports it)
probabilities = pipeline.predict_proba(X_test)
print(f"Class probabilities shape: {probabilities.shape}")  # (n_samples, n_classes)

# 4. score(X, y) - Transform X and score using final estimator
accuracy = pipeline.score(X_test, y_test)
print(f"Test accuracy: {accuracy:.3f}")

# 5. fit_transform(X, y) - Fit pipeline and return transformed X (uses all steps)
X_transformed = Pipeline([
    ('scaler', StandardScaler()),
    ('pca', PCA(n_components=2))
]).fit_transform(X_train)
print(f"Transformed shape: {X_transformed.shape}")  # (120, 2) - reduced to 2 components

# 6. Access individual steps using named_steps attribute
print(f"\nStep names: {pipeline.named_steps.keys()}")
print(f"Scaler mean: {pipeline.named_steps['scaler'].mean_}")
print(f"PCA explained variance: {pipeline.named_steps['pca'].explained_variance_ratio_}")
print(f"Classifier feature importances: {pipeline.named_steps['classifier'].feature_importances_}")

# 7. Access steps by index
print(f"\nFirst step: {pipeline.steps[0]}")  # ('scaler', StandardScaler(...))
print(f"Second step name: {pipeline.steps[1][0]}")  # 'pca'
print(f"Last step (estimator): {pipeline[-1]}")  # RandomForestClassifier(...)

# 8. Get parameters of any step (useful for GridSearchCV)
print(f"\nAll pipeline parameters:")
print(pipeline.get_params().keys())</code></pre>

                        <h3>Modifying Pipeline Steps</h3>
                        <p>You can set parameters of individual steps using the <code>step_name__parameter</code> syntax:</p>

                        <pre><code class="language-python">from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.datasets import load_iris

# Load data
iris = load_iris()
X, y = iris.data, iris.target

# Create pipeline
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('pca', PCA(n_components=2)),
    ('svc', SVC(kernel='rbf'))
])

# Set parameters using double underscore notation
# Format: step_name__parameter_name
pipeline.set_params(
    pca__n_components=3,  # Change PCA components from 2 to 3
    svc__C=10.0,          # Set SVM regularization
    svc__kernel='linear'  # Change kernel from 'rbf' to 'linear'
)

print("Updated parameters:")
print(f"PCA components: {pipeline.named_steps['pca'].n_components}")
print(f"SVC kernel: {pipeline.named_steps['svc'].kernel}")
print(f"SVC C: {pipeline.named_steps['svc'].C}")

# This syntax is crucial for GridSearchCV
from sklearn.model_selection import GridSearchCV

param_grid = {
    'pca__n_components': [2, 3, 4],
    'svc__C': [0.1, 1, 10],
    'svc__kernel': ['linear', 'rbf']
}

grid = GridSearchCV(pipeline, param_grid, cv=5)
grid.fit(X, y)
print(f"\nBest parameters: {grid.best_params_}")
print(f"Best CV score: {grid.best_score_:.3f}")</code></pre>

                        <h3>ColumnTransformer for Mixed Data Types</h3>
                        <p>ColumnTransformer applies different preprocessing to different columns (e.g., scaling numeric, encoding categorical):</p>

                        <pre><code class="language-python">from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
import pandas as pd
import numpy as np

# Create sample mixed data
data = pd.DataFrame({
    'age': [25, 30, np.nan, 45, 50],
    'income': [50000, 60000, 55000, np.nan, 80000],
    'city': ['NY', 'LA', 'NY', 'SF', 'LA'],
    'gender': ['M', 'F', 'F', 'M', 'F'],
    'purchased': [0, 1, 0, 1, 1]
})

X = data.drop('purchased', axis=1)
y = data['purchased']

# Define column groups
numeric_features = ['age', 'income']
categorical_features = ['city', 'gender']

# Create preprocessing pipelines for each data type
numeric_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),  # Fill missing values
    ('scaler', StandardScaler())                    # Scale features
])

categorical_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),  # Fill missing categories
    ('onehot', OneHotEncoder(handle_unknown='ignore'))     # One-hot encode
])

# Combine transformers using ColumnTransformer
# transformers: list of (name, transformer, columns) tuples
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ],
    remainder='drop'  # Options: 'drop' (default), 'passthrough', or a transformer
)

# Create full pipeline with preprocessor and model
full_pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
])

# Fit and predict (single call handles everything!)
full_pipeline.fit(X, y)
predictions = full_pipeline.predict(X)
print(f"Predictions: {predictions}")

# Access transformed column names
# Note: OneHotEncoder creates multiple columns
preprocessor.fit(X)
print(f"\nTransformed feature names:")
print(preprocessor.get_feature_names_out())</code></pre>

                        <h3>ColumnTransformer with Remainder</h3>
                        <p>Control what happens to columns not specified in transformers:</p>

                        <pre><code class="language-python">from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
import pandas as pd
import numpy as np

# Sample data with extra columns
X = pd.DataFrame({
    'age': [25, 30, 35],
    'income': [50000, 60000, 70000],
    'city': ['NY', 'LA', 'SF'],
    'id': [101, 102, 103],  # Not used in transformers
    'timestamp': ['2024-01-01', '2024-01-02', '2024-01-03']  # Not used
})

# Option 1: Drop unspecified columns (default)
ct_drop = ColumnTransformer([
    ('scale', StandardScaler(), ['age', 'income']),
    ('encode', OneHotEncoder(), ['city'])
], remainder='drop')  # 'id' and 'timestamp' will be dropped

# Option 2: Pass through unspecified columns unchanged
ct_passthrough = ColumnTransformer([
    ('scale', StandardScaler(), ['age', 'income']),
    ('encode', OneHotEncoder(), ['city'])
], remainder='passthrough')  # 'id' and 'timestamp' kept as-is

# Option 3: Apply a transformer to remaining columns
ct_custom = ColumnTransformer([
    ('scale', StandardScaler(), ['age', 'income']),
    ('encode', OneHotEncoder(), ['city'])
], remainder=StandardScaler())  # Scale remaining numeric columns

X_drop = ct_drop.fit_transform(X)
X_pass = ct_passthrough.fit_transform(X)
X_custom = ct_custom.fit_transform(X)

print(f"Drop: {X_drop.shape}")  # (3, 5) - age, income, city_NY, city_LA, city_SF
print(f"Passthrough: {X_pass.shape}")  # (3, 7) - adds id and timestamp
print(f"Custom: {X_custom.shape}")  # (3, 7) - scales id and timestamp too</code></pre>

                        <h3>FeatureUnion: Parallel Feature Extraction</h3>
                        <p>FeatureUnion runs multiple transformers in parallel and concatenates results (useful for combining different feature extraction methods):</p>

                        <pre><code class="language-python">from sklearn.pipeline import FeatureUnion, Pipeline
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import numpy as np

# Load data
iris = load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create parallel feature transformations
feature_union = FeatureUnion([
    ('pca', PCA(n_components=2)),                    # Extract 2 principal components
    ('poly', PolynomialFeatures(degree=2, include_bias=False))  # Add polynomial features
])

# Combine with classifier in pipeline
pipeline = Pipeline([
    ('scaler', StandardScaler()),           # Scale original features
    ('features', feature_union),            # Create 2 PCA + polynomial features in parallel
    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
])

pipeline.fit(X_train, y_train)

# Check combined feature count
# Original: 4 features
# PCA: 2 features
# Polynomial (degree=2 on 4 features): 14 features (4 + 6 interactions + 4 squares)
# Total: 2 + 14 = 16 features
X_transformed = pipeline.named_steps['features'].transform(
    pipeline.named_steps['scaler'].transform(X_train[:1])
)
print(f"Original features: {X_train.shape[1]}")  # 4
print(f"After FeatureUnion: {X_transformed.shape[1]}")  # 16
print(f"Accuracy: {pipeline.score(X_test, y_test):.3f}")</code></pre>

                        <h3>Custom Transformers</h3>
                        <p>Create custom transformers by implementing fit() and transform() methods:</p>

                        <pre><code class="language-python">from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import numpy as np

# Custom transformer: Log transform features
class LogTransformer(BaseEstimator, TransformerMixin):
    """Apply log(x + 1) transformation to avoid log(0)"""
    
    def fit(self, X, y=None):
        # No fitting needed for log transform
        return self
    
    def transform(self, X):
        # Apply log(x + 1) element-wise
        return np.log1p(X)

# Custom transformer: Feature selector based on variance
class VarianceThreshold(BaseEstimator, TransformerMixin):
    """Remove low-variance features"""
    
    def __init__(self, threshold=0.1):
        self.threshold = threshold
    
    def fit(self, X, y=None):
        # Calculate variance of each feature
        self.variances_ = np.var(X, axis=0)
        # Store mask of features to keep
        self.mask_ = self.variances_ > self.threshold
        return self
    
    def transform(self, X):
        # Keep only high-variance features
        return X[:, self.mask_]

# Load data
iris = load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Use custom transformers in pipeline
pipeline = Pipeline([
    ('log', LogTransformer()),                        # Custom: Log transform
    ('var_filter', VarianceThreshold(threshold=0.5)), # Custom: Remove low-variance
    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
])

pipeline.fit(X_train, y_train)
print(f"Original features: {X_train.shape[1]}")  # 4
print(f"After variance filter: {np.sum(pipeline.named_steps['var_filter'].mask_)}")  # e.g., 3
print(f"Accuracy: {pipeline.score(X_test, y_test):.3f}")</code></pre>

                        <div class="experiment-card">
                            <div class="card-meta mb-2">
                                <span class="badge bg-teal text-white">Real-World Pipeline Example</span>
                            </div>
                            <div class="card-content">
                                <h4>Complete Production Pipeline</h4>
                                <p>A typical ML pipeline for mixed data with feature engineering, selection, and tuning:</p>
                                <pre><code class="language-python">from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
import pandas as pd
import numpy as np

# Sample dataset
np.random.seed(42)
data = pd.DataFrame({
    'age': np.random.randint(20, 70, 100),
    'income': np.random.randint(30000, 120000, 100),
    'city': np.random.choice(['NY', 'LA', 'SF', 'CHI'], 100),
    'education': np.random.choice(['HS', 'BS', 'MS', 'PhD'], 100),
    'target': np.random.randint(0, 2, 100)
})

X = data.drop('target', axis=1)
y = data['target']

# Define preprocessing for different column types
numeric_features = ['age', 'income']
categorical_features = ['city', 'education']

numeric_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
])

# Combine preprocessors
preprocessor = ColumnTransformer([
    ('num', numeric_transformer, numeric_features),
    ('cat', categorical_transformer, categorical_features)
])

# Full pipeline with feature selection and model
full_pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('feature_selection', SelectKBest(f_classif, k=5)),
    ('classifier', RandomForestClassifier(random_state=42))
])

# Hyperparameter grid for tuning
param_grid = {
    'feature_selection__k': [3, 5, 'all'],
    'classifier__n_estimators': [50, 100, 200],
    'classifier__max_depth': [5, 10, None]
}

# Grid search with cross-validation
grid_search = GridSearchCV(
    full_pipeline,
    param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

grid_search.fit(X, y)

print(f"Best parameters: {grid_search.best_params_}")
print(f"Best CV score: {grid_search.best_score_:.3f}")
print(f"\nPipeline steps:")
for name, step in grid_search.best_estimator_.named_steps.items():
    print(f"  {name}: {step}")</code></pre>
                            </div>
                        </div>

                        <div class="highlight-box mt-4">
                            <i class="fas fa-check-circle text-success me-2"></i>
                            <strong>Pipeline Best Practices:</strong><br>
                            <ul>
                                <li><strong>Always fit on training data only:</strong> Never fit transformers on test data</li>
                                <li><strong>Use pipelines with cross-validation:</strong> Prevents data leakage across folds</li>
                                <li><strong>Name steps descriptively:</strong> Makes debugging and parameter access easier</li>
                                <li><strong>Combine with GridSearchCV:</strong> Tune preprocessing and model together</li>
                                <li><strong>Save entire pipeline:</strong> Use joblib.dump(pipeline, 'model.pkl') for deployment</li>
                                <li><strong>Custom transformers inherit BaseEstimator + TransformerMixin:</strong> Ensures compatibility</li>
                            </ul>
                        </div>
                    </div>

                    <!-- Tuning -->
                    <div id="tuning" class="blog-content mt-5">
                        <h2><i class="fas fa-sliders-h me-2 text-teal"></i>Hyperparameter Tuning</h2>
                        
                        <p>Hyperparameters control model behavior (learning rate, tree depth, etc.). Tuning finds optimal values.</p>

                        <h3>Grid Search</h3>
                        <pre><code class="language-python">from sklearn.model_selection import GridSearchCV

# Define parameter grid
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

# Grid search with cross-validation
grid = GridSearchCV(
    RandomForestClassifier(random_state=42),
    param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1  # Use all CPU cores
)

grid.fit(X_train, y_train)

print(f"Best params: {grid.best_params_}")
print(f"Best CV score: {grid.best_score_:.3f}")
print(f"Test score: {grid.score(X_test, y_test):.3f}")</code></pre>

                        <h3>Random Search (Faster)</h3>
                        <pre><code class="language-python">from sklearn.model_selection import RandomizedSearchCV

# Random search samples random combinations
param_dist = {
    'n_estimators': [50, 100, 150, 200, 250, 300],
    'max_depth': [None, 5, 10, 15, 20, 25, 30],
    'min_samples_split': [2, 5, 10, 15]
}

random = RandomizedSearchCV(
    RandomForestClassifier(random_state=42),
    param_dist,
    n_iter=20,  # Try 20 random combinations
    cv=5,
    random_state=42,
    n_jobs=-1
)

random.fit(X_train, y_train)
print(f"Best params: {random.best_params_}")</code></pre>

                        <div class="highlight-box">
                            <i class="fas fa-bolt"></i>
                            <strong>Grid vs Random:</strong> Grid Search is exhaustive but slow. Random Search samples randomly—often finds good parameters 10x faster. For large grids, use Random Search first, then Grid Search to fine-tune.
                        </div>
                    </div>


                    <!-- Complete Workflow Examples with Datasets -->
                    <div id="datasets" class="blog-content mt-5">
                        <h2><i class="fas fa-project-diagram me-2 text-teal"></i>Complete Workflow Examples with Datasets</h2>
                        
                        <p>Now that you've learned preprocessing, classification, regression, clustering, evaluation, pipelines, and hyperparameter tuning, let's see how everything fits together. This section demonstrates complete end-to-end ML workflows using Scikit-learn's built-in datasets.</p>

                        <div class="highlight-box">
                            <i class="fas fa-graduation-cap"></i>
                            <strong>What You'll See:</strong> Each example below walks through the entire process—from loading data and exploration, through preprocessing and model selection, to evaluation and visualization. These are realistic workflows you can adapt for your own projects.
                        </div>

                        <div class="experiment-card">
                            <div class="card-meta mb-2">
                                <span class="badge bg-teal text-white">Datasets Covered</span>
                            </div>
                            <div class="card-content">
                                <ul>
                                    <li><strong>Classification:</strong> Iris, Wine, Digits, Breast Cancer—demonstrating Logistic Regression, Random Forest, SVM, and evaluation</li>
                                    <li><strong>Regression:</strong> Diabetes, California Housing—demonstrating Linear Regression, Ridge, feature importance</li>
                                    <li><strong>Complete Pipeline:</strong> Every example shows data splitting, preprocessing, training, evaluation, and visualization</li>
                                </ul>
                            </div>
                        </div>

                        <!-- Iris Dataset -->
                        <h3 id="iris-dataset"><i class="fas fa-flower me-2 text-crimson"></i>1. Iris Dataset (Multi-class Classification)</h3>
                        
                        <div class="highlight-box">
                            <i class="fas fa-info-circle"></i>
                            <strong>About Iris:</strong> Classic dataset with 150 samples of iris flowers. Features include sepal length, sepal width, petal length, and petal width. Target: 3 species (setosa, versicolor, virginica). Perfect for learning classification.
                        </div>

                        <pre><code class="language-python"># Import necessary libraries
import numpy as np  # For numerical operations
import pandas as pd  # For data manipulation
import matplotlib.pyplot as plt  # For plotting
from sklearn.datasets import load_iris  # Load built-in Iris dataset
from sklearn.model_selection import train_test_split, cross_val_score  # For data splitting and validation
from sklearn.preprocessing import StandardScaler  # For feature scaling
from sklearn.linear_model import LogisticRegression  # Linear classifier
from sklearn.ensemble import RandomForestClassifier  # Tree-based ensemble classifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # Evaluation metrics
import seaborn as sns  # For advanced visualization

# 1. LOAD DATA
# load_iris() returns a Bunch object (dict-like) containing:
#   - data: feature matrix (150 samples x 4 features)
#   - target: class labels (0, 1, 2 for setosa, versicolor, virginica)
#   - feature_names: names of the 4 features
#   - target_names: names of the 3 species
iris = load_iris()
X, y = iris.data, iris.target  # X = features (150x4), y = labels (150,)

# Display dataset information
print(f"Dataset shape: {X.shape}")  # Output: (150, 4) - 150 samples, 4 features
print(f"Feature names: {iris.feature_names}")  # sepal length/width, petal length/width
print(f"Target names: {iris.target_names}")  # setosa, versicolor, virginica
print(f"Sample distribution: {np.bincount(y)}")  # Count samples per class - Output: [50 50 50] (balanced)</code></pre>

                        <pre><code class="language-python"># Import libraries for data exploration
import pandas as pd  # For DataFrame operations
import matplotlib.pyplot as plt  # For visualization
import seaborn as sns  # For enhanced plots
from sklearn.datasets import load_iris  # Load dataset

# 2. EXPLORE DATA
iris = load_iris()
X, y = iris.data, iris.target

# Create DataFrame for easy exploration and analysis
# pd.DataFrame() converts NumPy array to tabular format with column names
df = pd.DataFrame(X, columns=iris.feature_names)
# Add species names by mapping numeric labels (0,1,2) to text labels
df['species'] = iris.target_names[y]  # e.g., 0 -> 'setosa'

# Display first 5 rows to see data structure
print(df.head())  # Shows sample data with feature values and species
# Statistical summary: count, mean, std, min, 25%, 50%, 75%, max
print(df.describe())  # Helps identify feature ranges and distributions
# Count samples per species - should be 50 each (balanced dataset)
print(df['species'].value_counts())

# Visualize feature distributions to understand data patterns
plt.figure(figsize=(12, 4))  # Create figure 12 inches wide, 4 tall
for i in range(4):  # Loop through 4 features
    plt.subplot(1, 4, i+1)  # Create 1 row, 4 columns of subplots
    # Create overlapping histograms for each species
    # X[y==0, i] gets feature i values for species 0, etc.
    plt.hist([X[y==0, i], X[y==1, i], X[y==2, i]], 
             label=iris.target_names, alpha=0.7)  # alpha=0.7 for transparency
    plt.xlabel(iris.feature_names[i])  # Label x-axis with feature name
    plt.ylabel('Frequency')  # Count of samples in each bin
    plt.legend()  # Show which color represents which species
plt.tight_layout()  # Adjust spacing to prevent overlap
plt.show()  # Display the plot</code></pre>

                        <pre><code class="language-python"># Import required libraries
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split  # For splitting data
from sklearn.preprocessing import StandardScaler  # For feature normalization
from sklearn.linear_model import LogisticRegression  # Linear classification model
from sklearn.ensemble import RandomForestClassifier  # Ensemble tree model
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# 3. SPLIT DATA into training and testing sets
iris = load_iris()
X, y = iris.data, iris.target

# train_test_split() randomly divides data into train/test sets
# test_size=0.2: Use 20% for testing, 80% for training
# random_state=42: Set seed for reproducibility (same split every time)
# stratify=y: Maintain class proportions in both sets (33% of each species)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Training set: {X_train.shape}")  # (120, 4) - 80% of 150 samples
print(f"Test set: {X_test.shape}")  # (30, 4) - 20% of 150 samples

# 4. PREPROCESS: Scale features to mean=0, std=1
# Scaling is crucial for distance-based algorithms (e.g., Logistic Regression, SVM)
scaler = StandardScaler()  # Create scaler object
# fit_transform(): Learn mean/std from training data AND transform it
X_train_scaled = scaler.fit_transform(X_train)
# transform(): Apply same scaling (using training mean/std) to test data
# NEVER fit on test data - this would cause data leakage!
X_test_scaled = scaler.transform(X_test)

# 5. TRAIN MODELS on the training data
# Logistic Regression (linear decision boundaries)
# max_iter=200: Maximum optimization iterations
# random_state=42: For reproducibility in stochastic processes
log_reg = LogisticRegression(max_iter=200, random_state=42)
log_reg.fit(X_train_scaled, y_train)  # Learn weights from scaled training data

# Random Forest (ensemble of decision trees)
# n_estimators=100: Build 100 decision trees and average their predictions
# Tree-based models are scale-invariant (don't need scaled features)
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)  # Train on original (unscaled) data

# 6. EVALUATE models on test data (unseen data)
# predict(): Generate predictions for test samples
y_pred_lr = log_reg.predict(X_test_scaled)  # Use scaled test data
y_pred_rf = rf.predict(X_test)  # Use original test data

# accuracy_score(): Fraction of correct predictions
print(f"\nLogistic Regression Accuracy: {accuracy_score(y_test, y_pred_lr):.3f}")
print(f"Random Forest Accuracy: {accuracy_score(y_test, y_pred_rf):.3f}")

# classification_report(): Precision, recall, F1-score for each class
# Provides detailed per-class performance metrics
print("\nLogistic Regression Classification Report:")
print(classification_report(y_test, y_pred_lr, target_names=iris.target_names))</code></pre>

                        <pre><code class="language-python">import matplotlib.pyplot as plt
import seaborn as sns  # Advanced visualization library built on matplotlib
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix  # For error analysis

# 7. VISUALIZE RESULTS with a confusion matrix
iris = load_iris()
X, y = iris.data, iris.target
# Split data with same parameters to ensure reproducibility
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Random Forest model
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)  # Learn from training data
y_pred_rf = rf.predict(X_test)  # Make predictions on test data

# confusion_matrix(): Create matrix showing actual vs predicted classes
# Rows = actual classes, Columns = predicted classes
# Diagonal elements = correct predictions, off-diagonal = errors
cm = confusion_matrix(y_test, y_pred_rf)

# Visualize confusion matrix as a heatmap
plt.figure(figsize=(8, 6))  # Set figure size
# sns.heatmap(): Display matrix with color-coded cells
# annot=True: Show numbers in each cell
# fmt='d': Format numbers as integers (not decimals)
# cmap='Blues': Use blue color scheme (darker = higher values)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=iris.target_names,  # Label columns with species names
            yticklabels=iris.target_names)  # Label rows with species names
plt.xlabel('Predicted')  # What the model predicted
plt.ylabel('Actual')  # What the true class was
plt.title('Iris Classification Confusion Matrix')  # Descriptive title
plt.show()  # Display the plot

# How to read: If cell (setosa, versicolor) = 2, means 2 setosa samples
# were incorrectly classified as versicolor</code></pre>

                        <pre><code class="language-python">import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
import numpy as np

# 8. FEATURE IMPORTANCE - Which features are most useful for predictions?
iris = load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Random Forest (tree-based models provide feature importance)
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# feature_importances_: Array of importance scores (sum to 1.0)
# Higher score = feature contributes more to accurate predictions
# Based on how much each feature decreases impurity (Gini) across trees
importances = rf.feature_importances_

# np.argsort(): Get indices that would sort array in ascending order
# [::-1] reverses to get descending order (most important first)
indices = np.argsort(importances)[::-1]

# Create bar plot of feature importance
plt.figure(figsize=(10, 6))
# Plot bars in order of importance
plt.bar(range(X.shape[1]), importances[indices])
# Label x-axis with feature names in sorted order, rotated 45° for readability
plt.xticks(range(X.shape[1]), [iris.feature_names[i] for i in indices], rotation=45)
plt.xlabel('Feature')  # X-axis label
plt.ylabel('Importance')  # Y-axis label (0 to ~0.5 for Iris dataset)
plt.title('Feature Importance for Iris Classification')
plt.tight_layout()  # Prevent label cutoff
plt.show()

# Print ranked list of features with importance scores
print("Feature ranking:")
for i in range(X.shape[1]):
    print(f"{i+1}. {iris.feature_names[indices[i]]}: {importances[indices[i]]:.3f}")
# Typically petal width and petal length are most important for Iris</code></pre>

                        <!-- Wine Dataset -->
                        <h3 id="wine-dataset" class="mt-5"><i class="fas fa-wine-glass me-2 text-crimson"></i>2. Wine Dataset (Multi-class Classification)</h3>
                        
                        <div class="highlight-box">
                            <i class="fas fa-info-circle"></i>
                            <strong>About Wine:</strong> Chemical analysis of 178 wine samples from Italy. 13 features (alcohol, acidity, phenols, etc.). Target: 3 wine types. Great for classification with multiple continuous features.
                        </div>

                        <pre><code class="language-python"># Import necessary libraries
from sklearn.datasets import load_wine  # Wine quality dataset
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler  # For feature scaling
from sklearn.svm import SVC  # Support Vector Machine classifier
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd  # For data manipulation
import numpy as np  # For numerical operations

# 1. LOAD & EXPLORE
# load_wine() returns chemical analysis of 178 wine samples
# Features include alcohol content, acidity, phenols, color intensity, etc.
wine = load_wine()
X, y = wine.data, wine.target  # X = 13 chemical features, y = wine class (0, 1, 2)

print(f"Dataset shape: {X.shape}")  # (178, 13) - 178 samples, 13 features
print(f"Features: {len(wine.feature_names)}")  # 13 chemical properties
print(f"Classes: {wine.target_names}")  # class_0, class_1, class_2 (wine cultivars)
print(f"Class distribution: {np.bincount(y)}")  # Samples per class - may be imbalanced

# Create DataFrame for easier exploration
df_wine = pd.DataFrame(X, columns=wine.feature_names)
df_wine['wine_type'] = y  # Add target column

print("\nFirst few rows:")  # Preview data structure
print(df_wine.head())
print("\nStatistics:")  # Mean, std, min, max for each feature
print(df_wine.describe())  # Note: features have different scales (0.74 to 1680)</code></pre>

                        <pre><code class="language-python"># Import required libraries
from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler  # For feature normalization
from sklearn.svm import SVC  # Support Vector Machine
from sklearn.ensemble import GradientBoostingClassifier  # Boosting ensemble
from sklearn.metrics import accuracy_score, classification_report
import numpy as np

# 2. SPLIT & PREPROCESS data
wine = load_wine()
X, y = wine.data, wine.target

# train_test_split(): Randomly divide data
# test_size=0.25: Use 25% for testing (higher than standard 20% due to small dataset)
# random_state=42: Reproducible split
# stratify=y: Maintain class proportions in train/test sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y
)

# Scale features to mean=0, std=1 (critical for SVM performance)
# Wine features have vastly different scales (alcohol ~10-15, proline ~200-1600)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)  # Learn scaling from training data
X_test_scaled = scaler.transform(X_test)  # Apply same scaling to test data

# 3. TRAIN MULTIPLE MODELS for comparison
# SVM with RBF (Radial Basis Function) kernel
# kernel='rbf': Non-linear decision boundaries
# C=10: High regularization penalty (tighter fit to training data)
# gamma='scale': Kernel coefficient = 1 / (n_features * X.var())
#   See: https://scikit-learn.org/stable/modules/svm.html
svm = SVC(kernel='rbf', C=10, gamma='scale', random_state=42)
svm.fit(X_train_scaled, y_train)  # Train on scaled features

# Gradient Boosting: Sequential ensemble of decision trees
# n_estimators=100: Build 100 trees (each learns from previous tree's errors)
#   See: https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting
# Tree models don't need scaled features (they only use rank order)
gb = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb.fit(X_train, y_train)  # Train on original unscaled data

# 4. EVALUATE both models on test set
y_pred_svm = svm.predict(X_test_scaled)  # SVM needs scaled features
y_pred_gb = gb.predict(X_test)  # GB uses original features

# Compare accuracy scores
print(f"SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.3f}")
print(f"Gradient Boosting Accuracy: {accuracy_score(y_test, y_pred_gb):.3f}")

# Detailed per-class metrics (precision, recall, F1-score)
print("\nGradient Boosting Report:")
print(classification_report(y_test, y_pred_gb, target_names=wine.target_names))</code></pre>

                        <pre><code class="language-python"># Import libraries for cross-validation workflow
from sklearn.datasets import load_wine
from sklearn.model_selection import cross_val_score  # For k-fold cross-validation
from sklearn.preprocessing import StandardScaler  # Feature scaling
from sklearn.svm import SVC  # Classifier
from sklearn.pipeline import Pipeline  # Chain preprocessing + model together
import numpy as np

# 5. CROSS-VALIDATION with Pipeline
# Pipeline ensures scaling is done correctly within each CV fold
# This prevents data leakage (test data influencing training)
wine = load_wine()
X, y = wine.data, wine.target

# Create Pipeline: preprocessing step + model step
# Pipeline chains operations: data flows scaler → SVM
# See: https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html
pipeline = Pipeline([
    ('scaler', StandardScaler()),  # Step 1: Scale features
    ('svm', SVC(kernel='rbf', C=10, random_state=42))  # Step 2: Train SVM
])

# cross_val_score(): Perform k-fold cross-validation
# cv=5: Split data into 5 folds
#   - Train on 4 folds, test on 1 fold
#   - Repeat 5 times (each fold used as test once)
#   - Returns 5 accuracy scores
# scoring='accuracy': Metric to evaluate (could be 'f1', 'precision', etc.)
# Pipeline ensures each fold is scaled independently (no data leakage)
# See: https://scikit-learn.org/stable/modules/cross_validation.html
scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')

# Display results
print(f"Cross-validation scores: {scores}")  # 5 individual fold scores
# Mean ± 2*std gives 95% confidence interval estimate
print(f"Mean accuracy: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})")
# Example output: "Mean accuracy: 0.978 (+/- 0.034)"</code></pre>

                        <!-- Digits Dataset -->
                        <h3 id="digits-dataset" class="mt-5"><i class="fas fa-hashtag me-2 text-crimson"></i>3. Digits Dataset (Image Classification)</h3>
                        
                        <div class="highlight-box">
                            <i class="fas fa-info-circle"></i>
                            <strong>About Digits:</strong> 1,797 images of handwritten digits (0-9), each 8x8 pixels (64 features). Perfect for learning image classification and dimensionality reduction techniques.
                        </div>

                        <pre><code class="language-python"># Import libraries for visualization and data loading
import matplotlib.pyplot as plt  # For plotting
from sklearn.datasets import load_digits  # Handwritten digits dataset
import numpy as np  # For numerical operations

# 1. LOAD & VISUALIZE handwritten digits
# load_digits() returns 1,797 images of digits 0-9
# Each image is 8x8 pixels, flattened to 64-dimensional vector
digits = load_digits()
X, y = digits.data, digits.target  # X = 64 features (pixel intensities), y = digit label (0-9)

print(f"Dataset shape: {X.shape}")  # (1797, 64) - 1797 images, 64 pixels each
print(f"Image shape: {digits.images.shape}")  # (1797, 8, 8) - original 2D format
print(f"Classes: 0-9 (10 classes)")  # 10 possible digit labels
print(f"Samples per class: {np.bincount(y)}")  # Distribution (~180 samples per digit)

# Visualize sample digits to understand the data
# Create 2 rows × 5 columns = 10 subplots
fig, axes = plt.subplots(2, 5, figsize=(12, 5))
for i, ax in enumerate(axes.flat):  # axes.flat iterates over all subplots
    # imshow(): Display 2D array as image
    # cmap='gray': Use grayscale colormap (0=black, 16=white)
    ax.imshow(digits.images[i], cmap='gray')
    ax.set_title(f"Label: {digits.target[i]}")  # Show true digit label
    ax.axis('off')  # Hide axis ticks and labels
plt.tight_layout()  # Adjust spacing between subplots
plt.show()  # Display the plot</code></pre>

                        <pre><code class="language-python"># Import libraries for neural network training
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler  # For feature normalization
from sklearn.neural_network import MLPClassifier  # Multi-Layer Perceptron (neural network)
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# 2. SPLIT & TRAIN with neural network
digits = load_digits()
X, y = digits.data, digits.target  # X = 64 pixel intensities, y = digit label (0-9)

# Split data: 80% training, 20% testing
# stratify=y: Ensure balanced digit distribution in both sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Scale features to improve neural network convergence
# Neural networks learn faster when features are standardized
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)  # Fit and transform training data
X_test_scaled = scaler.transform(X_test)  # Transform test data (using training stats)

# MLPClassifier: Multi-Layer Perceptron (feedforward neural network)
# hidden_layer_sizes=(100, 50): Architecture with 2 hidden layers
#   - Layer 1: 100 neurons (fully connected to 64 input pixels)
#   - Layer 2: 50 neurons (fully connected to Layer 1)
#   - Output: 10 neurons (one per digit class)
# max_iter=500: Maximum training epochs (iterations through dataset)
# See: https://scikit-learn.org/stable/modules/neural_networks_supervised.html
mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)
mlp.fit(X_train_scaled, y_train)  # Train network using backpropagation

# Predict digit labels for test images
y_pred = mlp.predict(X_test_scaled)

# Evaluate performance
print(f"Accuracy: {accuracy_score(y_test, y_pred):.3f}")  # Overall correctness
print("\nClassification Report:")  # Per-digit precision, recall, F1-score
print(classification_report(y_test, y_pred))  # Shows performance for each digit 0-9</code></pre>

                        <pre><code class="language-python"># Import visualization libraries
import matplotlib.pyplot as plt
import seaborn as sns  # For advanced heatmaps
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import confusion_matrix  # For error pattern analysis

# 3. CONFUSION MATRIX VISUALIZATION - See where model makes mistakes
digits = load_digits()
X, y = digits.data, digits.target

# Reproduce same train/test split as previous example
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train neural network
mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)
mlp.fit(X_train_scaled, y_train)
y_pred = mlp.predict(X_test_scaled)  # Get predictions

# confusion_matrix(): 10x10 matrix showing actual vs predicted digits
# Rows = true digit, Columns = predicted digit
# Diagonal = correct predictions, off-diagonal = errors
cm = confusion_matrix(y_test, y_pred)

# Visualize as heatmap
plt.figure(figsize=(10, 8))  # Large figure for 10x10 matrix
# annot=True: Show count in each cell
# fmt='d': Display as integers
# cmap='Blues': Blue color scheme (darker = more samples)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted Digit')  # What model predicted
plt.ylabel('True Digit')  # Actual digit in test set
plt.title('Digit Classification Confusion Matrix')
plt.show()

# How to read: If cell (8, 3) = 5, means 5 images of digit 8 were
# incorrectly classified as digit 3 (common mistake due to similar shapes)</code></pre>

                        <pre><code class="language-python"># Import visualization libraries
import matplotlib.pyplot as plt
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
import numpy as np

# 4. VISUALIZE PREDICTIONS - See model's predictions on actual images
digits = load_digits()
X, y = digits.data, digits.target

# Reproduce same train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train neural network
mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)
mlp.fit(X_train_scaled, y_train)
y_pred = mlp.predict(X_test_scaled)  # Predict all test samples

# Show first 18 test images (3 rows × 6 columns) with predictions
fig, axes = plt.subplots(3, 6, figsize=(15, 8))
for i, ax in enumerate(axes.flat):  # Loop through 18 subplots
    # X_test[i] is 64-element array; reshape to 8x8 for display
    ax.imshow(X_test[i].reshape(8, 8), cmap='gray')
    # Show true label vs predicted label
    ax.set_title(f"True: {y_test[i]}\nPred: {y_pred[i]}")
    ax.axis('off')  # Hide axis ticks
    
    # Highlight incorrect predictions in red for easy spotting
    if y_test[i] != y_pred[i]:
        # Make incorrect predictions stand out visually
        ax.set_title(f"True: {y_test[i]}\nPred: {y_pred[i]}", 
                    color='red', fontweight='bold')
plt.tight_layout()  # Prevent title overlap
plt.show()

# This visualization helps identify which digits the model confuses
# e.g., 8 vs 3, 5 vs 3, 1 vs 7 are common errors</code></pre>

                        <!-- Breast Cancer Dataset -->
                        <h3 id="breast-cancer-dataset" class="mt-5"><i class="fas fa-heartbeat me-2 text-crimson"></i>4. Breast Cancer Dataset (Binary Classification)</h3>
                        
                        <div class="highlight-box">
                            <i class="fas fa-info-circle"></i>
                            <strong>About Breast Cancer:</strong> 569 samples with 30 features computed from breast mass images. Binary classification: malignant (0) or benign (1). Real medical data—demonstrates importance of precision/recall.
                        </div>

                        <pre><code class="language-python"># Import libraries for medical dataset analysis
from sklearn.datasets import load_breast_cancer  # Real medical diagnostic data
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd  # For data manipulation
import numpy as np  # For numerical operations

# 1. LOAD & EXPLORE breast cancer diagnostic data
# This dataset contains features computed from digitized images of breast mass
# Binary classification: malignant (cancerous) vs benign (non-cancerous)
cancer = load_breast_cancer()
X, y = cancer.data, cancer.target  # X = 30 features, y = diagnosis (0=malignant, 1=benign)

print(f"Dataset shape: {X.shape}")  # (569, 30) - 569 samples, 30 features
print(f"Features: {cancer.feature_names[:5]}... (30 total)")  # radius, texture, perimeter, area, smoothness, etc.
print(f"Classes: {cancer.target_names}")  # ['malignant' 'benign']
print(f"Class distribution: {np.bincount(y)}")  # Count of each class
print(f"Malignant (0): {(y==0).sum()}, Benign (1): {(y==1).sum()}")  # Show imbalance if any

# Create DataFrame for statistical analysis
# Features include mean, std error, and worst values for 10 measurements
df_cancer = pd.DataFrame(X, columns=cancer.feature_names)
print("\nFeature statistics:")  # Mean, std, min, max for all features
print(df_cancer.describe())  # Note: Features have very different scales (0.1 to 3000)</code></pre>

                        <pre><code class="language-python"># Import libraries for medical classification
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression  # Linear classifier
from sklearn.ensemble import RandomForestClassifier  # Tree ensemble
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report
import numpy as np

# 2. SPLIT, SCALE & TRAIN multiple models
cancer = load_breast_cancer()
X, y = cancer.data, cancer.target

# Split: 80% train, 20% test, maintaining class balance
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Scale features (critical for logistic regression)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train Logistic Regression
# max_iter=10000: High iteration limit (default 100 may not converge)
# See: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
lr = LogisticRegression(max_iter=10000, random_state=42)
lr.fit(X_train_scaled, y_train)  # Train on scaled data

# Train Random Forest (comparison model)
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)  # Trees don't need scaling

# 3. EVALUATE with MULTIPLE METRICS (critical for medical applications)
# Medical data requires careful evaluation beyond just accuracy
y_pred_lr = lr.predict(X_test_scaled)  # Binary predictions (0 or 1)
y_pred_rf = rf.predict(X_test)
y_proba_lr = lr.predict_proba(X_test_scaled)[:, 1]  # Probability of benign (class 1)

print("Logistic Regression:")
print(f"  Accuracy: {accuracy_score(y_test, y_pred_lr):.3f}")  # Overall correctness
print(f"  Precision: {precision_score(y_test, y_pred_lr):.3f}")  # Of predicted benign, how many are actually benign?
print(f"  Recall: {recall_score(y_test, y_pred_lr):.3f}")  # Of actual benign, how many did we catch?
print(f"  F1 Score: {f1_score(y_test, y_pred_lr):.3f}")  # Harmonic mean of precision & recall
print(f"  ROC-AUC: {roc_auc_score(y_test, y_proba_lr):.3f}")  # Area under ROC curve (0.5-1.0)

print("\nRandom Forest:")
print(f"  Accuracy: {accuracy_score(y_test, y_pred_rf):.3f}")
print(f"  Precision: {precision_score(y_test, y_pred_rf):.3f}")
print(f"  Recall: {recall_score(y_test, y_pred_rf):.3f}")  # High recall = fewer missed cancers
print(f"  F1 Score: {f1_score(y_test, y_pred_rf):.3f}")

# For medical diagnosis: High recall is often prioritized (don't miss cancers)
# High precision avoids false alarms (unnecessary biopsies)</code></pre>

                        <pre><code class="language-python"># Import libraries for ROC curve analysis
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_curve, roc_auc_score  # For ROC analysis

# 4. ROC CURVE - Visualize classifier performance across thresholds
# ROC = Receiver Operating Characteristic
# Shows trade-off between True Positive Rate and False Positive Rate
cancer = load_breast_cancer()
X, y = cancer.data, cancer.target

# Reproduce same train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Train logistic regression
lr = LogisticRegression(max_iter=10000, random_state=42)
lr.fit(X_train_scaled, y_train)
# Get probability predictions (not binary 0/1)
y_proba = lr.predict_proba(X_test_scaled)[:, 1]  # Probability of benign (class 1)

# roc_curve(): Calculate TPR and FPR at different classification thresholds
# fpr: False Positive Rate (X-axis) - How many benign predicted as malignant?
# tpr: True Positive Rate (Y-axis) - How many benign correctly identified?
# thresholds: Classification thresholds (0.0 to 1.0)
# See: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html
fpr, tpr, thresholds = roc_curve(y_test, y_proba)

# roc_auc_score(): Area Under ROC Curve
# 0.5 = random classifier, 1.0 = perfect classifier
auc = roc_auc_score(y_test, y_proba)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.3f})', linewidth=2)
plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')  # Diagonal line (AUC=0.5)
plt.xlabel('False Positive Rate')  # More FP = more false alarms
plt.ylabel('True Positive Rate')  # More TP = fewer missed diagnoses
plt.title('ROC Curve - Breast Cancer Classification')
plt.legend()
plt.grid(alpha=0.3)
plt.show()

# Ideal curve: Hugs top-left corner (high TPR, low FPR)
# Higher AUC = better overall classifier performance</code></pre>

                        <!-- Diabetes Dataset -->
                        <h3 id="diabetes-dataset" class="mt-5"><i class="fas fa-medkit me-2 text-crimson"></i>5. Diabetes Dataset (Regression)</h3>
                        
                        <div class="highlight-box">
                            <i class="fas fa-info-circle"></i>
                            <strong>About Diabetes:</strong> 442 samples with 10 baseline features (age, BMI, blood pressure, etc.). Target: quantitative measure of disease progression one year after baseline. Great for learning regression.
                        </div>

                        <pre><code class="language-python"># Import libraries for regression analysis
from sklearn.datasets import load_diabetes  # Medical progression prediction dataset
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge, Lasso  # Linear models with regularization
from sklearn.ensemble import RandomForestRegressor  # Tree ensemble for regression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import pandas as pd  # For data analysis
import numpy as np

# 1. LOAD & EXPLORE diabetes progression dataset
# This dataset contains baseline patient data and disease progression after 1 year
# Target is quantitative measure of disease progression (continuous value, not classification)
diabetes = load_diabetes()
X, y = diabetes.data, diabetes.target  # X = 10 features (age, BMI, BP, etc.), y = progression score

print(f"Dataset shape: {X.shape}")  # (442, 10) - 442 patients, 10 baseline measurements
print(f"Features: {diabetes.feature_names}")  # age, sex, bmi, bp, s1-s6 (blood serum measurements)
print(f"Target statistics: min={y.min():.1f}, max={y.max():.1f}, mean={y.mean():.1f}")
# Target values range from 25 to 346 (higher = worse progression)

# Create DataFrame for correlation analysis
df_diabetes = pd.DataFrame(X, columns=diabetes.feature_names)
df_diabetes['progression'] = y  # Add target column

# Identify which features correlate most with disease progression
print("\nCorrelation with target:")  # Positive = feature increases with disease progression
print(df_diabetes.corr()['progression'].sort_values(ascending=False))
# Typically: bmi (body mass index), s5 (serum triglycerides) are top predictors</code></pre>

                        <pre><code class="language-python"># Import regression models and metrics
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge, Lasso  # Linear models
from sklearn.ensemble import RandomForestRegressor  # Non-linear ensemble
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import numpy as np

# 2. SPLIT & TRAIN MULTIPLE REGRESSION MODELS
diabetes = load_diabetes()
X, y = diabetes.data, diabetes.target

# Split data (no stratification needed for regression)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Linear Regression - no regularization (baseline model)
# See: https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares
lr = LinearRegression()
lr.fit(X_train, y_train)  # Learns weights for each feature

# Ridge Regression - L2 regularization (penalizes large coefficients)
# alpha=1.0: Regularization strength (higher = more penalty = simpler model)
# Good when features are correlated (reduces overfitting)
# See: https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression
ridge = Ridge(alpha=1.0)
ridge.fit(X_train, y_train)

# Lasso Regression - L1 regularization (can zero out features)
# alpha=0.5: Regularization strength
# Performs automatic feature selection (sets some coefficients to exactly 0)
# See: https://scikit-learn.org/stable/modules/linear_model.html#lasso
lasso = Lasso(alpha=0.5)
lasso.fit(X_train, y_train)

# Random Forest Regressor - ensemble of decision trees
# n_estimators=100: Build 100 trees and average predictions
# Captures non-linear relationships between features and target
rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)
rf_reg.fit(X_train, y_train)

# 3. EVALUATE with regression metrics
models = {
    'Linear Regression': lr,
    'Ridge': ridge,
    'Lasso': lasso,
    'Random Forest': rf_reg
}

for name, model in models.items():
    y_pred = model.predict(X_test)
    # RMSE: Root Mean Squared Error (same units as target, penalizes large errors)
    rmse = mean_squared_error(y_test, y_pred, squared=False)
    # R² Score: Coefficient of determination (0-1, higher = better fit)
    #   1.0 = perfect predictions, 0 = model as good as mean baseline
    r2 = r2_score(y_test, y_pred)
    # MAE: Mean Absolute Error (average absolute difference, robust to outliers)
    mae = mean_absolute_error(y_test, y_pred)
    
    print(f"\n{name}:")
    print(f"  RMSE: {rmse:.2f}")  # Lower is better
    print(f"  R² Score: {r2:.3f}")  # Higher is better (max 1.0)
    print(f"  MAE: {mae:.2f}")  # Lower is better</code></pre>

                        <pre><code class="language-python"># Import visualization library
import matplotlib.pyplot as plt
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor

# 4. VISUALIZE PREDICTIONS - Scatter plot of actual vs predicted values
diabetes = load_diabetes()
X, y = diabetes.data, diabetes.target

# Reproduce same train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Random Forest (typically best performer)
rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)
rf_reg.fit(X_train, y_train)
y_pred = rf_reg.predict(X_test)  # Predict disease progression for test patients

# Create scatter plot
plt.figure(figsize=(10, 6))
# Each point = one test patient
# X-axis = actual progression, Y-axis = model's prediction
plt.scatter(y_test, y_pred, alpha=0.6)  # alpha=0.6 for transparency (see overlapping points)

# Plot ideal prediction line (y=x)
# Perfect predictions would fall exactly on this red dashed line
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)

plt.xlabel('Actual Disease Progression')  # True progression after 1 year
plt.ylabel('Predicted Disease Progression')  # Model's prediction
plt.title('Diabetes Progression: Actual vs Predicted')  # Title
plt.grid(alpha=0.3)  # Light grid for easier reading
plt.show()

# Points close to red line = good predictions
# Points far from line = model errors (over/under-estimation)</code></pre>

                        <pre><code class="language-python"># Import libraries for feature importance analysis
import matplotlib.pyplot as plt
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
import numpy as np

# 5. FEATURE IMPORTANCE - Which features best predict disease progression?
diabetes = load_diabetes()
X, y = diabetes.data, diabetes.target

# Reproduce same split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Random Forest
rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)
rf_reg.fit(X_train, y_train)

# Extract feature importances (how much each feature contributes to predictions)
importances = rf_reg.feature_importances_  # Sum to 1.0
# Sort features by importance (descending order)
indices = np.argsort(importances)[::-1]

# Create bar chart
plt.figure(figsize=(10, 6))
plt.bar(range(X.shape[1]), importances[indices])  # Bars sorted by importance
# Label x-axis with feature names in sorted order
plt.xticks(range(X.shape[1]), [diabetes.feature_names[i] for i in indices], rotation=45)
plt.xlabel('Feature')  # Baseline patient measurements
plt.ylabel('Importance')  # 0 to ~0.3 for Diabetes dataset
plt.title('Feature Importance for Diabetes Progression Prediction')
plt.tight_layout()  # Prevent label cutoff
plt.show()

# Print ranked list with importance scores
print("Feature ranking:")
for i in range(X.shape[1]):
    print(f"{i+1}. {diabetes.feature_names[indices[i]]}: {importances[indices[i]]:.3f}")

# Typically: bmi (body mass index) and s5 (serum triglycerides) are most important
# This tells us which patient measurements to prioritize in clinical settings</code></pre>

                        <!-- California Housing Dataset -->
                        <h3 id="california-housing-dataset" class="mt-5"><i class="fas fa-home me-2 text-crimson"></i>6. California Housing Dataset (Regression)</h3>
                        
                        <div class="highlight-box">
                            <i class="fas fa-info-circle"></i>
                            <strong>About California Housing:</strong> 20,640 samples from California census data. 8 features (median income, house age, rooms, location, etc.). Target: median house value. Larger dataset ideal for testing model scalability.
                        </div>

                        <pre><code class="language-python"># Import libraries for large-scale regression
from sklearn.datasets import fetch_california_housing  # NOTE: fetch_, not load_
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd  # For data analysis
import numpy as np

# 1. LOAD & EXPLORE California Housing dataset
# fetch_california_housing() downloads dataset from internet (first time only)
# This is a larger dataset (20,640 samples) - good for testing model scalability
# Based on 1990 California census data
housing = fetch_california_housing()
X, y = housing.data, housing.target  # X = 8 features, y = median house value

print(f"Dataset shape: {X.shape}")  # (20640, 8) - 20,640 California districts
print(f"Features: {housing.feature_names}")
# MedInc: median income, HouseAge, AveRooms, AveBedrms, Population, AveOccup, Latitude, Longitude

print(f"Target (median house value in $100k): min={y.min():.2f}, max={y.max():.2f}, mean={y.mean():.2f}")
# Values in $100,000s - e.g., 2.5 = $250,000 median house value

# Create DataFrame for correlation analysis
df_housing = pd.DataFrame(X, columns=housing.feature_names)
df_housing['MedHouseVal'] = y  # Add target column

print("\nFirst few rows:")  # Preview data structure
print(df_housing.head())

print("\nCorrelation with target:")  # Which features correlate with house prices?
print(df_housing.corr()['MedHouseVal'].sort_values(ascending=False))
# Typically: MedInc (median income) is strongest predictor of house value</code></pre>

                        <pre><code class="language-python"># Import regression models and evaluation metrics
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression  # Simple linear model
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor  # Powerful ensembles
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# 2. SPLIT, SCALE & TRAIN multiple models
housing = fetch_california_housing()
X, y = housing.data, housing.target

# Split: 80% train (16,512 samples), 20% test (4,128 samples)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"Training samples: {X_train.shape[0]}")  # 16,512 districts
print(f"Test samples: {X_test.shape[0]}")  # 4,128 districts

# Scale features (important for linear models, not trees)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Linear Regression - fast baseline model
lr = LinearRegression()
lr.fit(X_train_scaled, y_train)  # Train on scaled data

# Gradient Boosting - powerful for tabular data
# n_estimators=100: Build 100 sequential trees
# learning_rate=0.1: Step size for gradient descent (smaller = more conservative)
# max_depth=5: Maximum tree depth (prevents overfitting)
# See: https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting
gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)
gb.fit(X_train, y_train)  # Trees don't need scaling

# Random Forest - ensemble of independent trees
# max_depth=20: Allow deeper trees than Gradient Boosting
rf = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42)
rf.fit(X_train, y_train)

# 3. EVALUATE all models on test set
models = {
    'Linear Regression': (lr, X_test_scaled),  # Needs scaled data
    'Gradient Boosting': (gb, X_test),  # Original data
    'Random Forest': (rf, X_test)  # Original data
}

for name, (model, X_test_data) in models.items():
    y_pred = model.predict(X_test_data)
    # RMSE in $100k units (multiply by 100,000 for dollars)
    rmse = mean_squared_error(y_test, y_pred, squared=False)
    # R²: proportion of variance explained (0-1, higher = better)
    r2 = r2_score(y_test, y_pred)
    
    print(f"\n{name}:")
    print(f"  RMSE: {rmse:.3f} ($100k)")  # e.g., 0.5 = ±$50,000 error
    print(f"  R² Score: {r2:.3f}")  # e.g., 0.8 = explains 80% of variance</code></pre>

                        <pre><code class="language-python"># Import visualization library
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor

# 4. VISUALIZE PREDICTIONS with dual plots
housing = fetch_california_housing()
X, y = housing.data, housing.target

# Reproduce same split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Gradient Boosting (typically best model for this dataset)
gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)
gb.fit(X_train, y_train)
y_pred = gb.predict(X_test)  # Predict house values for 4,128 test districts

# Create figure with 2 side-by-side subplots
fig, axes = plt.subplots(1, 2, figsize=(15, 5))  # 1 row, 2 columns

# LEFT PLOT: Scatter plot of Actual vs Predicted
axes[0].scatter(y_test, y_pred, alpha=0.3)  # alpha=0.3 for transparency (many points)
# Plot y=x line (perfect predictions)
axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
axes[0].set_xlabel('Actual House Value ($100k)')  # True median house value
axes[0].set_ylabel('Predicted House Value ($100k)')  # Model's prediction
axes[0].set_title('California Housing: Actual vs Predicted')
axes[0].grid(alpha=0.3)
# Points near red line = accurate predictions
# Points above line = overestimation, below = underestimation

# RIGHT PLOT: Residual plot (errors vs predictions)
# residuals = actual - predicted (positive = underestimated, negative = overestimated)
residuals = y_test - y_pred
axes[1].scatter(y_pred, residuals, alpha=0.3)
axes[1].axhline(y=0, color='r', linestyle='--', lw=2)  # Zero error line
axes[1].set_xlabel('Predicted House Value ($100k)')
axes[1].set_ylabel('Residuals')  # Error in predictions
axes[1].set_title('Residual Plot')  # Check for patterns in errors
axes[1].grid(alpha=0.3)
# Random scatter around y=0 = good (no systematic bias)
# Pattern (e.g., curve) = model missing relationships

plt.tight_layout()  # Prevent subplot overlap
plt.show()</code></pre>

                        <pre><code class="language-python"># Import libraries for feature importance analysis
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
import numpy as np

# 5. FEATURE IMPORTANCE - Which factors most influence house prices?
housing = fetch_california_housing()
X, y = housing.data, housing.target

# Reproduce same split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Gradient Boosting
gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)
gb.fit(X_train, y_train)

# Extract feature importances from trained model
importances = gb.feature_importances_  # Sum to 1.0
# Sort features by importance (descending)
indices = np.argsort(importances)[::-1]

# Create bar chart of feature importance
plt.figure(figsize=(10, 6))
plt.bar(range(X.shape[1]), importances[indices])  # 8 features
# Label x-axis with feature names in sorted order
plt.xticks(range(X.shape[1]), [housing.feature_names[i] for i in indices], rotation=45)
plt.xlabel('Feature')  # Census and geographic features
plt.ylabel('Importance')  # 0 to ~0.5 for California Housing
plt.title('Feature Importance for California Housing Price Prediction')
plt.tight_layout()  # Prevent x-label cutoff
plt.show()

# Print ranked list with importance scores
print("Feature ranking:")
for i in range(X.shape[1]):
    print(f"{i+1}. {housing.feature_names[indices[i]]}: {importances[indices[i]]:.3f}")

# Typically: MedInc (median income) is by far the most important predictor
# Latitude and Longitude also matter (location, location, location!)
# This tells us income and location are key drivers of California house prices</code></pre>

                        <div class="highlight-box mt-4">
                            <i class="fas fa-graduation-cap"></i>
                            <strong>Datasets Summary:</strong> You've now seen complete workflows for all major Scikit-learn datasets—from loading and exploring to training, evaluation, and visualization. These patterns apply to any ML project. Use these datasets to experiment with new algorithms and techniques!
                        </div>
                    </div>

                    <!-- Best Practices -->
                    <div id="best-practices" class="blog-content mt-5">
                        <h2><i class="fas fa-trophy me-2 text-teal"></i>Best Practices & Summary</h2>
                        
                        <h3>Key Takeaways</h3>
                        <ul>
                            <li>✅ <strong>Always split data:</strong> Training set to train, test set to evaluate (never train on test!)</li>
                            <li>✅ <strong>Scale features:</strong> Especially for distance-based models (SVM, k-NN, neural nets)</li>
                            <li>✅ <strong>Use pipelines:</strong> Prevent data leakage and simplify workflows</li>
                            <li>✅ <strong>Cross-validate:</strong> Single train/test split can be misleading</li>
                            <li>✅ <strong>Choose metrics wisely:</strong> Accuracy isn't always appropriate (use F1 for imbalanced data)</li>
                            <li>✅ <strong>Start simple:</strong> Baseline with Logistic Regression before complex models</li>
                            <li>✅ <strong>Set random_state:</strong> For reproducibility in experiments</li>
                            <li>✅ <strong>Save models:</strong> Use <code>joblib</code> to persist trained models</li>
                        </ul>

                        <h3>Common Pitfalls</h3>
                        <div class="experiment-card">
                            <div class="card-meta mb-2">
                                <span class="badge bg-crimson text-white">Avoid These Mistakes</span>
                            </div>
                            <div class="card-content">
                                <ol>
                                    <li><strong>Data leakage:</strong> Fitting preprocessors on test data</li>
                                    <li><strong>Not scaling:</strong> SVM and neural nets need scaled features</li>
                                    <li><strong>Using accuracy for imbalanced data:</strong> 99% accuracy means nothing if 99% of data is one class</li>
                                    <li><strong>Overfitting:</strong> Model performs great on training data, poorly on test data</li>
                                    <li><strong>Not setting random_state:</strong> Results change every run</li>
                                </ol>
                            </div>
                        </div>

                        <h3>Model Persistence</h3>
                        <pre><code class="language-python">import joblib

# Save model
joblib.dump(model, 'model.joblib')

# Load model
loaded_model = joblib.load('model.joblib')
predictions = loaded_model.predict(X_new)</code></pre>

                        <h3>Series Completion</h3>
                        <div class="highlight-box">
                            <i class="fas fa-graduation-cap"></i>
                            <strong>Congratulations!</strong> You've completed the Python Data Science Series. You now have the full toolkit:
                            <ul class="mt-2">
                                <li><strong>NumPy:</strong> Efficient numerical computation</li>
                                <li><strong>Pandas:</strong> Data manipulation and analysis</li>
                                <li><strong>Matplotlib/Seaborn:</strong> Compelling visualizations</li>
                                <li><strong>Scikit-learn:</strong> Machine learning models and pipelines</li>
                            </ul>
                            <p class="mt-3">You're ready to tackle real-world data science projects—from exploratory analysis to predictive modeling!</p>
                        </div>
                    </div>

                    <!-- Scikit-learn API Cheat Sheet -->
                    <div class="blog-content mt-5" id="cheat-sheet">
                        <h2><i class="fas fa-bookmark me-2 text-teal"></i>Scikit-learn API Cheat Sheet</h2>
                        
                        <p class="lead">Quick reference for machine learning workflows with Scikit-learn.</p>

                        <div class="row mt-4">
                            <!-- Data Preparation -->
                            <div class="col-md-6 mb-4">
                                <div class="card border-0 shadow-sm h-100">
                                    <div class="card-header bg-teal text-dark">
                                        <h5 class="mb-0" style="color: #ffffff !important;"><i class="fas fa-database me-2"></i>Data Preparation</h5>
                                    </div>
                                    <div class="card-body">
                                        <table class="table table-sm table-hover text-dark">
                                            <tbody>
                                                <tr><td><code>train_test_split(X, y)</code></td><td>Split data</td></tr>
                                                <tr><td><code>test_size=0.2</code></td><td>20% test set</td></tr>
                                                <tr><td><code>random_state=42</code></td><td>Reproducibility</td></tr>
                                                <tr><td><code>StandardScaler()</code></td><td>Standardize</td></tr>
                                                <tr><td><code>MinMaxScaler()</code></td><td>Scale 0-1</td></tr>
                                                <tr><td><code>LabelEncoder()</code></td><td>Encode labels</td></tr>
                                                <tr><td><code>OneHotEncoder()</code></td><td>One-hot encode</td></tr>
                                            </tbody>
                                        </table>
                                    </div>
                                </div>
                            </div>

                            <!-- Model Training -->
                            <div class="col-md-6 mb-4">
                                <div class="card border-0 shadow-sm h-100">
                                    <div class="card-header bg-navy text-dark">
                                        <h5 class="mb-0"><i class="fas fa-brain me-2"></i>Model Training</h5>
                                    </div>
                                    <div class="card-body">
                                        <table class="table table-sm table-hover text-dark">
                                            <tbody>
                                                <tr><td><code>model.fit(X_train, y_train)</code></td><td>Train model</td></tr>
                                                <tr><td><code>model.predict(X_test)</code></td><td>Make predictions</td></tr>
                                                <tr><td><code>model.score(X, y)</code></td><td>Model accuracy</td></tr>
                                                <tr><td><code>model.predict_proba(X)</code></td><td>Probabilities</td></tr>
                                                <tr><td><code>LinearRegression()</code></td><td>Linear model</td></tr>
                                                <tr><td><code>LogisticRegression()</code></td><td>Classification</td></tr>
                                                <tr><td><code>RandomForestClassifier()</code></td><td>Random forest</td></tr>
                                            </tbody>
                                        </table>
                                    </div>
                                </div>
                            </div>

                            <!-- Model Evaluation -->
                            <div class="col-md-6 mb-4">
                                <div class="card border-0 shadow-sm h-100">
                                    <div class="card-header bg-blue text-dark">
                                        <h5 class="mb-0"><i class="fas fa-chart-bar me-2"></i>Model Evaluation</h5>
                                    </div>
                                    <div class="card-body">
                                        <table class="table table-sm table-hover text-dark">
                                            <tbody>
                                                <tr><td><code>accuracy_score(y, pred)</code></td><td>Accuracy</td></tr>
                                                <tr><td><code>precision_score(y, pred)</code></td><td>Precision</td></tr>
                                                <tr><td><code>recall_score(y, pred)</code></td><td>Recall</td></tr>
                                                <tr><td><code>f1_score(y, pred)</code></td><td>F1 score</td></tr>
                                                <tr><td><code>confusion_matrix(y, pred)</code></td><td>Confusion matrix</td></tr>
                                                <tr><td><code>mean_squared_error(y, pred)</code></td><td>MSE</td></tr>
                                                <tr><td><code>r2_score(y, pred)</code></td><td>R² score</td></tr>
                                            </tbody>
                                        </table>
                                    </div>
                                </div>
                            </div>

                            <!-- Preprocessing -->
                            <div class="col-md-6 mb-4">
                                <div class="card border-0 shadow-sm h-100">
                                    <div class="card-header bg-crimson text-dark">
                                        <h5 class="mb-0" style="color: #ffffff !important;"><i class="fas fa-cogs me-2"></i>Preprocessing</h5>
                                    </div>
                                    <div class="card-body">
                                        <table class="table table-sm table-hover text-dark">
                                            <tbody>
                                                <tr><td><code>scaler.fit(X_train)</code></td><td>Fit scaler</td></tr>
                                                <tr><td><code>scaler.transform(X)</code></td><td>Transform data</td></tr>
                                                <tr><td><code>scaler.fit_transform(X)</code></td><td>Fit & transform</td></tr>
                                                <tr><td><code>SimpleImputer()</code></td><td>Fill missing</td></tr>
                                                <tr><td><code>PolynomialFeatures()</code></td><td>Poly features</td></tr>
                                                <tr><td><code>normalize(X)</code></td><td>Normalize</td></tr>
                                                <tr><td><code>binarize(X)</code></td><td>Binarize</td></tr>
                                            </tbody>
                                        </table>
                                    </div>
                                </div>
                            </div>

                            <!-- Model Selection -->
                            <div class="col-md-6 mb-4">
                                <div class="card border-0 shadow-sm h-100">
                                    <div class="card-header bg-teal text-dark">
                                        <h5 class="mb-0" style="color: #ffffff !important;"><i class="fas fa-sliders-h me-2"></i>Model Selection</h5>
                                    </div>
                                    <div class="card-body">
                                        <table class="table table-sm table-hover text-dark">
                                            <tbody>
                                                <tr><td><code>cross_val_score(model, X, y)</code></td><td>Cross-validation</td></tr>
                                                <tr><td><code>cv=5</code></td><td>5-fold CV</td></tr>
                                                <tr><td><code>GridSearchCV(model, params)</code></td><td>Grid search</td></tr>
                                                <tr><td><code>RandomizedSearchCV()</code></td><td>Random search</td></tr>
                                                <tr><td><code>learning_curve()</code></td><td>Learning curve</td></tr>
                                                <tr><td><code>validation_curve()</code></td><td>Validation curve</td></tr>
                                            </tbody>
                                        </table>
                                    </div>
                                </div>
                            </div>

                            <!-- Pipelines -->
                            <div class="col-md-6 mb-4">
                                <div class="card border-0 shadow-sm h-100">
                                    <div class="card-header bg-navy text-dark">
                                        <h5 class="mb-0"><i class="fas fa-project-diagram me-2"></i>Pipelines</h5>
                                    </div>
                                    <div class="card-body">
                                        <table class="table table-sm table-hover text-dark">
                                            <tbody>
                                                <tr><td><code>Pipeline(steps)</code></td><td>Create pipeline</td></tr>
                                                <tr><td><code>make_pipeline()</code></td><td>Quick pipeline</td></tr>
                                                <tr><td><code>pipe.fit(X, y)</code></td><td>Fit pipeline</td></tr>
                                                <tr><td><code>pipe.predict(X)</code></td><td>Predict</td></tr>
                                                <tr><td><code>ColumnTransformer()</code></td><td>Column-wise ops</td></tr>
                                                <tr><td><code>FeatureUnion()</code></td><td>Combine features</td></tr>
                                            </tbody>
                                        </table>
                                    </div>
                                </div>
                            </div>

                            <!-- Ensemble Methods -->
                            <div class="col-md-6 mb-4">
                                <div class="card border-0 shadow-sm h-100">
                                    <div class="card-header bg-blue text-dark">
                                        <h5 class="mb-0"><i class="fas fa-layer-group me-2"></i>Ensemble Methods</h5>
                                    </div>
                                    <div class="card-body">
                                        <table class="table table-sm table-hover text-dark">
                                            <tbody>
                                                <tr><td><code>RandomForestClassifier()</code></td><td>Random forest</td></tr>
                                                <tr><td><code>GradientBoostingClassifier()</code></td><td>Gradient boost</td></tr>
                                                <tr><td><code>AdaBoostClassifier()</code></td><td>AdaBoost</td></tr>
                                                <tr><td><code>VotingClassifier()</code></td><td>Voting</td></tr>
                                                <tr><td><code>BaggingClassifier()</code></td><td>Bagging</td></tr>
                                                <tr><td><code>StackingClassifier()</code></td><td>Stacking</td></tr>
                                            </tbody>
                                        </table>
                                    </div>
                                </div>
                            </div>

                            <!-- Dimensionality Reduction -->
                            <div class="col-md-6 mb-4">
                                <div class="card border-0 shadow-sm h-100">
                                    <div class="card-header bg-crimson text-dark">
                                        <h5 class="mb-0" style="color: #ffffff !important;"><i class="fas fa-compress me-2"></i>Dimensionality Reduction</h5>
                                    </div>
                                    <div class="card-body">
                                        <table class="table table-sm table-hover text-dark">
                                            <tbody>
                                                <tr><td><code>PCA(n_components=2)</code></td><td>PCA</td></tr>
                                                <tr><td><code>pca.fit_transform(X)</code></td><td>Transform to PC</td></tr>
                                                <tr><td><code>pca.explained_variance_</code></td><td>Variance explained</td></tr>
                                                <tr><td><code>TruncatedSVD()</code></td><td>SVD</td></tr>
                                                <tr><td><code>TSNE()</code></td><td>t-SNE</td></tr>
                                                <tr><td><code>SelectKBest()</code></td><td>Feature selection</td></tr>
                                            </tbody>
                                        </table>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <div class="highlight-box mt-4">
                            <i class="fas fa-lightbulb"></i>
                            <strong>Pro Tips:</strong>
                            <ul class="mb-0">
                                <li><strong>Train-test split:</strong> Always split before preprocessing to avoid data leakage</li>
                                <li><strong>Cross-validation:</strong> Use CV for robust model evaluation (5-10 folds typical)</li>
                                <li><strong>Pipelines:</strong> Chain preprocessing + model to prevent leakage and simplify workflow</li>
                                <li><strong>Scaling:</strong> Required for distance-based algorithms (KNN, SVM, neural networks)</li>
                                <li><strong>Class imbalance:</strong> Use <code>class_weight='balanced'</code> or SMOTE for imbalanced data</li>
                            </ul>
                        </div>
                    </div>

                    <!-- Related Posts -->
                    <div class="related-posts">
                        <h3><i class="fas fa-book me-2"></i>Related Articles in This Series</h3>
                        <div class="related-post-item">
                            <h5 class="mb-2">Part 1: NumPy Foundations for Data Science</h5>
                            <p class="text-muted small mb-2">Master NumPy arrays, vectorization, broadcasting, and linear algebra operations—the foundation of Python data science.</p>
                            <a href="python-data-science-numpy-foundations.html" class="text-decoration-none">Read Article <i class="fas fa-arrow-right ms-1"></i></a>
                        </div>
                        <div class="related-post-item">
                            <h5 class="mb-2">Part 2: Pandas for Data Analysis</h5>
                            <p class="text-muted small mb-2">Master Pandas DataFrames, Series, data cleaning, transformation, groupby operations, and merge techniques for real-world data analysis.</p>
                            <a href="python-data-science-pandas-analysis.html" class="text-decoration-none">Read Article <i class="fas fa-arrow-right ms-1"></i></a>
                        </div>
                        <div class="related-post-item">
                            <h5 class="mb-2">Part 3: Data Visualization with Matplotlib & Seaborn</h5>
                            <p class="text-muted small mb-2">Create compelling visualizations with Python's most powerful plotting libraries. Learn line plots, bar charts, scatter plots, and statistical graphics.</p>
                            <a href="python-data-science-visualization.html" class="text-decoration-none">Read Article <i class="fas fa-arrow-right ms-1"></i></a>
                        </div>
                    </div>

            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer id="social-media" class="bg-dark text-light py-5">
        <div class="container py-5">
            <div class="row mb-4">
                <div class="col-lg-6 mb-4 mb-lg-0">
                    <h5 class="fw-bold mb-3">Let's Connect</h5>
                    <p class="text-light">
                        I'm always interested in sharing content about my interests on different topics. Read disclaimer and feel free to share further.
                    </p>
                </div>
                <div class="col-lg-6">
                    <h5 class="fw-bold mb-3">Follow Me</h5>
                    <div class="social-links d-flex gap-2 flex-wrap">
                        <a href="https://www.facebook.com/wasil.zafar/" target="_blank" class="social-icon" title="Facebook">
                            <i class="fab fa-facebook-f"></i>
                        </a>
                        <a href="https://twitter.com/wasilzafar" target="_blank" class="social-icon" title="Twitter">
                            <i class="fab fa-twitter"></i>
                        </a>
                        <a href="https://www.linkedin.com/in/wasilzafar" target="_blank" class="social-icon" title="LinkedIn">
                            <i class="fab fa-linkedin-in"></i>
                        </a>
                        <a href="https://www.youtube.com/@wasilzafar" target="_blank" class="social-icon" title="YouTube">
                            <i class="fab fa-youtube"></i>
                        </a>
                        <a href="https://www.instagram.com/itswzee/" target="_blank" class="social-icon" title="Instagram">
                            <i class="fab fa-instagram"></i>
                        </a>
                        <a href="https://in.pinterest.com/wasilz/" target="_blank" class="social-icon" title="Pinterest">
                            <i class="fab fa-pinterest-p"></i>
                        </a>
                        <a href="mailto:wasil.zafar@gmail.com" class="social-icon" title="Email">
                            <i class="fas fa-envelope"></i>
                        </a>
                    </div>
                </div>
            </div>

            <hr class="bg-secondary">

            <div class="row mt-4">
                <div class="col-md-6">
                    <p class="small">
                        <i class="fas fa-icons me-2"></i>Icons from <a href="https://www.flaticon.com/" target="_blank" class="text-light">Flaticon</a> &amp; <a href="https://fontawesome.com/" target="_blank" class="text-light">Font Awesome</a>
                    </p>
                    <p class="small mt-3">
                        <a href="/" class="text-light text-decoration-none">Home</a> | 
                        <a href="/disclaimer.html" class="text-light text-decoration-none">Disclaimer</a> | 
                        <a href="/privacy-policy.html" class="text-light text-decoration-none">Privacy Policy</a>
                    </p>
                </div>
                <div class="col-md-6 text-md-end">
                    <p class="small">
                        Enjoying this content? ☕ <a href="https://buymeacoffee.com/itswzee" target="_blank" class="text-light" style="text-decoration: underline;">Keep me caffeinated</a> to keep the pixels flowing!
                    </p>
                </div>
            </div>
        </div>
    </footer>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    
    <!-- Scroll-to-Top Button -->
    <button id="scrollToTop" class="scroll-to-top" title="Back to Top">
        <i class="fas fa-arrow-up"></i>
    </button>
    
    <!-- Cookie Consent JS -->
    <script src="../../../js/cookie-consent.js"></script>
    
    <!-- Main JS -->
    <script src="../../../js/main.js"></script>

    <!-- Prism.js Syntax Highlighting -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/toolbar/prism-toolbar.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/copy-to-clipboard/prism-copy-to-clipboard.min.js"></script>

    <!-- Scroll-to-Top Script -->
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const scrollToTopBtn = document.getElementById('scrollToTop');
            
            // Show/hide button on scroll
            window.addEventListener('scroll', function() {
                if (window.scrollY > 300) {
                    scrollToTopBtn.classList.add('show');
                } else {
                    scrollToTopBtn.classList.remove('show');
                }
            });
            
            // Smooth scroll to top on click
            scrollToTopBtn.addEventListener('click', function() {
                window.scrollTo({ top: 0, behavior: 'smooth' });
            });
        });
    </script>

    <!-- Side Navigation TOC Script -->
    <script>
        // Open side navigation
        function openNav() {
            document.getElementById('tocSidenav').classList.add('open');
            document.getElementById('tocOverlay').classList.add('show');
            document.body.style.overflow = 'hidden'; // Prevent background scroll
        }

        // Close side navigation
        function closeNav() {
            document.getElementById('tocSidenav').classList.remove('open');
            document.getElementById('tocOverlay').classList.remove('show');
            document.body.style.overflow = 'auto';
        }

        // Close on ESC key
        document.addEventListener('keydown', function(e) {
            if (e.key === 'Escape') {
                closeNav();
            }
        });

        // Highlight active section in TOC based on scroll position
        document.addEventListener('DOMContentLoaded', function() {
            const sections = document.querySelectorAll('[id]');
            const tocLinks = document.querySelectorAll('.sidenav-toc a');
            
            function highlightActiveSection() {
                let currentSection = '';
                
                sections.forEach(section => {
                    const sectionTop = section.offsetTop;
                    const sectionHeight = section.clientHeight;
                    
                    if (window.scrollY >= sectionTop - 200) {
                        currentSection = section.getAttribute('id');
                    }
                });
                
                tocLinks.forEach(link => {
                    link.classList.remove('active');
                    if (link.getAttribute('href') === '#' + currentSection) {
                        link.classList.add('active');
                    }
                });
            }
            
            // Highlight on scroll
            window.addEventListener('scroll', highlightActiveSection);
            
            // Initial highlight
            highlightActiveSection();
            
            // Smooth scroll for TOC links
            tocLinks.forEach(link => {
                link.addEventListener('click', function(e) {
                    e.preventDefault();
                    const targetId = this.getAttribute('href');
                    const targetSection = document.querySelector(targetId);
                    
                    if (targetSection) {
                        const offsetTop = targetSection.offsetTop - 80; // Account for fixed navbar
                        window.scrollTo({
                            top: offsetTop,
                            behavior: 'smooth'
                        });
                    }
                    
                    // Close nav after clicking
                    setTimeout(closeNav, 300);
                });
            });
        });
    </script>

    <!-- Prism Theme Switcher -->
    <script>
        // Available themes with display names
        const themes = {
            'prism-theme': 'Tomorrow Night',
            'prism-default': 'Default',
            'prism-dark': 'Dark',
            'prism-twilight': 'Twilight',
            'prism-okaidia': 'Okaidia',
            'prism-solarizedlight': 'Solarized Light'
        };

        // Load saved theme from localStorage or use default
        const savedTheme = localStorage.getItem('prism-theme') || 'prism-theme';

        // Function to switch theme
        function switchTheme(themeId) {
            // Disable all themes
            Object.keys(themes).forEach(id => {
                const link = document.getElementById(id);
                if (link) {
                    link.disabled = true;
                }
            });
            
            // Enable selected theme
            const selectedLink = document.getElementById(themeId);
            if (selectedLink) {
                selectedLink.disabled = false;
                localStorage.setItem('prism-theme', themeId);
            }

            // Update all dropdowns on the page to match selected theme
            document.querySelectorAll('div.code-toolbar select').forEach(dropdown => {
                dropdown.value = themeId;
            });

            // Re-apply syntax highlighting with new theme
            setTimeout(() => {
                Prism.highlightAll();
            }, 10);
        }

        // Apply saved theme on page load
        document.addEventListener('DOMContentLoaded', function() {
            switchTheme(savedTheme);
        });

        // Add theme switcher to Prism toolbar
        Prism.plugins.toolbar.registerButton('theme-switcher', function(env) {
            const select = document.createElement('select');
            select.setAttribute('aria-label', 'Select code theme');
            select.className = 'prism-theme-selector';
            
            // Populate dropdown with themes
            Object.keys(themes).forEach(themeId => {
                const option = document.createElement('option');
                option.value = themeId;
                option.textContent = themes[themeId];
                if (themeId === savedTheme) {
                    option.selected = true;
                }
                select.appendChild(option);
            });
            
            // Handle theme change
            select.addEventListener('change', function(e) {
                switchTheme(e.target.value);
            });
            
            return select;
        });
    </script>
</body>
</html>
