<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="robots" content="index, archive" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="description" content="Part 14: Memory Hierarchy & Cache - Learn about L1/L2/L3 caches, cache coherence protocols, NUMA architecture, and memory performance optimization." />
    <meta name="keywords" content="memory hierarchy, cache, L1 cache, L2 cache, L3 cache, cache coherence, MESI protocol, NUMA, cache line, temporal locality, spatial locality" />
    
    <meta property="og:title" content="Part 14: Memory Hierarchy & Cache | Computer Architecture & OS Mastery" />
    <meta property="og:description" content="Master memory hierarchy: L1/L2/L3 caches, cache coherence protocols, and NUMA architecture." />
    <meta property="og:type" content="article" />
    <meta property="og:url" content="https://wasilzafar.com/pages/series/computer-architecture/comp-arch-cache-memory-hierarchy.html" />
    <meta property="article:published_time" content="2026-01-31" />
    <meta property="article:author" content="Wasil Zafar" />
    <meta property="article:section" content="Technology" />

    <title>Part 14: Memory Hierarchy & Cache | Computer Architecture & OS Mastery - Wasil Zafar</title>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=DM+Sans:wght@400;500;600;700&family=Poppins:wght@300;400;500;600;700&family=Playfair+Display:wght@600;700&display=swap" rel="stylesheet" />
    <link rel="stylesheet" href="../../../css/main.css" type="text/css" />
    <link rel="apple-touch-icon" sizes="180x180" href="../../../images/favicon_io/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../../../images/favicon_io/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../../../images/favicon_io/favicon-16x16.png">
    <link rel="manifest" href="../../../images/favicon_io/site.webmanifest">

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" id="prism-theme" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" id="prism-default" disabled />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-dark.min.css" id="prism-dark" disabled />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-twilight.min.css" id="prism-twilight" disabled />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-okaidia.min.css" id="prism-okaidia" disabled />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-solarizedlight.min.css" id="prism-solarizedlight" disabled />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/toolbar/prism-toolbar.min.css" />

    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('consent', 'default', { 'ad_storage': 'denied', 'ad_user_data': 'denied', 'ad_personalization': 'denied', 'analytics_storage': 'denied', 'region': ['AT','BE','BG','HR','CY','CZ','DK','EE','FI','FR','DE','GR','HU','IE','IT','LV','LT','LU','MT','NL','PL','PT','RO','SK','SI','ES','SE'] });
        gtag('consent', 'default', { 'ad_storage': 'granted', 'ad_user_data': 'granted', 'ad_personalization': 'granted', 'analytics_storage': 'granted' });
        gtag('set', 'url_passthrough', true);
    </script>
    <script>
        (function(w, d, s, l, i) { w[l] = w[l] || []; w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'}); var f = d.getElementsByTagName(s)[0], j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f); })(window, document, 'script', 'dataLayer', 'GTM-PBS8M2JR');
    </script>
</head>
<body>
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-PBS8M2JR" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

    <nav class="navbar navbar-expand-lg navbar-dark bg-dark shadow-sm">
        <div class="container-fluid">
            <a class="navbar-brand fw-bold" href="/"><span class="gradient-text">Wasil Zafar</span></a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item"><a class="nav-link" href="/">Home</a></li>
                    <li class="nav-item"><a class="nav-link" href="/#about">About</a></li>
                    <li class="nav-item"><a class="nav-link" href="/#skills">Skills</a></li>
                    <li class="nav-item"><a class="nav-link" href="/#certifications">Certifications</a></li>
                    <li class="nav-item"><a class="nav-link" href="/#interests">Interests</a></li>
                </ul>
            </div>
        </div>
    </nav>

    <section class="blog-hero">
        <div class="container py-5">
            <a href="../../categories/technology.html" class="back-link"><i class="fas fa-arrow-left me-2"></i>Back to Technology</a>
            <h1 class="display-4 fw-bold mt-4">Part 14: Memory Hierarchy & Cache</h1>
            <div class="blog-meta">
                <span><i class="fas fa-calendar me-2"></i>January 31, 2026</span>
                <span><i class="fas fa-user me-2"></i>Wasil Zafar</span>
                <span class="reading-time"><i class="fas fa-clock me-1"></i>32 min read</span>
                <button onclick="window.print()" class="print-btn" title="Print this article"><i class="fas fa-print"></i> Print</button>
            </div>
            <p class="lead mt-3">Explore the memory hierarchy—from CPU registers to disk—and master cache design for optimal performance.</p>
        </div>
    </section>

    <button class="toc-toggle-btn" onclick="openNav()" title="Table of Contents" aria-label="Open Table of Contents"><i class="fas fa-list"></i></button>

    <div id="tocSidenav" class="sidenav-toc">
        <div class="toc-header">
            <h3><i class="fas fa-list me-2"></i>Table of Contents</h3>
            <button class="closebtn" onclick="closeNav()" aria-label="Close Table of Contents">&times;</button>
        </div>
        <ol>
            <li><a href="#introduction" onclick="closeNav()">Introduction</a></li>
            <li><a href="#memory-hierarchy" onclick="closeNav()">Memory Hierarchy Overview</a></li>
            <li><a href="#locality" onclick="closeNav()">Locality of Reference</a></li>
            <li><a href="#cache-basics" onclick="closeNav()">Cache Basics</a></li>
            <li><a href="#cache-mapping" onclick="closeNav()">Cache Mapping Strategies</a></li>
            <li><a href="#replacement-policies" onclick="closeNav()">Replacement Policies</a></li>
            <li><a href="#write-policies" onclick="closeNav()">Write Policies</a></li>
            <li><a href="#cache-coherence" onclick="closeNav()">Cache Coherence</a></li>
            <li><a href="#numa" onclick="closeNav()">NUMA Architecture</a></li>
            <li><a href="#conclusion" onclick="closeNav()">Conclusion & Next Steps</a></li>
        </ol>
    </div>
    <div id="tocOverlay" class="sidenav-overlay" onclick="closeNav()"></div>

    <section class="py-5">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 mx-auto">

                <div id="introduction" class="blog-content">
                    <h2><i class="fas fa-memory me-2 text-teal"></i>Introduction</h2>
                    <p>Modern computers use a memory hierarchy to balance speed and capacity. Fast memory is expensive and limited; slower memory is cheap and abundant. Caches bridge this gap.</p>

                    <div class="highlight-box highlight-crimson">
                        <i class="fas fa-sitemap me-2"></i>
                        <strong>Series Context:</strong> This is <strong>Part 14 of 24</strong> in the Computer Architecture & Operating Systems Mastery series. We transition from process management to memory systems.
                    </div>

                    <div class="experiment-card" id="series-nav">
                        <h4><i class="fas fa-map-signs me-2"></i>Complete Series Navigation</h4>
                        <div class="meta mb-2">
                            <span class="badge bg-teal me-2">24-Part Series</span>
                            <span class="badge bg-crimson">Computer Architecture & OS Mastery</span>
                        </div>
                        <div class="content">
                            <ol>
                                <li><a href="comp-arch-foundations.html"><strong>Part 1:</strong> Foundations of Computer Systems</a> — System overview, architectures, OS role</li>
                                <li><a href="comp-arch-digital-logic.html"><strong>Part 2:</strong> Digital Logic & CPU Building Blocks</a> — Gates, registers, datapath, microarchitecture</li>
                                <li><a href="comp-arch-isa.html"><strong>Part 3:</strong> Instruction Set Architecture (ISA)</a> — RISC vs CISC, instruction formats, addressing</li>
                                <li><a href="comp-arch-assembly.html"><strong>Part 4:</strong> Assembly Language & Machine Code</a> — Registers, stack, calling conventions</li>
                                <li><a href="comp-arch-linkers-loaders.html"><strong>Part 5:</strong> Assemblers, Linkers & Loaders</a> — Object files, ELF, dynamic linking</li>
                                <li><a href="comp-arch-compilers.html"><strong>Part 6:</strong> Compilers & Program Translation</a> — Lexing, parsing, code generation</li>
                                <li><a href="comp-arch-cpu-pipelining.html"><strong>Part 7:</strong> CPU Execution & Pipelining</a> — Fetch-decode-execute, hazards, prediction</li>
                                <li><a href="comp-arch-os-kernel.html"><strong>Part 8:</strong> OS Architecture & Kernel Design</a> — Monolithic, microkernel, system calls</li>
                                <li><a href="comp-arch-processes.html"><strong>Part 9:</strong> Processes & Program Execution</a> — Process lifecycle, PCB, fork/exec</li>
                                <li><a href="comp-arch-threads-concurrency.html"><strong>Part 10:</strong> Threads & Concurrency</a> — Threading models, pthreads, race conditions</li>
                                <li><a href="comp-arch-cpu-scheduling.html"><strong>Part 11:</strong> CPU Scheduling Algorithms</a> — FCFS, RR, CFS, real-time scheduling</li>
                                <li><a href="comp-arch-synchronization.html"><strong>Part 12:</strong> Synchronization & Coordination</a> — Locks, semaphores, classic problems</li>
                                <li><a href="comp-arch-deadlocks.html"><strong>Part 13:</strong> Deadlocks & Prevention</a> — Coffman conditions, Banker's algorithm</li>
                                <li><strong>Part 14: Memory Hierarchy & Cache (This Guide)</strong> — L1/L2/L3, cache coherence, NUMA</li>
                                <li><a href="comp-arch-memory-management.html"><strong>Part 15:</strong> Memory Management Fundamentals</a> — Address spaces, fragmentation, allocation</li>
                                <li><a href="comp-arch-virtual-memory.html"><strong>Part 16:</strong> Virtual Memory & Paging</a> — Page tables, TLB, demand paging</li>
                                <li><a href="comp-arch-file-systems.html"><strong>Part 17:</strong> File Systems & Storage</a> — Inodes, journaling, ext4, NTFS</li>
                                <li><a href="comp-arch-io-devices.html"><strong>Part 18:</strong> I/O Systems & Device Drivers</a> — Interrupts, DMA, disk scheduling</li>
                                <li><a href="comp-arch-multiprocessor.html"><strong>Part 19:</strong> Multiprocessor Systems</a> — SMP, NUMA, cache coherence</li>
                                <li><a href="comp-arch-security.html"><strong>Part 20:</strong> OS Security & Protection</a> — Privilege levels, ASLR, sandboxing</li>
                                <li><a href="comp-arch-virtualization.html"><strong>Part 21:</strong> Virtualization & Containers</a> — Hypervisors, namespaces, cgroups</li>
                                <li><a href="comp-arch-kernel-internals.html"><strong>Part 22:</strong> Advanced Kernel Internals</a> — Linux subsystems, kernel debugging</li>
                                <li><a href="comp-arch-case-studies.html"><strong>Part 23:</strong> Case Studies</a> — Linux vs Windows vs macOS</li>
                                <li><a href="comp-arch-capstone-projects.html"><strong>Part 24:</strong> Capstone Projects</a> — Shell, thread pool, paging simulator</li>
                            </ol>
                        </div>
                    </div>

                    <div class="highlight-box">
                        <i class="fas fa-question-circle me-2"></i>
                        <strong>The Memory Wall:</strong> CPUs have gotten 10,000× faster over decades, but memory access time has only improved 10×. Caches hide this latency gap by keeping frequently-used data close to the CPU.
                    </div>
                </div>

                <div id="memory-hierarchy" class="blog-content mt-5">
                    <h2><i class="fas fa-layer-group me-2 text-teal"></i>Memory Hierarchy Overview</h2>
                    
                    <p>Memory is organized in a <strong>pyramid</strong>: smaller, faster, more expensive memory at the top; larger, slower, cheaper memory at the bottom.</p>

                    <div class="experiment-card">
                        <h4><i class="fas fa-mountain me-2"></i>The Memory Pyramid</h4>
                        <div class="content">
<pre class="language-text"><code>Memory Hierarchy (Modern Desktop/Server):
══════════════════════════════════════════════════════════════

              ┌─────────┐
              │Registers│  ~1 KB      ~0.3 ns    $$$$$$
              │  ~32    │
         ┌────┴─────────┴────┐
         │    L1 Cache       │  32-64 KB   ~1 ns      $$$$$
         │  (per core)       │  (data + instruction separate)
    ┌────┴───────────────────┴────┐
    │        L2 Cache             │  256-512 KB  ~4 ns    $$$$
    │       (per core)            │
┌───┴─────────────────────────────┴───┐
│           L3 Cache (shared)         │  8-32 MB    ~12 ns   $$$
│          (all cores share)          │
├─────────────────────────────────────┤
│           Main Memory (RAM)         │  16-128 GB  ~100 ns   $$
│              (DDR4/5)               │
├─────────────────────────────────────┤
│          SSD (NVMe/SATA)            │  512GB-4TB  ~50-100 μs  $
│                                     │
├─────────────────────────────────────┤
│          HDD (Magnetic)             │  1-20 TB    ~5-10 ms    ¢
└─────────────────────────────────────┘


Speed Comparison (cycles at 3 GHz):
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Level           Latency      CPU Cycles     Relative
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Register        0.3 ns       1              1×
L1 Cache        1 ns         3-4            3×
L2 Cache        4 ns         12             12×
L3 Cache        12 ns        36             36×
Main Memory     100 ns       300            300×
SSD             50 μs        150,000        150,000×
HDD             5 ms         15,000,000     15,000,000×</code></pre>
                        </div>
                    </div>

<pre class="language-bash"><code># View CPU cache information on Linux
$ lscpu | grep -i cache
L1d cache:           32K    # L1 data cache per core
L1i cache:           32K    # L1 instruction cache per core
L2 cache:            256K   # L2 per core
L3 cache:            8192K  # L3 shared

# Detailed cache info
$ cat /sys/devices/system/cpu/cpu0/cache/index0/size
32K
$ cat /sys/devices/system/cpu/cpu0/cache/index0/type
Data

# Windows PowerShell
Get-WmiObject Win32_CacheMemory | Select Purpose, InstalledSize</code></pre>
                </div>

                <div id="locality" class="blog-content mt-5">
                    <h2><i class="fas fa-crosshairs me-2 text-teal"></i>Locality of Reference</h2>
                    
                    <p>Caches work because of <strong>locality</strong>—programs tend to access the same data (or nearby data) repeatedly.</p>

<pre class="language-text"><code>Types of Locality:
══════════════════════════════════════════════════════════════

1. TEMPORAL LOCALITY (Time)
   • Recently accessed data will likely be accessed again soon
   • Example: Loop counter, frequently called functions
   
   for (int i = 0; i &lt; 1000; i++) {  /* i accessed 1000 times */
       sum += array[i];               /* sum accessed 1000 times */
   }

2. SPATIAL LOCALITY (Space)
   • Data near recently accessed data will likely be accessed
   • Example: Array elements, struct fields, sequential code
   
   int array[1000];
   for (int i = 0; i &lt; 1000; i++) {
       sum += array[i];   /* array[0], array[1], array[2]... */
   }
   /* Each array element is adjacent in memory */


Why Caches Exploit Locality:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
• Temporal: Keep recently accessed data in cache
• Spatial: Load entire cache lines (64 bytes), not single bytes
  → Access array[0] loads array[0..15] into cache
  → array[1..15] are already cached!</code></pre>

                    <div class="highlight-box highlight-navy">
                        <i class="fas fa-info-circle me-2"></i>
                        <strong>Rule of Thumb:</strong> Programs spend 90% of time in 10% of code. A small, fast cache can satisfy most memory accesses if it holds the "hot" working set.
                    </div>
                </div>

                <div id="cache-basics" class="blog-content mt-5">
                    <h2><i class="fas fa-microchip me-2 text-teal"></i>Cache Basics</h2>
                    
                    <p>A cache stores copies of frequently accessed memory in small, fast SRAM. Key concepts: cache lines, tags, and hit/miss.</p>

                    <div class="experiment-card">
                        <h4><i class="fas fa-cubes me-2"></i>Cache Structure</h4>
                        <div class="content">
<pre class="language-text"><code>Cache Terminology:
══════════════════════════════════════════════════════════════

CACHE LINE (Block):
• Unit of transfer between cache and memory
• Typically 64 bytes (exploits spatial locality)
• Contains: Tag + Data + Status bits

TAG:
• Identifies which memory address is stored
• Part of memory address stored alongside data

VALID BIT:
• Indicates if cache line contains valid data

DIRTY BIT:
• Indicates if cached data differs from memory
• (For write-back caches)


Cache Line Structure:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
┌───────┬───────┬──────────────────────────────────────────┐
│ Valid │ Dirty │   Tag   │          Data (64 bytes)       │
│   1   │   1   │  ~20    │                                │
└───────┴───────┴─────────┴────────────────────────────────┘


Memory Address Decomposition:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
For 64-byte cache line, 64 sets, 32-bit address:

│◄──────── 32 bits ─────────►│
┌─────────────┬────────┬──────┐
│    Tag      │ Index  │Offset│
│   20 bits   │ 6 bits │6 bits│
└─────────────┴────────┴──────┘

• Offset (6 bits): Which byte within 64-byte line
• Index (6 bits): Which cache set (64 sets)
• Tag (20 bits): Distinguishes different addresses mapping to same set</code></pre>
                        </div>
                    </div>

<pre class="language-text"><code>Cache Hit and Miss:
══════════════════════════════════════════════════════════════

CACHE HIT:
CPU requests → Check cache → Found! → Return data
Latency: 1-4 cycles (L1), 12 cycles (L2), 36 cycles (L3)

CACHE MISS:
CPU requests → Check cache → Not found → Fetch from memory
                                       → Store in cache
                                       → Return data
Latency: 100+ cycles (memory access)


Types of Cache Misses (The Three C's):
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
1. COMPULSORY (Cold) Miss
   • First access to data - never been in cache
   • Unavoidable (except prefetching)

2. CAPACITY Miss
   • Cache not big enough for working set
   • Data evicted and accessed again
   • Fix: Larger cache

3. CONFLICT Miss
   • Multiple addresses map to same cache location
   • Data evicted prematurely
   • Fix: Higher associativity</code></pre>
                </div>

                <div id="cache-mapping" class="blog-content mt-5">
                    <h2><i class="fas fa-sitemap me-2 text-teal"></i>Cache Mapping Strategies</h2>
                    
                    <p>How does a memory address map to a cache location? Three strategies with different trade-offs.</p>

                    <div class="experiment-card">
                        <h4><i class="fas fa-map me-2"></i>Cache Mapping Types</h4>
                        <div class="content">
<pre class="language-text"><code>1. DIRECT MAPPED Cache:
══════════════════════════════════════════════════════════════
Each memory address maps to exactly ONE cache location.
Location = (Address) mod (Number of cache lines)

Memory:         Cache:
┌─────┐         ┌─────┐
│  0  │ ────┐   │  0  │
├─────┤     │   ├─────┤
│  1  │ ────┼→  │  1  │
├─────┤     │   ├─────┤
│  2  │ ────┤   │  2  │
├─────┤     │   ├─────┤
│  3  │ ────┘   │  3  │ ← Address 0,4,8... all map here!
├─────┤         └─────┘
│  4  │ ────┐
├─────┤     │   Problem: Addresses 0 and 4 CONFLICT
│  5  │     │   Accessing alternately causes thrashing!
│ ... │     │
└─────┘     └──→

✓ Simple, fast lookup (one comparison)
✗ High conflict miss rate


2. FULLY ASSOCIATIVE Cache:
══════════════════════════════════════════════════════════════
Any memory address can go in ANY cache location.

Memory:         Cache:
┌─────┐         ┌─────┐
│ Any │ ────────│ Any │  Check ALL tags in parallel
│ ... │ ────────│ ... │  
└─────┘         └─────┘

✓ No conflict misses
✗ Expensive - must compare all tags simultaneously
✗ Only practical for small caches (TLB)


3. SET-ASSOCIATIVE Cache (Best of Both):
══════════════════════════════════════════════════════════════
Address maps to a SET of N locations (N-way associative).

4-Way Set-Associative (4 lines per set):
                    ┌─────────────────────┐
Memory addr ──────→ │ Set 0: Way0|Way1|Way2|Way3 │
maps to set         │ Set 1: Way0|Way1|Way2|Way3 │
                    │ Set 2: Way0|Way1|Way2|Way3 │
                    │  ...                       │
                    └─────────────────────┘

Set = (Address) mod (Number of sets)
Then search within set (4 comparisons max)

✓ Balance of speed and flexibility
✓ Most common: 4-way, 8-way, 16-way L1
✗ More complex than direct-mapped</code></pre>
                        </div>
                    </div>

<pre class="language-text"><code>Comparison:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
                    Direct    4-Way       Fully
                    Mapped    Assoc.      Assoc.
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Comparisons/access     1         4          All
Conflict misses       High      Low        None
Hardware cost         Low       Medium     High
Typical use           Old L1    Modern     TLB, 
                                L1/L2/L3   small caches</code></pre>
                </div>

                <div id="replacement-policies" class="blog-content mt-5">
                    <h2><i class="fas fa-recycle me-2 text-teal"></i>Replacement Policies</h2>
                    
                    <p>When a cache set is full, which line do we evict? The <strong>replacement policy</strong> decides.</p>

<pre class="language-text"><code>Cache Replacement Policies:
══════════════════════════════════════════════════════════════

1. LRU (Least Recently Used)
   • Evict line that hasn't been accessed longest
   • Exploits temporal locality
   • Expensive to implement perfectly (track all accesses)
   • Common: Pseudo-LRU approximations
   
   Access order: A B C D A B E (4-way cache)
   Cache: [E, A, B, D]  ← C was LRU, evicted

2. FIFO (First In, First Out)
   • Evict oldest line (first loaded)
   • Simple to implement
   • Doesn't consider access frequency
   • Can evict frequently-used data

3. Random
   • Pick random line to evict
   • Surprisingly competitive!
   • Avoids pathological worst-cases
   • Simple hardware

4. LFU (Least Frequently Used)
   • Evict line with fewest accesses
   • Requires access counters
   • Problem: Old but formerly-popular data never evicted
   

Modern CPUs: Pseudo-LRU or Tree-PLRU
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
True LRU for 8-way requires tracking order of 8 elements.
Approximations use tree structure with few bits:

        ┌───────┐
        │   0   │  ← Points to "older" half
        └───┬───┘
       ┌────┴────┐
       │    │    │
     ┌─┴─┐ ┌─┴─┐
     │ 0 │ │ 1 │
     └─┬─┘ └─┬─┘
    ┌──┴──┐┌─┴──┐
   W0 W1  W2 W3

Evict by following 0-pointers down tree.</code></pre>
                </div>

                <div id="write-policies" class="blog-content mt-5">
                    <h2><i class="fas fa-pen me-2 text-teal"></i>Write Policies</h2>
                    
                    <p>When CPU writes data, when does it update main memory? Two main strategies.</p>

                    <div class="experiment-card">
                        <h4><i class="fas fa-edit me-2"></i>Write-Through vs Write-Back</h4>
                        <div class="content">
<pre class="language-text"><code>Write Policies:
══════════════════════════════════════════════════════════════

WRITE-THROUGH:
• Every write goes to BOTH cache AND memory immediately
• Memory always has current data
• Simple, no dirty bits needed

CPU writes X=5:
   ┌─────┐    X=5    ┌───────┐    X=5    ┌────────┐
   │ CPU │ ────────→ │ Cache │ ────────→ │ Memory │
   └─────┘           └───────┘           └────────┘

✓ Memory always consistent
✓ Simple recovery on crash
✗ Every write is slow (memory speed)
✗ High memory bandwidth usage

Solution: Write Buffer
   Writes queue in buffer, drain to memory in background
   CPU doesn't wait for memory


WRITE-BACK:
• Write only to cache (mark line "dirty")
• Write to memory only when line evicted
• Memory may have stale data

CPU writes X=5:
   ┌─────┐    X=5    ┌───────┐           ┌────────┐
   │ CPU │ ────────→ │ Cache │  (old X)  │ Memory │
   └─────┘           │[dirty]│           │ X=old  │
                     └───────┘           └────────┘

Later, when cache line evicted:
                     ┌───────┐    X=5    ┌────────┐
                     │ Cache │ ────────→ │ Memory │
                     └───────┘           └────────┘

✓ Fewer memory writes (coalesce multiple writes)
✓ Lower bandwidth
✗ Complex (track dirty bits)
✗ Crash can lose data

Most modern CPUs: Write-back for performance</code></pre>
                        </div>
                    </div>

<pre class="language-text"><code>Write Miss Policies:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
What if write is to address NOT in cache?

Write-Allocate (typical with write-back):
  Load cache line from memory, then write to cache
  Good if writing more data to same line soon

No-Write-Allocate (typical with write-through):
  Write directly to memory, don't load to cache
  Good if data won't be read soon</code></pre>
                </div>

                <div id="cache-coherence" class="blog-content mt-5">
                    <h2><i class="fas fa-sync-alt me-2 text-teal"></i>Cache Coherence</h2>
                    
                    <p>In multicore systems, each core has its own L1/L2 cache. What if two cores cache the same address and one writes to it?</p>

<pre class="language-text"><code>The Cache Coherence Problem:
══════════════════════════════════════════════════════════════

    Core 0           Core 1
   ┌──────┐         ┌──────┐
   │ L1   │         │ L1   │
   │ X=5  │         │ X=5  │  ← Both cached X=5
   └──┬───┘         └──┬───┘
      │                │
      └──────┬─────────┘
             │
         ┌───┴───┐
         │  L3   │
         │ X=5   │
         └───────┘

Core 0 writes X=7:
   ┌──────┐         ┌──────┐
   │ L1   │         │ L1   │
   │ X=7  │         │ X=5  │  ← STALE! Core 1 sees old value!
   └──────┘         └──────┘

This is INCOHERENT - different cores see different values!


MESI Protocol (Most common coherence protocol):
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Each cache line has a state:

M (Modified): This cache has only copy, it's dirty
              • Can read/write freely
              • Must write back before others can read

E (Exclusive): This cache has only copy, it's clean
              • Can read freely
              • Can transition to Modified on write

S (Shared): Multiple caches may have copies
              • Can read freely
              • Must broadcast before writing (→ invalidate others)

I (Invalid): Line not valid / not present
              • Must fetch from memory or other cache


State Transitions:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
         Read hit     Write hit     Other reads    Other writes
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Modified    M            M         →S (share)      →I (inval)
Exclusive   E           →M         →S              →I
Shared      S           →M*        S               →I
Invalid    →E or S*     →M*        -               -

* Requires bus transaction (snoop)</code></pre>

                    <div class="highlight-box highlight-crimson">
                        <i class="fas fa-exclamation-triangle me-2"></i>
                        <strong>Performance Impact:</strong> Cache coherence adds overhead. "False sharing" occurs when different cores write to different variables that happen to be on the same cache line—causing constant invalidations even though there's no true sharing!
                    </div>

<pre class="language-c"><code>/* False Sharing Example */
struct CountersBad {
    int counter0;  /* Core 0 increments */
    int counter1;  /* Core 1 increments */
};  /* Both on SAME cache line! Constant invalidations */

/* Fix: Pad to separate cache lines */
struct CountersGood {
    int counter0;
    char padding[60];  /* 64-byte cache line alignment */
    int counter1;
};  /* Each counter on OWN cache line */</code></pre>
                </div>

                <div id="numa" class="blog-content mt-5">
                    <h2><i class="fas fa-network-wired me-2 text-teal"></i>NUMA Architecture</h2>
                    
                    <p><strong>NUMA (Non-Uniform Memory Access)</strong> systems have memory physically distributed across multiple nodes. Access time depends on which node owns the memory.</p>

                    <div class="experiment-card">
                        <h4><i class="fas fa-server me-2"></i>NUMA Topology</h4>
                        <div class="content">
<pre class="language-text"><code>NUMA Architecture (2-Socket Server):
══════════════════════════════════════════════════════════════

┌─────────────────────────────────────────────────────────────┐
│                        Node 0                               │
│  ┌────────────────────────┐    ┌──────────────────────┐    │
│  │  CPU 0 (8 cores)       │    │  Local Memory        │    │
│  │  ┌────┐ ┌────┐ ┌────┐  │←──→│  64 GB DDR4          │    │
│  │  │Core│ │Core│ │... │  │    │  Access: ~80ns       │    │
│  │  └────┘ └────┘ └────┘  │    └──────────────────────┘    │
│  │  └──── L3 Cache ──────┘│                                │
│  └────────────────────────┘                                │
│            │                                                │
│            │ Interconnect (QPI / UPI)                      │
│            │ ~40-100 GB/s, adds ~40ns latency              │
│            │                                                │
│            ↓                                                │
└────────────┼────────────────────────────────────────────────┘
             │
┌────────────┼────────────────────────────────────────────────┐
│            ↓                        Node 1                  │
│  ┌────────────────────────┐    ┌──────────────────────┐    │
│  │  CPU 1 (8 cores)       │    │  Remote Memory       │    │
│  │  ┌────┐ ┌────┐ ┌────┐  │←──→│  64 GB DDR4          │    │
│  │  │Core│ │Core│ │... │  │    │  Access from Node0:  │    │
│  │  └────┘ └────┘ └────┘  │    │  ~120ns (+40ns hop)  │    │
│  │  └──── L3 Cache ──────┘│    └──────────────────────┘    │
│  └────────────────────────┘                                │
└─────────────────────────────────────────────────────────────┘


NUMA Latency Impact:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Access Type          Latency     Bandwidth
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Local memory         ~80ns       ~100 GB/s
Remote memory        ~120ns      ~60 GB/s (interconnect limited)
                     (+50%)      (-40%)

For memory-intensive workloads, NUMA placement matters!</code></pre>
                        </div>
                    </div>

<pre class="language-bash"><code># Check NUMA topology on Linux
$ numactl --hardware
available: 2 nodes (0-1)
node 0 cpus: 0-7
node 0 size: 65536 MB
node 1 cpus: 8-15  
node 1 size: 65536 MB
node distances:
node   0   1 
  0:  10  21    # Local=10, Remote=21 (2.1× slower)
  1:  21  10

# Run process on specific NUMA node
$ numactl --cpunodebind=0 --membind=0 ./my_program

# View NUMA statistics
$ numastat
                           node0           node1
numa_hit              1234567890      987654321
numa_miss                   1234         56789  # Cross-node accesses (bad)
numa_foreign                5678          1234</code></pre>

                    <div class="highlight-box">
                        <i class="fas fa-key me-2"></i>
                        <strong>NUMA Optimization:</strong> Allocate memory on the same node as the threads that use it. Linux's "first touch" policy places pages on the node where they're first accessed. Pre-fault pages in the right context!
                    </div>
                </div>

                <div id="conclusion" class="blog-content mt-5">
                    <h2><i class="fas fa-flag-checkered me-2 text-teal"></i>Conclusion & Next Steps</h2>
                    
                    <p>Memory hierarchy is fundamental to computer performance. We've covered:</p>
                    
                    <ul>
                        <li><strong>Memory Pyramid:</strong> Speed vs capacity trade-offs</li>
                        <li><strong>Locality:</strong> Temporal and spatial access patterns</li>
                        <li><strong>Cache Mapping:</strong> Direct, fully associative, set-associative</li>
                        <li><strong>Replacement:</strong> LRU, FIFO, random policies</li>
                        <li><strong>Write Policies:</strong> Write-through vs write-back</li>
                        <li><strong>Coherence:</strong> MESI protocol for multicore</li>
                        <li><strong>NUMA:</strong> Non-uniform memory access in multi-socket systems</li>
                    </ul>

                    <div class="highlight-box">
                        <i class="fas fa-key me-2"></i>
                        <strong>Key Insight:</strong> Writing cache-friendly code means accessing memory sequentially, reusing data while it's cached, and avoiding false sharing in multithreaded programs.
                    </div>

                    <div class="series-next">
                        <h4><i class="fas fa-arrow-right me-2"></i>Next in the Series</h4>
                        <p>In <a href="comp-arch-memory-management.html"><strong>Part 15: Memory Management Fundamentals</strong></a>, we'll explore how operating systems manage physical memory—address spaces, fragmentation, and allocation strategies.</p>
                    </div>
                </div>

                <div class="related-posts">
                    <h3><i class="fas fa-book me-2"></i>Continue the Computer Architecture & OS Series</h3>
                    <div class="related-post-item">
                        <h5>Part 13: Deadlocks & Prevention</h5>
                        <p>Coffman conditions, detection, and Banker's algorithm.</p>
                        <a href="comp-arch-deadlocks.html">Read Article <i class="fas fa-arrow-right ms-1"></i></a>
                    </div>
                    <div class="related-post-item">
                        <h5>Part 15: Memory Management Fundamentals</h5>
                        <p>Address spaces, fragmentation, and memory allocation.</p>
                        <a href="comp-arch-memory-management.html">Read Article <i class="fas fa-arrow-right ms-1"></i></a>
                    </div>
                    <div class="related-post-item">
                        <h5>Part 19: Multiprocessor Systems</h5>
                        <p>SMP, NUMA, and cache coherence in detail.</p>
                        <a href="comp-arch-multiprocessor.html">Read Article <i class="fas fa-arrow-right ms-1"></i></a>
                    </div>
                </div>

                </div>
            </div>
        </div>
    </section>

    <footer id="social-media" class="bg-dark text-light py-5">
        <div class="container py-5">
            <div class="row mb-4">
                <div class="col-lg-6 mb-4 mb-lg-0">
                    <h5 class="fw-bold mb-3">Let's Connect</h5>
                    <p class="text-light">I'm always interested in sharing content about my interests on different topics. Read disclaimer and feel free to share further.</p>
                </div>
                <div class="col-lg-6">
                    <h5 class="fw-bold mb-3">Follow Me</h5>
                    <div class="social-links d-flex gap-2 flex-wrap">
                        <a href="https://www.facebook.com/wasil.zafar/" target="_blank" class="social-icon" title="Facebook"><i class="fab fa-facebook-f"></i></a>
                        <a href="https://twitter.com/wasilzafar" target="_blank" class="social-icon" title="Twitter"><i class="fab fa-twitter"></i></a>
                        <a href="https://www.linkedin.com/in/wasilzafar" target="_blank" class="social-icon" title="LinkedIn"><i class="fab fa-linkedin-in"></i></a>
                        <a href="https://www.youtube.com/@wasilzafar" target="_blank" class="social-icon" title="YouTube"><i class="fab fa-youtube"></i></a>
                        <a href="https://www.instagram.com/itswzee/" target="_blank" class="social-icon" title="Instagram"><i class="fab fa-instagram"></i></a>
                        <a href="mailto:wasil.zafar@gmail.com" class="social-icon" title="Email"><i class="fas fa-envelope"></i></a>
                    </div>
                </div>
            </div>
            <hr class="bg-secondary">
            <div class="row mt-4">
                <div class="col-md-6">
                    <p class="small"><i class="fas fa-icons me-2"></i>Icons from <a href="https://fontawesome.com/" target="_blank" class="text-light">Font Awesome</a></p>
                    <p class="small mt-3">
                        <a href="/" class="text-light text-decoration-none">Home</a> | 
                        <a href="/disclaimer.html" class="text-light text-decoration-none">Disclaimer</a> | 
                        <a href="/privacy-policy.html" class="text-light text-decoration-none">Privacy Policy</a>
                    </p>
                </div>
                <div class="col-md-6 text-md-end">
                    <p class="small">Enjoying this content? <a href="https://buymeacoffee.com/itswzee" target="_blank" class="text-light" style="text-decoration: underline;">Keep me caffeinated</a> to keep the pixels flowing!</p>
                </div>
            </div>
        </div>
    </footer>

    <button id="scrollToTop" class="scroll-to-top" title="Back to Top"><i class="fas fa-arrow-up"></i></button>
    <div id="categoryIndicator" class="category-indicator"></div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script src="../../../js/main.js"></script>
    <script src="../../../js/cookie-consent.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-c.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/toolbar/prism-toolbar.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/copy-to-clipboard/prism-copy-to-clipboard.min.js"></script>
    <script>
        const themes = { 'prism-theme': 'Tomorrow Night', 'prism-default': 'Default', 'prism-dark': 'Dark', 'prism-twilight': 'Twilight', 'prism-okaidia': 'Okaidia', 'prism-solarizedlight': 'Solarized Light' };
        const savedTheme = localStorage.getItem('prism-theme') || 'prism-theme';
        function switchTheme(themeId) { Object.keys(themes).forEach(id => { const link = document.getElementById(id); if (link) link.disabled = true; }); const selectedLink = document.getElementById(themeId); if (selectedLink) { selectedLink.disabled = false; localStorage.setItem('prism-theme', themeId); } document.querySelectorAll('div.code-toolbar select').forEach(dropdown => { dropdown.value = themeId; }); setTimeout(() => Prism.highlightAll(), 10); }
        document.addEventListener('DOMContentLoaded', function() { switchTheme(savedTheme); });
        Prism.plugins.toolbar.registerButton('theme-switcher', function(env) { const select = document.createElement('select'); select.setAttribute('aria-label', 'Select code theme'); Object.keys(themes).forEach(themeId => { const option = document.createElement('option'); option.value = themeId; option.textContent = themes[themeId]; if (themeId === savedTheme) option.selected = true; select.appendChild(option); }); select.addEventListener('change', function(e) { switchTheme(e.target.value); }); return select; });
    </script>
</body>
</html>
