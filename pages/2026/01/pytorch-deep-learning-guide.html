<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="robots" content="index, archive" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="description" content="Master PyTorch from scratch. Learn tensors, autograd, neural networks, CNNs, RNNs, transfer learning, and deployment. Complete beginner-friendly guide with executable examples." />
    <meta name="author" content="Wasil Zafar" />
    <meta name="keywords" content="PyTorch, Deep Learning, Neural Networks, Python, Machine Learning, CNN, RNN, LSTM, Transfer Learning, GPU, Autograd, TorchScript" />
    <meta property="og:title" content="PyTorch Deep Learning: Complete Beginner's Guide to Building Neural Networks" />
    <meta property="og:description" content="Learn PyTorch fundamentals: tensors, autograd, building neural networks, CNNs, RNNs, transfer learning, and deployment. Beginner-friendly with hands-on examples." />
    <meta property="og:type" content="article" />
    <meta property="article:published_time" content="2026-01-01" />
    <meta property="article:author" content="Wasil Zafar" />
    <meta property="article:section" content="Technology" />
    
    <title>PyTorch Deep Learning: Complete Beginner's Guide to Building Neural Networks - Wasil Zafar</title>

    <!-- Bootstrap 5 CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    
    <!-- Font Awesome Icons -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet" />

    <!-- Google Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=DM+Sans:wght@400;500;600;700&family=Poppins:wght@300;400;500;600;700&family=Playfair+Display:wght@600;700&display=swap" rel="stylesheet" />

    <!-- Custom Styles -->
    <link rel="stylesheet" href="../../../css/main.css" type="text/css" />

    <!-- Prism.js Syntax Highlighting -->
    <!-- Multiple themes for dynamic switching -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" id="prism-theme" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" id="prism-default" disabled />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-dark.min.css" id="prism-dark" disabled />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-twilight.min.css" id="prism-twilight" disabled />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-okaidia.min.css" id="prism-okaidia" disabled />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-solarizedlight.min.css" id="prism-solarizedlight" disabled />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/toolbar/prism-toolbar.min.css" />

    <!-- Favicon -->
    <link rel="apple-touch-icon" sizes="180x180" href="../../../images/favicon_io/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../../../images/favicon_io/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../../../images/favicon_io/favicon-16x16.png">
    <link rel="manifest" href="../../../images/favicon_io/site.webmanifest">

    <!-- Google Consent Mode v2 -->
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        
        gtag('consent', 'default', {
            'ad_storage': 'denied',
            'ad_user_data': 'denied',
            'ad_personalization': 'denied',
            'analytics_storage': 'denied',
            'region': ['AT','BE','BG','HR','CY','CZ','DK','EE','FI','FR','DE','GR','HU','IE','IT','LV','LT','LU','MT','NL','PL','PT','RO','SK','SI','ES','SE']
        });
        
        gtag('consent', 'default', {
            'ad_storage': 'granted',
            'ad_user_data': 'granted',
            'ad_personalization': 'granted',
            'analytics_storage': 'granted'
        });
        
        gtag('set', 'url_passthrough', true);
    </script>

    <!-- Google Tag Manager -->
    <script>
        (function(w, d, s, l, i) {
            w[l] = w[l] || [];
            w[l].push({
                'gtm.start': new Date().getTime(),
                event: 'gtm.js'
            });
            var f = d.getElementsByTagName(s)[0],
                j = d.createElement(s),
                dl = l != 'dataLayer' ? '&l=' + l : '';
            j.async = true;
            j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
            f.parentNode.insertBefore(j, f);
        })(window, document, 'script', 'dataLayer', 'GTM-PBS8M2JR');
    </script>

    <style>
        /* Blog Post Specific Styles */
        .blog-hero {
            background: linear-gradient(135deg, var(--color-navy) 0%, var(--color-blue) 100%);
            color: white;
            padding: 80px 0;
        }

        .blog-header {
            margin-bottom: 2rem;
        }

        .blog-meta {
            font-size: 0.95rem;
            color: var(--color-teal);
            margin-bottom: 1rem;
        }

        .blog-meta span {
            margin-right: 1.5rem;
        }

        .blog-content {
            max-width: 900px;
            margin: 0 auto;
            font-size: 1.05rem;
            line-height: 1.8;
            color: #333;
        }

        .blog-content h2 {
            font-size: 1.8rem;
            font-weight: 700;
            margin-top: 2.5rem;
            margin-bottom: 1.5rem;
            color: var(--color-navy);
            border-bottom: 3px solid var(--color-teal);
            padding-bottom: 0.5rem;
        }

        .blog-content h3 {
            font-size: 1.3rem;
            font-weight: 600;
            margin-top: 2rem;
            margin-bottom: 1rem;
            color: var(--color-blue);
        }

        .blog-content p {
            margin-bottom: 1.2rem;
            text-align: justify;
        }

        .blog-content strong {
            color: var(--color-crimson);
        }

        .highlight-box {
            background: rgba(59, 151, 151, 0.1);
            border-left: 4px solid var(--color-teal);
            padding: 1.5rem;
            margin: 2rem 0;
            border-radius: 4px;
        }

        .experiment-card {
            background: #f8f9fa;
            border: 1px solid #ddd;
            border-radius: 8px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
            transition: all 0.3s ease;
        }

        .experiment-card:hover {
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
            transform: translateY(-2px);
        }

        .experiment-card h4 {
            color: var(--color-crimson);
            font-weight: 700;
            margin-bottom: 0.5rem;
        }

        .experiment-card .card-meta {
            font-size: 0.9rem;
            color: var(--color-blue);
            margin-bottom: 1rem;
            font-style: italic;
        }

        .card-meta .badge {
            font-size: 0.85rem;
            font-weight: 600;
            padding: 0.5rem 1rem;
            margin-right: 0.5rem;
            letter-spacing: 0.3px;
        }

        .bg-teal {
            background-color: var(--color-teal) !important;
        }

        .bg-crimson {
            background-color: var(--color-crimson) !important;
        }

        .toc-box {
            background: #f8f9fa;
            border: 2px solid var(--color-teal);
            border-radius: 8px;
            padding: 1.5rem;
            margin: 2rem 0;
        }

        .toc-box h3 {
            color: var(--color-navy);
            font-weight: 700;
            margin-bottom: 1rem;
            border: none;
            margin-top: 0;
        }

        .toc-box ol {
            margin-bottom: 0;
            padding-left: 1.5rem;
        }

        .toc-box li {
            margin-bottom: 0.5rem;
        }

        .toc-box a {
            color: var(--color-blue);
            text-decoration: none;
            transition: color 0.2s ease;
        }

        .toc-box a:hover {
            color: var(--color-crimson);
            text-decoration: underline;
        }

        .reading-time {
            display: inline-block;
            background: var(--color-crimson);
            color: white;
            padding: 0.3rem 0.8rem;
            border-radius: 4px;
            font-size: 0.9rem;
        }

        .back-link {
            display: inline-block;
            color: white;
            text-decoration: none;
            transition: all 0.3s ease;
            margin-bottom: 1rem;
            opacity: 0.9;
        }

        .back-link:hover {
            color: var(--color-teal);
            opacity: 1;
            transform: translateX(-5px);
        }

        .related-posts {
            background: #f8f9fa;
            border-radius: 8px;
            padding: 2rem;
            margin-top: 3rem;
        }

        .related-posts h3 {
            color: var(--color-navy);
            margin-bottom: 1.5rem;
        }

        .related-post-item {
            padding: 1rem;
            border-left: 3px solid var(--color-teal);
            margin-bottom: 1rem;
            transition: all 0.3s ease;
        }

        .related-post-item:hover {
            background: white;
            border-left-color: var(--color-crimson);
        }

        .related-post-item a {
            color: var(--color-blue);
            text-decoration: none;
            font-weight: 600;
        }

        .related-post-item a:hover {
            color: var(--color-crimson);
        }

        /* Code Block Styles */
        pre[class*="language-"] {
            position: relative;
            margin: 1.5rem 0;
            padding-top: 3rem;
            border-radius: 8px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
        }

        code[class*="language-"] {
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
        }

        /* Toolbar styling */
        div.code-toolbar > .toolbar {
            opacity: 1;
            display: flex;
            gap: 0.5rem;
        }

        div.code-toolbar > .toolbar > .toolbar-item > button {
            background: var(--color-teal);
            color: white;
            border: none;
            padding: 0.4rem 0.8rem;
            border-radius: 4px;
            font-size: 0.85rem;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        div.code-toolbar > .toolbar > .toolbar-item > button:hover {
            background: var(--color-blue);
            transform: translateY(-1px);
        }

        div.code-toolbar > .toolbar > .toolbar-item > button:focus {
            outline: 2px solid var(--color-teal);
            outline-offset: 2px;
        }

        /* Theme switcher dropdown */
        div.code-toolbar > .toolbar > .toolbar-item > select {
            background: var(--color-navy);
            color: white;
            border: 1px solid var(--color-teal);
            padding: 0.4rem 0.8rem;
            border-radius: 4px;
            font-size: 0.85rem;
            cursor: pointer;
            transition: all 0.3s ease;
            outline: none;
        }

        div.code-toolbar > .toolbar > .toolbar-item > select:hover {
            background: var(--color-blue);
            border-color: var(--color-crimson);
        }

        div.code-toolbar > .toolbar > .toolbar-item > select:focus {
            outline: 2px solid var(--color-teal);
            outline-offset: 2px;
        }

        /* Style select options */
        div.code-toolbar > .toolbar > .toolbar-item > select option {
            background: var(--color-navy);
            color: white;
        }

        /* Scroll-to-Top Button */
        .scroll-to-top {
            position: fixed;
            bottom: 2rem;
            right: 2rem;
            width: 50px;
            height: 50px;
            background: var(--color-teal);
            color: white;
            border: none;
            border-radius: 50%;
            font-size: 1.2rem;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
            opacity: 0;
            visibility: hidden;
            transition: all 0.3s ease;
            box-shadow: 0 4px 12px rgba(59, 151, 151, 0.3);
            z-index: 999;
        }

        .scroll-to-top.show {
            opacity: 1;
            visibility: visible;
        }

        .scroll-to-top:hover {
            background: var(--color-crimson);
            transform: translateY(-3px);
            box-shadow: 0 6px 16px rgba(191, 9, 47, 0.4);
        }

        .scroll-to-top:active {
            transform: translateY(-1px);
        }

        @media (max-width: 768px) {
            .scroll-to-top {
                bottom: 1rem;
                right: 1rem;
                width: 45px;
                height: 45px;
                font-size: 1rem;
            }
        }

        .related-posts {
            margin-top: 3rem;
            padding-top: 2rem;
            border-top: 2px solid var(--color-teal);
        }

        .related-post-item {
            margin-bottom: 1rem;
        }

        .related-post-item a {
            color: var(--color-blue);
            text-decoration: none;
            font-weight: 600;
        }

        .related-post-item a:hover {
            color: var(--color-crimson);
        }
    </style>
</head>
<body>
    <!-- Google Tag Manager (noscript) -->
    <noscript>
        <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-PBS8M2JR" height="0" width="0" style="display:none;visibility:hidden"></iframe>
    </noscript>

    <!-- Navigation Bar -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark shadow-sm">
        <div class="container-fluid">
            <a class="navbar-brand fw-bold" href="/">
                <span class="gradient-text">Wasil Zafar</span>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="/">Home</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="/#about">About</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="/#skills">Skills</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="/#certifications">Certifications</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="/#interests">Interests</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Hero Section -->
    <section class="blog-hero">
        <div class="container py-5">
            <div class="blog-header">
                <a href="/pages/categories/technology.html" class="back-link">
                    <i class="fas fa-arrow-left me-2"></i>Back to Technology
                </a>
                <h1 class="display-4 fw-bold mb-3">PyTorch Deep Learning: Complete Beginner's Guide to Building Neural Networks</h1>
                <div class="blog-meta">
                    <span><i class="fas fa-calendar me-2"></i>January 1, 2026</span>
                    <span><i class="fas fa-user me-2"></i>Wasil Zafar</span>
                    <span class="reading-time"><i class="fas fa-clock me-1"></i>40 min read</span>
                </div>
                <p class="lead">Master PyTorch from the ground up—learn tensors, automatic differentiation, neural network construction, training loops, CNNs, RNNs, transfer learning, and production deployment. A comprehensive hands-on guide with executable code examples.</p>
            </div>
        </div>
    </section>

    <!-- Main Content -->
    <section class="py-5">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 mx-auto">
                    
                    <!-- Table of Contents -->
                    <div class="toc-box">
                        <h3><i class="fas fa-list me-2"></i>Table of Contents</h3>
                        <ol>
                            <li><a href="#introduction">What is PyTorch?</a></li>
                            <li><a href="#installation">Installation & Setup</a></li>
                            <li><a href="#tensors">Tensors: The Foundation</a></li>
                            <li><a href="#operations">Tensor Operations & Manipulations</a></li>
                            <li><a href="#autograd">Autograd: Automatic Differentiation</a></li>
                            <li><a href="#nn-module">Building Neural Networks with nn.Module</a></li>
                            <li><a href="#activations">Activation Functions & Initialization</a></li>
                            <li><a href="#optimizers">Optimizers & Learning Rate Scheduling</a></li>
                            <li><a href="#datasets">Datasets & DataLoaders</a></li>
                            <li><a href="#training-loop">The Training Loop</a></li>
                            <li><a href="#evaluation">Model Evaluation & Metrics</a></li>
                            <li><a href="#saving">Saving & Loading Models</a></li>
                            <li><a href="#gpu">GPU Acceleration & Device Management</a></li>
                            <li><a href="#mixed-precision">Mixed Precision Training</a></li>
                            <li><a href="#custom-dataset">Custom Datasets & Transforms</a></li>
                            <li><a href="#transfer-learning">Transfer Learning with Pretrained Models</a></li>
                            <li><a href="#cnn">Convolutional Neural Networks (CNNs)</a></li>
                            <li><a href="#rnn">Recurrent Neural Networks (RNNs & LSTMs)</a></li>
                            <li><a href="#embeddings">Embeddings for NLP</a></li>
                            <li><a href="#advanced">Advanced Training Techniques</a></li>
                            <li><a href="#custom-layers">Custom Layers & Loss Functions</a></li>
                            <li><a href="#interpretability">Model Interpretability (Grad-CAM)</a></li>
                            <li><a href="#deployment">Deployment with TorchScript</a></li>
                            <li><a href="#best-practices">Best Practices & Common Pitfalls</a></li>
                        </ol>
                    </div>

                    <!-- Introduction -->
                    <div id="introduction" class="blog-content mt-5">
                        <h2><i class="fas fa-rocket me-2 text-teal"></i>What is PyTorch?</h2>
                        
                        <p>PyTorch is an open-source deep learning framework developed by Facebook's AI Research lab (FAIR). It has rapidly become one of the most popular frameworks in both research and production environments due to its <strong>flexibility, ease of use, and Pythonic design</strong>.</p>

                        <p>Unlike static graph frameworks, PyTorch uses <strong>dynamic computation graphs</strong> (define-by-run), which means the graph is built on-the-fly during forward passes. This makes debugging intuitive and enables complex architectures with varying control flow.</p>

                        <div class="highlight-box">
                            <i class="fas fa-lightbulb"></i>
                            <strong>Why PyTorch?</strong> It combines the flexibility of NumPy with the power of GPU acceleration and automatic differentiation. You write standard Python code, and PyTorch handles gradient computation automatically—making it perfect for rapid prototyping and research.
                        </div>

                        <div class="experiment-card">
                            <div class="card-meta mb-2">
                                <span class="badge bg-teal text-white">Key Concepts</span>
                            </div>
                            <div class="card-content">
                                <ul>
                                    <li><strong>Tensors:</strong> Multi-dimensional arrays (like NumPy) optimized for GPU computation</li>
                                    <li><strong>Autograd:</strong> Automatic differentiation engine for computing gradients</li>
                                    <li><strong>nn.Module:</strong> Base class for building neural network layers and models</li>
                                    <li><strong>Optimizers:</strong> Algorithms (SGD, Adam) that update model parameters</li>
                                    <li><strong>DataLoader:</strong> Efficient data loading with batching, shuffling, and parallel processing</li>
                                </ul>
                            </div>
                            <div class="card-tags">
                                <span class="bias-tag">Deep Learning</span>
                                <span class="bias-tag">Research-Friendly</span>
                                <span class="bias-tag">Production-Ready</span>
                            </div>
                        </div>

                        <p><strong>When to use PyTorch:</strong></p>
                        <ul>
                            <li>Building custom neural network architectures with complex control flow</li>
                            <li>Research projects requiring flexibility and rapid experimentation</li>
                            <li>Projects needing GPU acceleration for tensor operations</li>
                            <li>Production deployments with TorchScript for optimized inference</li>
                            <li>Computer vision, NLP, reinforcement learning, or any deep learning task</li>
                        </ul>
                    </div>

                    <!-- Installation -->
                    <div id="installation" class="blog-content mt-5">
                        <h2><i class="fas fa-download me-2 text-teal"></i>Installation & Setup</h2>
                        
                        <p>PyTorch installation varies based on your system configuration (CPU vs GPU, CUDA version). Visit <a href="https://pytorch.org/get-started/locally/" target="_blank">pytorch.org</a> for the latest installation commands tailored to your setup.</p>

                        <h3>CPU-Only Installation</h3>
                        <pre><code class="language-bash"># Install PyTorch (CPU version)
pip install torch torchvision torchaudio

# Verify installation
python -c "import torch; print('PyTorch version:', torch.__version__)"</code></pre>

                        <h3>GPU Installation (CUDA-enabled)</h3>
                        <pre><code class="language-bash"># Example: PyTorch with CUDA 12.1 support
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# Verify GPU availability
python -c "import torch; print('CUDA available:', torch.cuda.is_available())"</code></pre>

                        <h3>Verify Installation</h3>
                        <pre><code class="language-python"># Import PyTorch and check configuration
import torch
import torchvision
import torchaudio
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

# Display version and device information
print('PyTorch version:', torch.__version__)
print('CUDA available:', torch.cuda.is_available())
print('CUDA device count:', torch.cuda.device_count())
if torch.cuda.is_available():
    print('Current CUDA device:', torch.cuda.current_device())
    print('Device name:', torch.cuda.get_device_name(0))</code></pre>

                        <div class="highlight-box">
                            <i class="fas fa-info-circle"></i>
                            <strong>GPU Recommendation:</strong> If you have an NVIDIA GPU with CUDA support, installing the GPU version will significantly speed up training. Deep learning benefits massively from parallel GPU computation—training times can be 10-100x faster compared to CPU.
                        </div>
                    </div>

                    <!-- Tensors -->
                    <div id="tensors" class="blog-content mt-5">
                        <h2><i class="fas fa-cubes me-2 text-teal"></i>Tensors: The Foundation</h2>
                        
                        <p>Tensors are the fundamental data structure in PyTorch—multi-dimensional arrays similar to NumPy ndarrays but with GPU acceleration and automatic differentiation support. Everything in PyTorch operates on tensors.</p>

                        <h3>Creating Tensors</h3>
                        <pre><code class="language-python">import torch
import numpy as np

# Create tensor from Python list
a = torch.tensor([1, 2, 3], dtype=torch.int32)
print('Tensor a:', a)
# Output: tensor([1, 2, 3], dtype=torch.int32)

# Create 2D tensor with random values from standard normal distribution
b = torch.randn(2, 3)  # 2 rows, 3 columns
print('Tensor b shape:', b.shape)  # torch.Size([2, 3])
print('Tensor b dtype:', b.dtype)  # torch.float32 (default)
print('Tensor b:\n', b)</code></pre>

                        <h3>NumPy Interoperability</h3>
                        <pre><code class="language-python">import torch
import numpy as np

# Convert NumPy array to PyTorch tensor
np_array = np.array([[10, 20], [30, 40]], dtype=np.float32)
tensor_from_numpy = torch.from_numpy(np_array)
print('From NumPy:', tensor_from_numpy)
# Output: tensor([[10., 20.], [30., 40.]])

# Convert PyTorch tensor back to NumPy array
# WARNING: This shares memory with the original tensor!
back_to_numpy = tensor_from_numpy.numpy()
print('Back to NumPy:', back_to_numpy)
print('Type:', type(back_to_numpy))  # <class 'numpy.ndarray'>

# Modifying one affects the other (shared memory)
tensor_from_numpy[0, 0] = 99
print('Modified NumPy array:', back_to_numpy)  # [[99., 20.], [30., 40.]]</code></pre>

                        <h3>Common Tensor Creation Functions</h3>
                        <pre><code class="language-python">import torch

# Zeros tensor: all elements are 0
zeros = torch.zeros(3, 4)  # 3x4 matrix of zeros
print('Zeros shape:', zeros.shape)  # torch.Size([3, 4])

# Ones tensor: all elements are 1
ones = torch.ones(2, 3)
print('Ones:\n', ones)

# Empty tensor: uninitialized values (whatever was in memory)
# Faster than zeros/ones but values are garbage
empty = torch.empty(2, 2)
print('Empty (uninitialized):\n', empty)

# Range tensor: evenly spaced values (like NumPy arange)
# arange(start, end, step) - end is exclusive
range_tensor = torch.arange(0, 10, 2)  # [0, 2, 4, 6, 8]
print('Range:', range_tensor)

# Linspace: evenly spaced values including both endpoints
linspace = torch.linspace(0, 1, 5)  # 5 values from 0 to 1
print('Linspace:', linspace)  # [0.0, 0.25, 0.5, 0.75, 1.0]

# Identity matrix: diagonal ones, rest zeros
identity = torch.eye(3)  # 3x3 identity matrix
print('Identity:\n', identity)

# Random tensors
rand_uniform = torch.rand(2, 3)  # Uniform distribution [0, 1)
rand_normal = torch.randn(2, 3)  # Standard normal distribution (mean=0, std=1)
rand_int = torch.randint(0, 10, (3, 3))  # Random integers in [0, 10)
print('Random uniform:\n', rand_uniform)
print('Random normal:\n', rand_normal)
print('Random integers:\n', rand_int)</code></pre>

                        <h3>Tensor Attributes</h3>
                        <pre><code class="language-python">import torch

# Create sample tensor
tensor = torch.randn(2, 3, 4)  # 3D tensor

# Shape: dimensions of the tensor
print('Shape:', tensor.shape)  # torch.Size([2, 3, 4])
print('Size:', tensor.size())  # Same as shape: torch.Size([2, 3, 4])

# Number of dimensions
print('Number of dimensions:', tensor.ndim)  # 3

# Total number of elements
print('Total elements:', tensor.numel())  # 2 * 3 * 4 = 24

# Data type
print('Data type:', tensor.dtype)  # torch.float32

# Device (CPU or GPU)
print('Device:', tensor.device)  # cpu or cuda:0

# Check if requires gradient tracking
print('Requires grad:', tensor.requires_grad)  # False by default

# Memory layout (row-major by default)
print('Is contiguous:', tensor.is_contiguous())  # True</code></pre>

                        <div class="highlight-box">
                            <i class="fas fa-exclamation-triangle"></i>
                            <strong>Memory Efficiency:</strong> Tensors created with <code>from_numpy()</code> share memory with the original NumPy array. Modifying one affects the other. Use <code>.clone()</code> if you need an independent copy: <code>independent = tensor_from_numpy.clone()</code>
                        </div>
                    </div>

                    <!-- Tensor Operations -->
                    <div id="operations" class="blog-content mt-5">
                        <h2><i class="fas fa-calculator me-2 text-teal"></i>Tensor Operations & Manipulations</h2>
                        
                        <p>PyTorch provides a rich set of operations for manipulating tensors—from basic arithmetic to advanced reshaping and slicing. Most operations have both functional (<code>torch.add()</code>) and method (<code>tensor.add()</code>) forms.</p>

                        <h3>Reshaping & Views</h3>
                        <pre><code class="language-python">import torch

# Create 1D tensor with 12 elements
x = torch.arange(12)  # [0, 1, 2, ..., 11]
print('Original:', x)

# Reshape to 2D (3 rows, 4 columns)
# view() returns a new tensor sharing the same data (no copy)
x_2d = x.view(3, 4)
print('Reshaped to 3x4:\n', x_2d)
# tensor([[ 0,  1,  2,  3],
#         [ 4,  5,  6,  7],
#         [ 8,  9, 10, 11]])

# Transpose: swap dimensions
# t() works only for 2D tensors
x_transposed = x_2d.t()
print('Transposed (4x3):\n', x_transposed)

# Automatic dimension inference with -1
# PyTorch calculates the missing dimension
auto_shape = x.view(4, -1)  # -1 means "figure this out" (becomes 3)
print('Auto-shaped (4, 3):', auto_shape.shape)  # torch.Size([4, 3])

# WARNING: view() requires contiguous memory
# If tensor is not contiguous, use reshape() instead
x_permuted = x_2d.permute(1, 0)  # Swap dimensions (now non-contiguous)
try:
    x_view = x_permuted.view(-1)  # This will fail!
except RuntimeError as e:
    print('Error:', str(e)[:50])  # "view size is not compatible..."

# reshape() handles non-contiguous tensors (may copy data)
x_reshaped = x_permuted.reshape(-1)
print('Reshaped from non-contiguous:', x_reshaped.shape)</code></pre>

                        <h3>Slicing & Indexing</h3>
                        <pre><code class="language-python">import torch

# Create 2D tensor
matrix = torch.tensor([[1, 2, 3],
                       [4, 5, 6],
                       [7, 8, 9]])

# Access single element (returns 0D tensor)
element = matrix[1, 2]  # Row 1, Column 2 (value: 6)
print('Element [1, 2]:', element)  # tensor(6)
print('As Python scalar:', element.item())  # 6

# Access entire row
row = matrix[0, :]  # Row 0, all columns
print('First row:', row)  # tensor([1, 2, 3])

# Access entire column
column = matrix[:, 1]  # All rows, column 1
print('Second column:', column)  # tensor([2, 5, 8])

# Slice submatrix
submatrix = matrix[0:2, 1:3]  # Rows 0-1, columns 1-2
print('Submatrix:\n', submatrix)
# tensor([[2, 3],
#         [5, 6]])

# Advanced indexing with lists
rows = matrix[[0, 2], :]  # Select rows 0 and 2
print('Rows 0 and 2:\n', rows)

# Boolean masking
mask = matrix > 5  # Create boolean mask
print('Mask (elements > 5):\n', mask)
filtered = matrix[mask]  # Extract elements where mask is True
print('Filtered values:', filtered)  # tensor([6, 7, 8, 9])</code></pre>

                        <h3>Arithmetic Operations (Element-wise)</h3>
                        <pre><code class="language-python">import torch

# Create sample tensors
a = torch.tensor([1, 2, 3, 4])
b = torch.tensor([10, 20, 30, 40])

# Element-wise addition
print('Addition:', a + b)  # tensor([11, 22, 33, 44])

# Element-wise multiplication
print('Multiplication:', a * b)  # tensor([10, 40, 90, 160])

# Element-wise division
print('Division:', b / a)  # tensor([10., 10., 10., 10.])

# Power
print('a squared:', a ** 2)  # tensor([1, 4, 9, 16])

# Universal functions (ufuncs)
print('Square root:', torch.sqrt(a.float()))  # tensor([1.0, 1.414, 1.732, 2.0])
print('Exponential:', torch.exp(a.float()))  # tensor([2.718, 7.389, 20.086, 54.598])
print('Sine:', torch.sin(a.float()))  # tensor([0.841, 0.909, 0.141, -0.757])
print('Natural log:', torch.log(a.float()))  # tensor([0.0, 0.693, 1.099, 1.386])

# In-place operations (modify tensor directly, denoted by underscore suffix)
a.add_(10)  # Add 10 to all elements in-place
print('After in-place add:', a)  # tensor([11, 12, 13, 14])</code></pre>

                        <h3>Matrix Operations</h3>
                        <pre><code class="language-python">import torch

# Matrix multiplication (dot product)
A = torch.tensor([[1, 2], [3, 4]])  # 2x2 matrix
B = torch.tensor([[5, 6], [7, 8]])  # 2x2 matrix

# @ operator for matrix multiplication (recommended)
C = A @ B
print('Matrix multiplication (A @ B):\n', C)
# tensor([[19, 22],
#         [43, 50]])

# Alternative: torch.matmul()
C_alt = torch.matmul(A, B)
print('Same result:', torch.equal(C, C_alt))  # True

# Batch matrix multiplication (3D tensors)
batch_a = torch.randn(10, 3, 4)  # 10 matrices of size 3x4
batch_b = torch.randn(10, 4, 5)  # 10 matrices of size 4x5
batch_c = batch_a @ batch_b  # Result: 10 matrices of size 3x5
print('Batch matmul shape:', batch_c.shape)  # torch.Size([10, 3, 5])

# Element-wise matrix multiplication (Hadamard product)
hadamard = A * B  # NOT matrix multiplication!
print('Element-wise multiplication:\n', hadamard)
# tensor([[ 5, 12],
#         [21, 32]])</code></pre>

                        <h3>Concatenation & Stacking</h3>
                        <pre><code class="language-python">import torch

# Create sample tensors
x = torch.tensor([[1, 2], [3, 4]])
y = torch.tensor([[5, 6], [7, 8]])

# Concatenate along rows (dimension 0)
# Stacks vertically - increases number of rows
concat_rows = torch.cat([x, y], dim=0)
print('Concatenate rows (dim=0):\n', concat_rows)
# tensor([[1, 2],
#         [3, 4],
#         [5, 6],
#         [7, 8]])
print('Shape:', concat_rows.shape)  # torch.Size([4, 2])

# Concatenate along columns (dimension 1)
# Stacks horizontally - increases number of columns
concat_cols = torch.cat([x, y], dim=1)
print('Concatenate columns (dim=1):\n', concat_cols)
# tensor([[1, 2, 5, 6],
#         [3, 4, 7, 8]])
print('Shape:', concat_cols.shape)  # torch.Size([2, 4])

# Stack: adds new dimension
# Creates 3D tensor by stacking 2D tensors
stacked = torch.stack([x, y], dim=0)
print('Stacked (dim=0) shape:', stacked.shape)  # torch.Size([2, 2, 2])
print('Stacked:\n', stacked)
# tensor([[[1, 2],
#          [3, 4]],
#         [[5, 6],
#          [7, 8]]])</code></pre>

                        <div class="highlight-box">
                            <i class="fas fa-bolt"></i>
                            <strong>Performance Tip:</strong> In-place operations (suffix <code>_</code>) modify tensors directly without allocating new memory. Use them carefully—they save memory but can interfere with autograd if the tensor requires gradients. Avoid in-place ops on tensors involved in gradient computation.
                        </div>
                    </div>

                    <!-- Autograd -->
                    <div id="autograd" class="blog-content mt-5">
                        <h2><i class="fas fa-project-diagram me-2 text-teal"></i>Autograd: Automatic Differentiation</h2>
                        
                        <p>Autograd is PyTorch's automatic differentiation engine—the magic behind neural network training. It automatically computes gradients (derivatives) of tensor operations, eliminating the need for manual backpropagation calculations.</p>

                        <p>When you set <code>requires_grad=True</code> on a tensor, PyTorch tracks all operations performed on it. Calling <code>.backward()</code> automatically computes gradients for all tensors in the computational graph.</p>

                        <h3>Basic Gradient Computation</h3>
                        <pre><code class="language-python">import torch

# Create tensor with gradient tracking enabled
# This tells PyTorch: "I want to compute gradients for this tensor"
x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)
print('x:', x)
print('x.requires_grad:', x.requires_grad)  # True

# Perform operations
# PyTorch builds a computation graph behind the scenes
y = x ** 2  # y = x²
z = y.sum()  # z = sum(y) = x₁² + x₂² + x₃²

print('z:', z)  # tensor(14., grad_fn=<SumBackward0>)
print('z.grad_fn:', z.grad_fn)  # Shows the operation that created z

# Compute gradients via backpropagation
# This computes dz/dx for all x values
z.backward()

# Access gradients: dz/dx = 2x
print('x.grad:', x.grad)  # tensor([2., 4., 6.])
# Explanation: d(x₁² + x₂² + x₃²)/dx = [2x₁, 2x₂, 2x₃] = [2*1, 2*2, 2*3]</code></pre>

                        <h3>Multiple Backward Passes (Gradient Accumulation)</h3>
                        <pre><code class="language-python">import torch

# Gradients accumulate by default!
x = torch.tensor([1.0, 2.0], requires_grad=True)

# First computation
y1 = (x ** 2).sum()
y1.backward()  # Compute gradients
print('After first backward:', x.grad)  # tensor([2., 4.])

# Second computation WITHOUT zeroing gradients
# Gradients will ACCUMULATE (add to existing gradients)
y2 = (x ** 3).sum()
y2.backward()
print('After second backward (accumulated):', x.grad)  # tensor([5., 16.])
# Expected: [2 + 3*1², 4 + 3*2²] = [2+3, 4+12] = [5, 16]

# CRITICAL: Always zero gradients before new backward pass in training!
x.grad.zero_()  # Reset gradients to zero
y3 = (x ** 2).sum()
y3.backward()
print('After zeroing and new backward:', x.grad)  # tensor([2., 4.])</code></pre>

                        <h3>Detaching from Computation Graph</h3>
                        <pre><code class="language-python">import torch

x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)
y = x ** 2

# Detach: create a tensor without gradient tracking
# Useful when you want to use values without affecting gradients
y_detached = y.detach()
print('y_detached.requires_grad:', y_detached.requires_grad)  # False

# Operations on detached tensor won't be tracked
z = y_detached * 2
# z.backward() would fail because z has no grad_fn

# Alternative: torch.no_grad() context manager
# Temporarily disables gradient tracking for all operations
with torch.no_grad():
    y_no_grad = x ** 3
    z_no_grad = y_no_grad.sum()
    print('z_no_grad.requires_grad:', z_no_grad.requires_grad)  # False

# Use no_grad during inference to save memory and speed up computation</code></pre>

                        <h3>Gradient Flow Example</h3>
                        <pre><code class="language-python">import torch

# Simulate a simple neural network computation
# Input → Weight multiplication → Activation → Loss

# Create learnable weights (parameters)
w = torch.randn(3, 3, requires_grad=True)
b = torch.randn(3, requires_grad=True)

# Input data (no gradient needed for inputs)
x = torch.randn(5, 3)  # 5 samples, 3 features

# Forward pass: compute predictions
# Linear transformation: y = xW + b
out = x @ w + b  # @ is matrix multiplication
print('Output shape:', out.shape)  # torch.Size([5, 3])

# Compute loss (mean squared error)
# In real training, you'd compare with actual labels
loss = out.pow(2).mean()  # L = mean((out)²)
print('Loss:', loss.item())  # Scalar value

# Backward pass: compute gradients
loss.backward()

# Check gradients
print('w.grad shape:', w.grad.shape)  # torch.Size([3, 3])
print('b.grad shape:', b.grad.shape)  # torch.Size([3])
print('Weight gradient (first 3 values):', w.grad.flatten()[:3])

# These gradients tell us how to adjust w and b to reduce loss
# Optimizers use these gradients to update parameters</code></pre>

                        <div class="highlight-box">
                            <i class="fas fa-brain"></i>
                            <strong>How Autograd Works:</strong> PyTorch builds a <strong>Dynamic Computation Graph</strong> during the forward pass. Each operation creates a node storing the operation and its inputs. When you call <code>.backward()</code>, PyTorch traverses this graph in reverse (backpropagation), applying the chain rule to compute gradients for all tensors with <code>requires_grad=True</code>.
                        </div>

                        <div class="experiment-card">
                            <div class="card-meta mb-2">
                                <span class="badge bg-teal text-white">Common Autograd Patterns</span>
                            </div>
                            <div class="card-content">
                                <ul>
                                    <li><strong>Training:</strong> Enable gradients with <code>requires_grad=True</code> for parameters</li>
                                    <li><strong>Inference:</strong> Disable gradients with <code>torch.no_grad()</code> to save memory</li>
                                    <li><strong>Zero Gradients:</strong> Call <code>optimizer.zero_grad()</code> before each backward pass</li>
                                    <li><strong>Gradient Clipping:</strong> Prevent exploding gradients with <code>torch.nn.utils.clip_grad_norm_()</code></li>
                                    <li><strong>Detach:</strong> Use <code>.detach()</code> to break gradient flow when needed</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <!-- nn.Module -->
                    <div id="nn-module" class="blog-content mt-5">
                        <h2><i class="fas fa-network-wired me-2 text-teal"></i>Building Neural Networks with nn.Module</h2>
                        
                        <p>The <code>nn.Module</code> class is the foundation for building neural networks in PyTorch. All models inherit from this base class, which provides essential functionality for parameter management, device transfer, and training/evaluation modes.</p>

                        <h3>Basic Neural Network Structure</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn

# Define a simple feedforward neural network
class SimpleNet(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(SimpleNet, self).__init__()  # Initialize parent class
        
        # Define layers as instance attributes
        # PyTorch automatically tracks these as parameters
        self.fc1 = nn.Linear(input_size, hidden_size)  # Input → Hidden
        self.fc2 = nn.Linear(hidden_size, output_size)  # Hidden → Output
        self.relu = nn.ReLU()  # Activation function
    
    def forward(self, x):
        # Define forward pass: how data flows through the network
        x = self.fc1(x)      # Apply first linear transformation
        x = self.relu(x)     # Apply activation
        x = self.fc2(x)      # Apply second linear transformation
        return x

# Create model instance
model = SimpleNet(input_size=10, hidden_size=20, output_size=5)
print(model)
# Output shows model architecture:
# SimpleNet(
#   (fc1): Linear(in_features=10, out_features=20, bias=True)
#   (fc2): Linear(in_features=20, out_features=5, bias=True)
#   (relu): ReLU()
# )

# Count total parameters
total_params = sum(p.numel() for p in model.parameters())
print(f'Total parameters: {total_params}')
# fc1: 10*20 + 20 = 220, fc2: 20*5 + 5 = 105, Total: 325</code></pre>

                        <h3>Forward Pass Example</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn

# Create model
class SimpleNet(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(SimpleNet, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, output_size)
        self.relu = nn.ReLU()
    
    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x

model = SimpleNet(input_size=10, hidden_size=20, output_size=5)

# Create batch of input data (32 samples, 10 features each)
batch = torch.randn(32, 10)

# Forward pass: model(batch) calls forward() automatically
output = model(batch)
print('Output shape:', output.shape)  # torch.Size([32, 5])
print('Output (first sample):', output[0])  # 5 logits for this sample</code></pre>

                        <h3>nn.Sequential: Quick Model Building</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn

# Sequential allows building models without defining forward()
# Layers execute in order automatically
model = nn.Sequential(
    nn.Linear(10, 20),      # Layer 1
    nn.ReLU(),              # Activation 1
    nn.Linear(20, 20),      # Layer 2
    nn.ReLU(),              # Activation 2
    nn.Linear(20, 5)        # Output layer
)

print(model)

# Forward pass
x = torch.randn(32, 10)
output = model(x)
print('Output shape:', output.shape)  # torch.Size([32, 5])

# Access individual layers
print('First layer:', model[0])  # Linear(in_features=10, out_features=20)
print('First layer weights shape:', model[0].weight.shape)  # torch.Size([20, 10])</code></pre>

                        <div class="highlight-box">
                            <i class="fas fa-code"></i>
                            <strong>When to use Sequential vs Custom nn.Module:</strong> Use <code>nn.Sequential</code> for simple feed-forward architectures with linear data flow. Use custom <code>nn.Module</code> classes when you need complex control flow, skip connections (ResNet), multiple inputs/outputs, or custom forward logic.
                        </div>
                    </div>

                    <!-- Activations -->
                    <div id="activations" class="blog-content mt-5">
                        <h2><i class="fas fa-wave-square me-2 text-teal"></i>Activation Functions & Initialization</h2>
                        
                        <p>Activation functions introduce non-linearity into neural networks, enabling them to learn complex patterns. Weight initialization determines starting values for parameters and significantly impacts training convergence.</p>

                        <h3>Common Activation Functions</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn

# Create sample input
x = torch.tensor([-2.0, -1.0, 0.0, 1.0, 2.0])

# ReLU: max(0, x) - most common, fast, avoids vanishing gradients
relu = nn.ReLU()
print('ReLU:', relu(x))  # tensor([0., 0., 0., 1., 2.])

# Leaky ReLU: allows small negative values (0.01*x when x < 0)
leaky_relu = nn.LeakyReLU(negative_slope=0.01)
print('Leaky ReLU:', leaky_relu(x))  # tensor([-0.02, -0.01, 0., 1., 2.])

# Sigmoid: squashes values to (0, 1) - used in binary classification
sigmoid = nn.Sigmoid()
print('Sigmoid:', sigmoid(x))  # tensor([0.119, 0.269, 0.5, 0.731, 0.881])

# Tanh: squashes values to (-1, 1) - zero-centered
tanh = nn.Tanh()
print('Tanh:', tanh(x))  # tensor([-0.964, -0.762, 0., 0.762, 0.964])

# Softmax: converts logits to probabilities (sum to 1)
# Used in multi-class classification output layer
softmax = nn.Softmax(dim=0)
print('Softmax:', softmax(x))  # tensor([0.012, 0.032, 0.087, 0.236, 0.643])
print('Sum:', softmax(x).sum())  # tensor(1.0)</code></pre>

                        <h3>Weight Initialization</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn

# Create a linear layer
layer = nn.Linear(10, 20)

# Default initialization (varies by layer type)
print('Default weights (first 5):', layer.weight.data.flatten()[:5])
print('Default bias (first 5):', layer.bias.data[:5])

# Xavier/Glorot initialization (good for tanh/sigmoid)
nn.init.xavier_uniform_(layer.weight)
print('Xavier weights (first 5):', layer.weight.data.flatten()[:5])

# He initialization (good for ReLU)
nn.init.kaiming_normal_(layer.weight, mode='fan_in', nonlinearity='relu')
print('He weights (first 5):', layer.weight.data.flatten()[:5])

# Constant initialization
nn.init.constant_(layer.bias, 0.0)  # Initialize all biases to 0
print('Constant bias:', layer.bias.data[:5])

# Custom initialization in model
class CustomInitNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(10, 20)
        self.fc2 = nn.Linear(20, 10)
        
        # Apply custom initialization
        nn.init.xavier_uniform_(self.fc1.weight)
        nn.init.kaiming_normal_(self.fc2.weight)
        nn.init.zeros_(self.fc1.bias)
        nn.init.zeros_(self.fc2.bias)
    
    def forward(self, x):
        return self.fc2(torch.relu(self.fc1(x)))

model = CustomInitNet()
print('Model initialized with custom weights')</code></pre>

                        <div class="experiment-card">
                            <div class="card-meta mb-2">
                                <span class="badge bg-teal text-white">Activation Function Cheat Sheet</span>
                            </div>
                            <div class="card-content">
                                <ul>
                                    <li><strong>ReLU:</strong> Default choice for hidden layers. Fast, avoids vanishing gradients. Can suffer from "dying ReLU" problem.</li>
                                    <li><strong>Leaky ReLU:</strong> Fixes dying ReLU by allowing small negative values. Good alternative to ReLU.</li>
                                    <li><strong>Sigmoid:</strong> Output layer for binary classification. Suffers from vanishing gradients in deep networks.</li>
                                    <li><strong>Tanh:</strong> Zero-centered sigmoid. Better than sigmoid for hidden layers but still has vanishing gradient issues.</li>
                                    <li><strong>Softmax:</strong> Output layer for multi-class classification. Converts logits to probabilities.</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <!-- Optimizers -->
                    <div id="optimizers" class="blog-content mt-5">
                        <h2><i class="fas fa-cogs me-2 text-teal"></i>Optimizers & Learning Rate Scheduling</h2>
                        
                        <p>Optimizers update model parameters based on computed gradients. PyTorch provides many optimization algorithms, each with different convergence properties and hyperparameters.</p>

                        <h3>Common Optimizers</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim

# Create a simple model
model = nn.Sequential(
    nn.Linear(10, 20),
    nn.ReLU(),
    nn.Linear(20, 5)
)

# SGD (Stochastic Gradient Descent)
# Simple, requires careful learning rate tuning
optimizer_sgd = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
print('SGD optimizer:', optimizer_sgd)

# Adam (Adaptive Moment Estimation)
# Most popular, adapts learning rate per parameter
# Good default choice for most tasks
optimizer_adam = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))
print('Adam optimizer:', optimizer_adam)

# AdamW (Adam with weight decay fix)
# Better generalization than Adam
optimizer_adamw = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)
print('AdamW optimizer:', optimizer_adamw)

# RMSprop (Root Mean Square Propagation)
# Good for RNNs, adapts learning rates
optimizer_rmsprop = optim.RMSprop(model.parameters(), lr=0.001)
print('RMSprop optimizer:', optimizer_rmsprop)</code></pre>

                        <h3>Optimizer Usage Pattern</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim

# Create model and optimizer
model = nn.Sequential(nn.Linear(10, 5))
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.MSELoss()

# Training loop pattern
for epoch in range(10):
    # 1. Zero gradients from previous step
    optimizer.zero_grad()
    
    # 2. Forward pass
    inputs = torch.randn(32, 10)
    targets = torch.randn(32, 5)
    outputs = model(inputs)
    
    # 3. Compute loss
    loss = criterion(outputs, targets)
    
    # 4. Backward pass (compute gradients)
    loss.backward()
    
    # 5. Update parameters
    optimizer.step()
    
    if epoch % 2 == 0:
        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')</code></pre>

                        <h3>Learning Rate Scheduling</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR

# Create model and optimizer
model = nn.Sequential(nn.Linear(10, 5))
optimizer = optim.Adam(model.parameters(), lr=0.1)

# StepLR: reduce LR by gamma every step_size epochs
scheduler_step = StepLR(optimizer, step_size=30, gamma=0.1)
print('Initial LR:', optimizer.param_groups[0]['lr'])  # 0.1

for epoch in range(5):
    # Training code here...
    pass
    
    # Step scheduler at end of epoch
    scheduler_step.step()
    print(f'Epoch {epoch+1}, LR: {optimizer.param_groups[0]["lr"]:.6f}')

# ReduceLROnPlateau: reduce LR when metric plateaus
# Useful when you monitor validation loss
optimizer2 = optim.Adam(model.parameters(), lr=0.1)
scheduler_plateau = ReduceLROnPlateau(optimizer2, mode='min', factor=0.5, patience=5)

# During training, call with validation loss
for epoch in range(10):
    val_loss = 0.5 - epoch * 0.03  # Simulated decreasing loss
    scheduler_plateau.step(val_loss)
    print(f'Epoch {epoch+1}, Val Loss: {val_loss:.4f}, LR: {optimizer2.param_groups[0]["lr"]:.6f}')

# CosineAnnealingLR: smooth cosine decay
optimizer3 = optim.Adam(model.parameters(), lr=0.1)
scheduler_cosine = CosineAnnealingLR(optimizer3, T_max=10, eta_min=0.001)

for epoch in range(10):
    scheduler_cosine.step()
    print(f'Epoch {epoch+1}, LR: {optimizer3.param_groups[0]["lr"]:.6f}')</code></pre>

                        <div class="highlight-box">
                            <i class="fas fa-lightbulb"></i>
                            <strong>Optimizer Choice Guide:</strong> Start with <strong>Adam</strong> or <strong>AdamW</strong> (lr=0.001) as default. Use <strong>SGD with momentum</strong> (lr=0.01-0.1, momentum=0.9) for computer vision when you need best final performance and have time to tune. Use <strong>RMSprop</strong> for RNNs. Always enable weight decay for regularization.
                        </div>
                    </div>

                    <!-- Datasets & DataLoaders -->
                    <div id="datasets" class="blog-content mt-5">
                        <h2><i class="fas fa-database me-2 text-teal"></i>Datasets & DataLoaders</h2>
                        
                        <p>PyTorch's <code>Dataset</code> and <code>DataLoader</code> classes provide efficient data loading with automatic batching, shuffling, and parallel loading. This is essential for training on large datasets.</p>

                        <h3>Creating Custom Dataset</h3>
                        <pre><code class="language-python">import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np

# Custom Dataset: must implement __len__ and __getitem__
class CustomDataset(Dataset):
    def __init__(self, num_samples=1000, num_features=10):
        # Initialize data (in practice, load from files here)
        self.data = torch.randn(num_samples, num_features)
        self.labels = torch.randint(0, 2, (num_samples,))  # Binary labels
    
    def __len__(self):
        # Return total number of samples
        return len(self.data)
    
    def __getitem__(self, idx):
        # Return one sample (data, label) at index idx
        return self.data[idx], self.labels[idx]

# Create dataset instance
dataset = CustomDataset(num_samples=1000, num_features=10)
print(f'Dataset size: {len(dataset)}')

# Access individual samples
sample_data, sample_label = dataset[0]
print(f'Sample data shape: {sample_data.shape}')  # torch.Size([10])
print(f'Sample label: {sample_label.item()}')  # 0 or 1</code></pre>

                        <h3>DataLoader: Batching & Shuffling</h3>
                        <pre><code class="language-python">import torch
from torch.utils.data import Dataset, DataLoader

# Custom dataset (same as above)
class CustomDataset(Dataset):
    def __init__(self, num_samples=1000, num_features=10):
        self.data = torch.randn(num_samples, num_features)
        self.labels = torch.randint(0, 2, (num_samples,))
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        return self.data[idx], self.labels[idx]

dataset = CustomDataset(num_samples=1000, num_features=10)

# Create DataLoader
dataloader = DataLoader(
    dataset,
    batch_size=32,        # Load 32 samples per batch
    shuffle=True,         # Shuffle data every epoch
    num_workers=0,        # Parallel data loading (0 = single process)
    pin_memory=True       # Faster GPU transfer (use with CUDA)
)

print(f'Number of batches: {len(dataloader)}')  # 1000 / 32 = 32 batches

# Iterate through batches
for batch_idx, (data, labels) in enumerate(dataloader):
    print(f'Batch {batch_idx}: data shape {data.shape}, labels shape {labels.shape}')
    # data shape: torch.Size([32, 10])
    # labels shape: torch.Size([32])
    
    if batch_idx == 2:  # Show only first 3 batches
        break</code></pre>

                        <h3>Using Built-in Datasets (TorchVision)</h3>
                        <pre><code class="language-python">import torch
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms

# Define data transformations
transform = transforms.Compose([
    transforms.ToTensor(),  # Convert PIL Image to Tensor
    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]
])

# Load MNIST dataset (downloads automatically on first run)
train_dataset = torchvision.datasets.MNIST(
    root='./data',           # Download location
    train=True,              # Training set
    download=True,           # Download if not present
    transform=transform      # Apply transformations
)

test_dataset = torchvision.datasets.MNIST(
    root='./data',
    train=False,             # Test set
    download=True,
    transform=transform
)

print(f'Training samples: {len(train_dataset)}')  # 60,000
print(f'Test samples: {len(test_dataset)}')      # 10,000

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

# Examine one batch
images, labels = next(iter(train_loader))
print(f'Image batch shape: {images.shape}')  # torch.Size([64, 1, 28, 28])
print(f'Label batch shape: {labels.shape}')  # torch.Size([64])</code></pre>

                        <div class="experiment-card">
                            <div class="card-meta mb-2">
                                <span class="badge bg-teal text-white">DataLoader Best Practices</span>
                            </div>
                            <div class="card-content">
                                <ul>
                                    <li><strong>Batch Size:</strong> Start with 32 or 64. Larger batches (256+) need higher learning rates. GPU memory limits max batch size.</li>
                                    <li><strong>Shuffle:</strong> Always shuffle training data. Don't shuffle validation/test data (reproducible evaluation).</li>
                                    <li><strong>num_workers:</strong> Use 2-4 workers for parallel loading on multi-core CPUs. Set to 0 on Windows to avoid issues.</li>
                                    <li><strong>pin_memory:</strong> Set True when using GPU—faster data transfer to CUDA.</li>
                                    <li><strong>drop_last:</strong> Set True to drop incomplete final batch (useful for batch normalization).</li>
                                </ul>
                            </div>
                        </div>
                    </div>

                    <!-- Training Loop -->
                    <div id="training-loop" class="blog-content mt-5">
                        <h2><i class="fas fa-sync-alt me-2 text-teal"></i>The Training Loop</h2>
                        
                        <p>The training loop is where all components come together: model, optimizer, loss function, and data. Understanding this pattern is crucial for successfully training neural networks.</p>

                        <h3>Complete Training Loop Example</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

# 1. Define Dataset
class SimpleDataset(Dataset):
    def __init__(self, num_samples=1000):
        self.data = torch.randn(num_samples, 10)
        self.labels = torch.randint(0, 2, (num_samples,))
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        return self.data[idx], self.labels[idx]

# 2. Create DataLoader
train_dataset = SimpleDataset(num_samples=1000)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# 3. Define Model
model = nn.Sequential(
    nn.Linear(10, 20),
    nn.ReLU(),
    nn.Linear(20, 2)  # Binary classification (2 classes)
)

# 4. Define Loss and Optimizer
criterion = nn.CrossEntropyLoss()  # For classification
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 5. Training Loop
num_epochs = 10

for epoch in range(num_epochs):
    model.train()  # Set model to training mode (enables dropout, batch norm)
    running_loss = 0.0
    correct = 0
    total = 0
    
    for batch_idx, (data, labels) in enumerate(train_loader):
        # Zero gradients
        optimizer.zero_grad()
        
        # Forward pass
        outputs = model(data)
        loss = criterion(outputs, labels)
        
        # Backward pass
        loss.backward()
        
        # Update weights
        optimizer.step()
        
        # Track metrics
        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
    
    # Epoch statistics
    epoch_loss = running_loss / len(train_loader)
    epoch_acc = 100 * correct / total
    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')</code></pre>

                        <h3>Training with Validation</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

# Dataset (same as above)
class SimpleDataset(Dataset):
    def __init__(self, num_samples=1000):
        self.data = torch.randn(num_samples, 10)
        self.labels = torch.randint(0, 2, (num_samples,))
    def __len__(self):
        return len(self.data)
    def __getitem__(self, idx):
        return self.data[idx], self.labels[idx]

# Create train and validation sets
train_loader = DataLoader(SimpleDataset(800), batch_size=32, shuffle=True)
val_loader = DataLoader(SimpleDataset(200), batch_size=32, shuffle=False)

model = nn.Sequential(nn.Linear(10, 20), nn.ReLU(), nn.Linear(20, 2))
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training loop with validation
for epoch in range(10):
    # TRAINING PHASE
    model.train()
    train_loss = 0.0
    
    for data, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(data)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
    
    train_loss /= len(train_loader)
    
    # VALIDATION PHASE
    model.eval()  # Set to evaluation mode (disables dropout, batch norm training)
    val_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad():  # Disable gradient computation (saves memory)
        for data, labels in val_loader:
            outputs = model(data)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
            
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    
    val_loss /= len(val_loader)
    val_acc = 100 * correct / total
    
    print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')</code></pre>

                        <div class="highlight-box">
                            <i class="fas fa-exclamation-circle"></i>
                            <strong>Critical Training Steps:</strong> Always call <code>optimizer.zero_grad()</code> before backward pass (gradients accumulate by default). Use <code>model.train()</code> for training and <code>model.eval()</code> + <code>torch.no_grad()</code> for validation/testing. This ensures correct behavior of dropout and batch normalization layers.
                        </div>
                    </div>

                    <!-- Evaluation, Saving, GPU, Transfer Learning, CNNs, Best Practices -->
                    
                    <div id="evaluation" class="blog-content mt-5">
                        <h2><i class="fas fa-chart-line me-2 text-teal"></i>Model Evaluation & Metrics</h2>
                        
                        <p>Proper evaluation requires setting the model to evaluation mode and computing appropriate metrics. Always evaluate on held-out test data to assess generalization.</p>

                        <h3>Evaluation Pattern</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset

# Simple dataset and model
class TestDataset(Dataset):
    def __init__(self):
        self.data = torch.randn(100, 10)
        self.labels = torch.randint(0, 3, (100,))
    def __len__(self):
        return len(self.data)
    def __getitem__(self, idx):
        return self.data[idx], self.labels[idx]

test_loader = DataLoader(TestDataset(), batch_size=32)
model = nn.Sequential(nn.Linear(10, 20), nn.ReLU(), nn.Linear(20, 3))

# Evaluation function
def evaluate_model(model, dataloader):
    model.eval()  # Set to evaluation mode
    correct = 0
    total = 0
    all_preds = []
    all_labels = []
    
    with torch.no_grad():  # Disable gradient tracking
        for data, labels in dataloader:
            outputs = model(data)
            _, predicted = torch.max(outputs, 1)
            
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    
    accuracy = 100 * correct / total
    return accuracy, all_preds, all_labels

acc, preds, labels = evaluate_model(model, test_loader)
print(f'Test Accuracy: {acc:.2f}%')</code></pre>
                    </div>

                    <div id="saving" class="blog-content mt-5">
                        <h2><i class="fas fa-save me-2 text-teal"></i>Saving & Loading Models</h2>
                        
                        <p>PyTorch provides two approaches: save the entire model or save only the state dictionary (recommended). The state dict contains all learnable parameters.</p>

                        <h3>Save and Load State Dict (Recommended)</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn

# Define and train a model
model = nn.Sequential(nn.Linear(10, 20), nn.ReLU(), nn.Linear(20, 5))

# Save only the state dict (parameters)
torch.save(model.state_dict(), 'model_weights.pth')
print('Model state dict saved')

# Load state dict into a NEW model instance
# IMPORTANT: Model architecture must match exactly
model_loaded = nn.Sequential(nn.Linear(10, 20), nn.ReLU(), nn.Linear(20, 5))
model_loaded.load_state_dict(torch.load('model_weights.pth'))
model_loaded.eval()
print('Model state dict loaded')

# Verify weights match
print('Weights match:', torch.equal(model.state_dict()['0.weight'], 
                                     model_loaded.state_dict()['0.weight']))</code></pre>

                        <h3>Save Entire Model (Alternative)</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn

model = nn.Sequential(nn.Linear(10, 5))

# Save entire model (architecture + weights)
torch.save(model, 'entire_model.pth')

# Load entire model
model_loaded = torch.load('entire_model.pth')
model_loaded.eval()
print('Entire model loaded')</code></pre>

                        <h3>Save Training Checkpoint</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim

model = nn.Sequential(nn.Linear(10, 5))
optimizer = optim.Adam(model.parameters(), lr=0.001)
epoch = 10
loss = 0.5

# Save complete training state
checkpoint = {
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'loss': loss
}
torch.save(checkpoint, 'checkpoint.pth')
print('Checkpoint saved')

# Load checkpoint and resume training
checkpoint = torch.load('checkpoint.pth')
model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
start_epoch = checkpoint['epoch']
last_loss = checkpoint['loss']
print(f'Resumed from epoch {start_epoch}, loss {last_loss:.4f}')</code></pre>
                    </div>

                    <div id="gpu" class="blog-content mt-5">
                        <h2><i class="fas fa-microchip me-2 text-teal"></i>GPU Acceleration & Device Management</h2>
                        
                        <p>Training on GPU can be 10-100x faster than CPU. PyTorch makes GPU usage simple with the <code>.to(device)</code> method.</p>

                        <h3>Basic GPU Usage</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn

# Check GPU availability
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f'Using device: {device}')

if torch.cuda.is_available():
    print(f'GPU: {torch.cuda.get_device_name(0)}')
    print(f'Memory allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB')

# Move model to GPU
model = nn.Sequential(nn.Linear(10, 20), nn.ReLU(), nn.Linear(20, 5))
model = model.to(device)
print('Model moved to', device)

# Move data to GPU (must match model device!)
data = torch.randn(32, 10).to(device)
labels = torch.randint(0, 5, (32,)).to(device)

# Forward pass on GPU
outputs = model(data)
print('Output device:', outputs.device)  # cuda:0</code></pre>

                        <h3>Training Loop with GPU</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

# Setup device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Create data
X_train = torch.randn(1000, 10)
y_train = torch.randint(0, 2, (1000,))
train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32)

# Model, loss, optimizer on GPU
model = nn.Sequential(nn.Linear(10, 20), nn.ReLU(), nn.Linear(20, 2)).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training loop
for epoch in range(5):
    for data, labels in train_loader:
        # Move batch to GPU
        data, labels = data.to(device), labels.to(device)
        
        optimizer.zero_grad()
        outputs = model(data)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
    
    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')</code></pre>

                        <div class="highlight-box">
                            <i class="fas fa-bolt"></i>
                            <strong>GPU Best Practices:</strong> Always move both model AND data to the same device. Use <code>torch.cuda.empty_cache()</code> to free unused GPU memory. Monitor memory with <code>torch.cuda.memory_allocated()</code>. Use mixed precision training (next section) to reduce memory usage and speed up training.
                        </div>
                    </div>

                    <div id="mixed-precision" class="blog-content mt-5">
                        <h2><i class="fas fa-tachometer-alt me-2 text-teal"></i>Mixed Precision Training</h2>
                        
                        <p>Mixed precision uses FP16 (16-bit) instead of FP32 (32-bit) for faster training and lower memory usage. PyTorch's automatic mixed precision (AMP) handles this automatically.</p>

                        <h3>Using torch.cuda.amp</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim
from torch.cuda.amp import GradScaler, autocast
from torch.utils.data import DataLoader, TensorDataset

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Model and data
model = nn.Sequential(nn.Linear(10, 20), nn.ReLU(), nn.Linear(20, 2)).to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

X_train = torch.randn(1000, 10)
y_train = torch.randint(0, 2, (1000,))
train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32)

# Create gradient scaler for mixed precision
scaler = GradScaler()

# Training loop with AMP
for epoch in range(5):
    for data, labels in train_loader:
        data, labels = data.to(device), labels.to(device)
        
        optimizer.zero_grad()
        
        # Wrap forward pass in autocast
        with autocast():
            outputs = model(data)
            loss = criterion(outputs, labels)
        
        # Scale loss and backward pass
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
    
    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')

print('Mixed precision training complete - typically 2-3x faster!')</code></pre>
                    </div>

                    <div id="transfer-learning" class="blog-content mt-5">
                        <h2><i class="fas fa-exchange-alt me-2 text-teal"></i>Transfer Learning with Pretrained Models</h2>
                        
                        <p>Transfer learning uses models pretrained on large datasets (ImageNet) as feature extractors. This dramatically reduces training time and data requirements.</p>

                        <h3>Using Pretrained ResNet</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn
import torchvision.models as models

# Load pretrained ResNet-18 (trained on ImageNet)
model = models.resnet18(pretrained=True)
print('Pretrained ResNet-18 loaded')

# Freeze all layers (don't update pretrained weights)
for param in model.parameters():
    param.requires_grad = False

# Replace final layer for new task (e.g., 10 classes instead of 1000)
num_features = model.fc.in_features  # 512 for ResNet-18
model.fc = nn.Linear(num_features, 10)  # Only this layer will be trained

print('Modified for 10-class classification')
print(f'Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}')

# Now train only the final layer on your dataset</code></pre>

                        <h3>Fine-Tuning Pretrained Model</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models

# Load pretrained model
model = models.resnet18(pretrained=True)

# Replace final layer
model.fc = nn.Linear(model.fc.in_features, 10)

# Two-stage training:
# Stage 1: Train only final layer (frozen backbone)
for param in model.parameters():
    param.requires_grad = False
model.fc.requires_grad_(True)  # Unfreeze only final layer

optimizer = optim.Adam(model.fc.parameters(), lr=0.001)
# Train for a few epochs...

# Stage 2: Fine-tune entire model with lower learning rate
for param in model.parameters():
    param.requires_grad = True

optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Lower LR!
# Continue training...</code></pre>
                    </div>

                    <div id="cnn" class="blog-content mt-5">
                        <h2><i class="fas fa-images me-2 text-teal"></i>Convolutional Neural Networks (CNNs)</h2>
                        
                        <p>CNNs are the architecture of choice for computer vision. They use convolutional layers to automatically learn spatial hierarchies of features.</p>

                        <h3>Simple CNN for Image Classification</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        # Convolutional layers
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # 1 input channel (grayscale)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)  # 2x2 max pooling
        
        # Fully connected layers
        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # After 2 pooling: 28->14->7
        self.fc2 = nn.Linear(128, 10)  # 10 classes (MNIST digits)
        self.dropout = nn.Dropout(0.5)
    
    def forward(self, x):
        # Conv block 1: Conv -> ReLU -> Pool
        x = self.pool(F.relu(self.conv1(x)))  # (28, 28) -> (14, 14)
        
        # Conv block 2: Conv -> ReLU -> Pool
        x = self.pool(F.relu(self.conv2(x)))  # (14, 14) -> (7, 7)
        
        # Flatten for fully connected layers
        x = x.view(-1, 64 * 7 * 7)  # Batch x Features
        
        # Fully connected layers
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x

# Create model
model = SimpleCNN()
print(model)

# Test forward pass
x = torch.randn(4, 1, 28, 28)  # Batch of 4 grayscale 28x28 images
output = model(x)
print(f'Output shape: {output.shape}')  # torch.Size([4, 10])</code></pre>
                    </div>

                    <div id="rnn" class="blog-content mt-5">
                        <h2><i class="fas fa-stream me-2 text-teal"></i>Recurrent Neural Networks (RNNs & LSTMs)</h2>
                        
                        <p>RNNs process sequential data by maintaining hidden states across time steps. LSTMs (Long Short-Term Memory) solve the vanishing gradient problem in standard RNNs.</p>

                        <h3>Simple RNN for Sequence Classification</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn

class RNNClassifier(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, num_classes):
        super(RNNClassifier, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # RNN layer
        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)
        
        # Fully connected output layer
        self.fc = nn.Linear(hidden_size, num_classes)
    
    def forward(self, x):
        # Initialize hidden state
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        
        # Forward propagate RNN
        out, _ = self.rnn(x, h0)  # out: (batch, seq_len, hidden_size)
        
        # Get output from last time step
        out = self.fc(out[:, -1, :])  # (batch, num_classes)
        return out

# Create model
model = RNNClassifier(input_size=10, hidden_size=128, num_layers=2, num_classes=5)
print(model)

# Test forward pass
x = torch.randn(32, 20, 10)  # (batch, seq_len, input_size)
output = model(x)
print(f'Output shape: {output.shape}')  # torch.Size([32, 5])</code></pre>

                        <h3>LSTM for Text Classification</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn

class LSTMClassifier(nn.Module):
    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):
        super(LSTMClassifier, self).__init__()
        # Embedding layer
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        
        # LSTM layer (bidirectional for better context)
        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)
        
        # Fully connected layer (2x hidden_dim because bidirectional)
        self.fc = nn.Linear(hidden_dim * 2, num_classes)
        self.dropout = nn.Dropout(0.5)
    
    def forward(self, x):
        # x: (batch, seq_len) - integer token IDs
        embedded = self.embedding(x)  # (batch, seq_len, embed_dim)
        
        # LSTM forward pass
        lstm_out, (hidden, cell) = self.lstm(embedded)
        
        # Concatenate final forward and backward hidden states
        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)
        
        # Apply dropout and output layer
        out = self.dropout(hidden)
        out = self.fc(out)
        return out

# Create model
model = LSTMClassifier(vocab_size=10000, embed_dim=100, hidden_dim=256, num_classes=2)
print(model)

# Test forward pass
x = torch.randint(0, 10000, (32, 50))  # (batch, seq_len) - token IDs
output = model(x)
print(f'Output shape: {output.shape}')  # torch.Size([32, 2])</code></pre>

                        <div class="highlight-box">
                            <i class="fas fa-lightbulb"></i>
                            <strong>LSTM vs RNN:</strong> Use LSTMs for longer sequences (>20 steps) where long-term dependencies matter. For very long sequences (>500 tokens), consider Transformers instead. Bidirectional LSTMs see both past and future context but can't be used for real-time prediction.
                        </div>
                    </div>

                    <div id="embeddings" class="blog-content mt-5">
                        <h2><i class="fas fa-language me-2 text-teal"></i>Embeddings for NLP</h2>
                        
                        <p>Embeddings convert discrete tokens (words, characters) into continuous vector representations that capture semantic meaning.</p>

                        <h3>Creating Word Embeddings</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn

# Create embedding layer
vocab_size = 10000  # Size of vocabulary
embedding_dim = 300  # Dimension of embedding vectors

embedding = nn.Embedding(vocab_size, embedding_dim)
print(f'Embedding matrix shape: {embedding.weight.shape}')  # torch.Size([10000, 300])

# Convert word IDs to embeddings
word_ids = torch.LongTensor([5, 42, 123, 7])  # Word IDs from vocabulary
word_vectors = embedding(word_ids)
print(f'Word vectors shape: {word_vectors.shape}')  # torch.Size([4, 300])

# Batch of sentences
sentences = torch.LongTensor([[5, 42, 123, 7, 0],    # Sentence 1 (0 = padding)
                              [15, 88, 3, 0, 0]])      # Sentence 2
sentence_vectors = embedding(sentences)
print(f'Sentence embeddings shape: {sentence_vectors.shape}')  # torch.Size([2, 5, 300])</code></pre>

                        <h3>Using Pretrained Embeddings (GloVe)</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn

# Load pretrained GloVe embeddings (example - you'd load from file)
vocab_size = 10000
embedding_dim = 300

# Create embedding layer
embedding = nn.Embedding(vocab_size, embedding_dim)

# Load pretrained weights (replace with actual GloVe weights)
# pretrained_weights = torch.load('glove.6B.300d.pt')
# embedding.weight.data.copy_(pretrained_weights)

# Freeze embeddings (don't update during training)
embedding.weight.requires_grad = False
print('Pretrained embeddings loaded and frozen')

# For fine-tuning, keep trainable:
# embedding.weight.requires_grad = True</code></pre>

                        <h3>Embedding with Padding</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn

# Create embedding with padding_idx
embedding = nn.Embedding(vocab_size=10000, embedding_dim=300, padding_idx=0)

# Padding token (ID=0) will always have zero vector
print(f'Padding embedding: {embedding(torch.LongTensor([0]))}')  # All zeros

# Regular tokens have learned embeddings
print(f'Word embedding shape: {embedding(torch.LongTensor([42])).shape}')  # (1, 300)</code></pre>
                    </div>

                    <div id="advanced" class="blog-content mt-5">
                        <h2><i class="fas fa-cogs me-2 text-teal"></i>Advanced Training Techniques</h2>
                        
                        <h3>Gradient Clipping</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim

model = nn.Sequential(nn.Linear(10, 20), nn.ReLU(), nn.Linear(20, 5))
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

# Training loop with gradient clipping
data = torch.randn(32, 10)
labels = torch.randint(0, 5, (32,))

optimizer.zero_grad()
outputs = model(data)
loss = criterion(outputs, labels)
loss.backward()

# Clip gradients to prevent exploding gradients
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

optimizer.step()
print('Gradients clipped to max norm 1.0')</code></pre>

                        <h3>Learning Rate Scheduling</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau

model = nn.Linear(10, 5)
optimizer = optim.Adam(model.parameters(), lr=0.01)

# StepLR: Decay LR by gamma every step_size epochs
scheduler = StepLR(optimizer, step_size=10, gamma=0.1)

# Training loop
for epoch in range(30):
    # ... training code ...
    
    # Update learning rate
    scheduler.step()
    print(f'Epoch {epoch}, LR: {optimizer.param_groups[0]["lr"]:.6f}')

# ReduceLROnPlateau: Reduce LR when metric plateaus
scheduler_plateau = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)

for epoch in range(30):
    # ... training code ...
    val_loss = 0.5  # Example validation loss
    
    # Reduce LR if validation loss doesn't improve
    scheduler_plateau.step(val_loss)</code></pre>

                        <h3>Early Stopping</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn
import torch.optim as optim

class EarlyStopping:
    def __init__(self, patience=7, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_loss = None
        self.early_stop = False
    
    def __call__(self, val_loss):
        if self.best_loss is None:
            self.best_loss = val_loss
        elif val_loss > self.best_loss - self.min_delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_loss = val_loss
            self.counter = 0

# Usage
model = nn.Linear(10, 5)
optimizer = optim.Adam(model.parameters())
early_stopping = EarlyStopping(patience=10)

for epoch in range(100):
    # ... training code ...
    val_loss = 0.5  # Example validation loss
    
    early_stopping(val_loss)
    if early_stopping.early_stop:
        print(f'Early stopping at epoch {epoch}')
        break</code></pre>
                    </div>

                    <div id="custom-layers" class="blog-content mt-5">
                        <h2><i class="fas fa-layer-group me-2 text-teal"></i>Custom Layers & Loss Functions</h2>
                        
                        <h3>Creating Custom Layers</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn

class CustomLinear(nn.Module):
    def __init__(self, in_features, out_features, use_bias=True):
        super(CustomLinear, self).__init__()
        self.in_features = in_features
        self.out_features = out_features
        
        # Initialize weights and bias
        self.weight = nn.Parameter(torch.randn(out_features, in_features))
        if use_bias:
            self.bias = nn.Parameter(torch.randn(out_features))
        else:
            self.register_parameter('bias', None)
    
    def forward(self, x):
        # Custom linear transformation: y = xW^T + b
        output = torch.matmul(x, self.weight.t())
        if self.bias is not None:
            output += self.bias
        return output

# Use custom layer
layer = CustomLinear(10, 5)
x = torch.randn(32, 10)
output = layer(x)
print(f'Output shape: {output.shape}')  # torch.Size([32, 5])</code></pre>

                        <h3>Custom Activation Function</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn

class Swish(nn.Module):
    """Swish activation: x * sigmoid(x)"""
    def forward(self, x):
        return x * torch.sigmoid(x)

# Use custom activation
model = nn.Sequential(
    nn.Linear(10, 20),
    Swish(),  # Custom activation
    nn.Linear(20, 5)
)

x = torch.randn(32, 10)
output = model(x)
print(f'Output shape: {output.shape}')  # torch.Size([32, 5])</code></pre>

                        <h3>Custom Loss Function</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn

class FocalLoss(nn.Module):
    """Focal Loss for handling class imbalance"""
    def __init__(self, alpha=1, gamma=2):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.ce_loss = nn.CrossEntropyLoss(reduction='none')
    
    def forward(self, inputs, targets):
        ce_loss = self.ce_loss(inputs, targets)
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss
        return focal_loss.mean()

# Use custom loss
model = nn.Linear(10, 5)
criterion = FocalLoss(alpha=1, gamma=2)

outputs = model(torch.randn(32, 10))
targets = torch.randint(0, 5, (32,))
loss = criterion(outputs, targets)
print(f'Focal loss: {loss.item():.4f}')</code></pre>
                    </div>

                    <div id="interpretability" class="blog-content mt-5">
                        <h2><i class="fas fa-eye me-2 text-teal"></i>Model Interpretability (Grad-CAM)</h2>
                        
                        <p>Grad-CAM (Gradient-weighted Class Activation Mapping) visualizes which parts of an image a CNN focuses on for predictions.</p>

                        <h3>Implementing Grad-CAM</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F

class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.activations = None
        
        # Register hooks
        target_layer.register_forward_hook(self.save_activation)
        target_layer.register_backward_hook(self.save_gradient)
    
    def save_activation(self, module, input, output):
        self.activations = output
    
    def save_gradient(self, module, grad_input, grad_output):
        self.gradients = grad_output[0]
    
    def generate_cam(self, input_image, target_class):
        # Forward pass
        output = self.model(input_image)
        
        # Backward pass for target class
        self.model.zero_grad()
        class_loss = output[0, target_class]
        class_loss.backward()
        
        # Get gradients and activations
        gradients = self.gradients.detach()
        activations = self.activations.detach()
        
        # Global average pooling of gradients
        weights = torch.mean(gradients, dim=(2, 3), keepdim=True)
        
        # Weighted combination of activation maps
        cam = torch.sum(weights * activations, dim=1, keepdim=True)
        cam = F.relu(cam)  # Only positive influence
        
        # Normalize
        cam = cam - cam.min()
        cam = cam / cam.max()
        
        return cam

# Example usage with ResNet
import torchvision.models as models

model = models.resnet18(pretrained=True)
model.eval()

# Get last convolutional layer
target_layer = model.layer4[-1].conv2

# Create Grad-CAM
grad_cam = GradCAM(model, target_layer)

# Generate CAM for an image
image = torch.randn(1, 3, 224, 224)  # Example image
cam = grad_cam.generate_cam(image, target_class=243)  # 243 = "bull mastiff"
print(f'CAM shape: {cam.shape}')  # torch.Size([1, 1, 7, 7])</code></pre>

                        <div class="highlight-box">
                            <i class="fas fa-info-circle"></i>
                            <strong>Interpretability Tools:</strong> For production use, consider libraries like <code>captum</code> (PyTorch's official interpretability library) which provides Grad-CAM, Integrated Gradients, and many other attribution methods out of the box.
                        </div>
                    </div>

                    <div id="deployment" class="blog-content mt-5">
                        <h2><i class="fas fa-rocket me-2 text-teal"></i>Deployment with TorchScript</h2>
                        
                        <p>TorchScript converts PyTorch models into an intermediate representation that can run independently of Python, enabling production deployment in C++.</p>

                        <h3>Tracing a Model</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn

# Define a simple model
class SimpleModel(nn.Module):
    def __init__(self):
        super(SimpleModel, self).__init__()
        self.linear = nn.Linear(10, 5)
    
    def forward(self, x):
        return torch.relu(self.linear(x))

model = SimpleModel()
model.eval()

# Create example input
example_input = torch.randn(1, 10)

# Trace the model
traced_model = torch.jit.trace(model, example_input)

# Save traced model
traced_model.save('model_traced.pt')
print('Model traced and saved')

# Load and use traced model
loaded_model = torch.jit.load('model_traced.pt')
output = loaded_model(example_input)
print(f'Output: {output}')</code></pre>

                        <h3>Scripting a Model (for Control Flow)</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn

class ModelWithControlFlow(nn.Module):
    def __init__(self):
        super(ModelWithControlFlow, self).__init__()
        self.linear = nn.Linear(10, 5)
    
    def forward(self, x):
        # Control flow - use scripting instead of tracing
        if x.sum() > 0:
            return torch.relu(self.linear(x))
        else:
            return torch.sigmoid(self.linear(x))

model = ModelWithControlFlow()
model.eval()

# Script the model (handles control flow)
scripted_model = torch.jit.script(model)

# Save scripted model
scripted_model.save('model_scripted.pt')
print('Model scripted and saved')

# Load and use
loaded_model = torch.jit.load('model_scripted.pt')
output = loaded_model(torch.randn(1, 10))
print(f'Output: {output}')</code></pre>

                        <h3>Optimizing for Mobile Deployment</h3>
                        <pre><code class="language-python">import torch
import torch.nn as nn
from torch.utils.mobile_optimizer import optimize_for_mobile

# Create and trace model
model = nn.Sequential(
    nn.Linear(10, 20),
    nn.ReLU(),
    nn.Linear(20, 5)
)
model.eval()

example = torch.randn(1, 10)
traced_model = torch.jit.trace(model, example)

# Optimize for mobile
mobile_model = optimize_for_mobile(traced_model)

# Save optimized model
mobile_model._save_for_lite_interpreter('model_mobile.ptl')
print('Model optimized and saved for mobile deployment')

# Model can now be loaded in iOS/Android apps</code></pre>

                        <div class="highlight-box">
                            <i class="fas fa-server"></i>
                            <strong>Production Deployment Options:</strong> For web services, use TorchServe (official PyTorch serving framework) or ONNX Runtime. For edge devices, use TorchScript with mobile optimization. For maximum performance, convert to ONNX and use TensorRT (NVIDIA GPUs).
                        </div>
                    </div>

                    <div id="best-practices" class="blog-content mt-5">
                        <h2><i class="fas fa-check-circle me-2 text-teal"></i>Best Practices & Common Pitfalls</h2>
                        
                        <div class="experiment-card">
                            <div class="card-meta mb-2">
                                <span class="badge bg-teal text-white">Essential Best Practices</span>
                            </div>
                            <div class="card-content">
                                <h4>Model Development</h4>
                                <ul>
                                    <li><strong>Start simple:</strong> Begin with a small model, ensure it overfits on a tiny dataset (proves implementation works), then scale up.</li>
                                    <li><strong>Normalize inputs:</strong> Always normalize/standardize input data (mean=0, std=1) for faster convergence.</li>
                                    <li><strong>Batch normalization:</strong> Add batch norm layers after linear/conv layers for more stable training.</li>
                                    <li><strong>Dropout:</strong> Use dropout (0.2-0.5) to prevent overfitting, especially in fully connected layers.</li>
                                </ul>

                                <h4>Training</h4>
                                <ul>
                                    <li><strong>Learning rate:</strong> Most important hyperparameter. Start with 0.001 for Adam, 0.01-0.1 for SGD. Use learning rate scheduling.</li>
                                    <li><strong>Gradient clipping:</strong> Prevent exploding gradients with <code>torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)</code></li>
                                    <li><strong>Early stopping:</strong> Stop training when validation loss stops improving (patience ~10 epochs).</li>
                                    <li><strong>Checkpointing:</strong> Save model checkpoints every N epochs to avoid losing progress.</li>
                                </ul>

                                <h4>Common Pitfalls</h4>
                                <ul>
                                    <li><strong>Forgetting .eval():</strong> Always set model to eval mode during validation/testing to disable dropout and batch norm training behavior.</li>
                                    <li><strong>Not zeroing gradients:</strong> Always call <code>optimizer.zero_grad()</code> before backward pass—gradients accumulate by default!</li>
                                    <li><strong>Device mismatch:</strong> Ensure model and data are on the same device (both CPU or both GPU).</li>
                                    <li><strong>Wrong loss function:</strong> Use CrossEntropyLoss for classification (includes softmax), MSELoss for regression.</li>
                                    <li><strong>Data leakage:</strong> Never include test data in training. Don't normalize train and test together—fit on train, transform test.</li>
                                </ul>

                                <h4>Debugging</h4>
                                <ul>
                                    <li><strong>Check shapes:</strong> Print tensor shapes frequently. Most bugs are shape mismatches.</li>
                                    <li><strong>Overfit small batch:</strong> Ensure model can overfit 1-2 batches (loss → 0). If not, there's a bug in implementation.</li>
                                    <li><strong>Gradient checks:</strong> Verify gradients are flowing: <code>print([p.grad.abs().mean() for p in model.parameters()])</code></li>
                                    <li><strong>Learning rate finder:</strong> Plot loss vs learning rate to find optimal LR range.</li>
                                </ul>

                                <h4>Performance Optimization</h4>
                                <ul>
                                    <li><strong>GPU utilization:</strong> Use larger batch sizes to maximize GPU usage. Monitor with <code>nvidia-smi</code>.</li>
                                    <li><strong>Mixed precision:</strong> Enable AMP for 2-3x speedup on modern GPUs (Volta, Turing, Ampere).</li>
                                    <li><strong>DataLoader workers:</strong> Use num_workers=4-8 for parallel data loading on multi-core CPUs.</li>
                                    <li><strong>Pin memory:</strong> Enable pin_memory=True in DataLoader when using GPU for faster transfers.</li>
                                </ul>
                            </div>
                            <div class="card-tags">
                                <span class="bias-tag">Best Practices</span>
                                <span class="bias-tag">Production Ready</span>
                                <span class="bias-tag">Debugging</span>
                            </div>
                        </div>

                        <div class="highlight-box mt-4">
                            <i class="fas fa-graduation-cap"></i>
                            <strong>Next Steps:</strong> You now have a solid foundation in PyTorch! Practice by implementing classic papers (ResNet, LSTM), participate in Kaggle competitions, or build your own projects. The PyTorch documentation and community forums are excellent resources for continued learning. Remember: the best way to learn deep learning is by doing—start building!
                        </div>
                    </div>
                    
                    <!-- Related Posts -->
                    <div class="related-posts">
                        <h3><i class="fas fa-book me-2"></i>Related Articles in This Series</h3>
                        <div class="related-post-item">
                            <h5 class="mb-2">TensorFlow Deep Learning: Complete Beginner's Guide to Building Neural Networks</h5>
                            <p class="text-muted small mb-2">Master TensorFlow 2 and Keras for deep learning. Learn neural network architectures, training workflows, and deployment techniques.</p>
                            <a href="tensorflow-deep-learning-guide.html" class="text-decoration-none">Read Article <i class="fas fa-arrow-right ms-1"></i></a>
                        </div>
                        <div class="related-post-item">
                            <h5 class="mb-2">Part 4: Machine Learning with Scikit-learn</h5>
                            <p class="text-muted small mb-2">Build and evaluate machine learning models using Scikit-learn. Learn classification, regression, clustering, and best practices for real-world projects.</p>
                            <a href="../12/python-data-science-machine-learning.html" class="text-decoration-none">Read Article <i class="fas fa-arrow-right ms-1"></i></a>
                        </div>
                        <div class="related-post-item">
                            <h5 class="mb-2">Part 1: NumPy Foundations for Data Science</h5>
                            <p class="text-muted small mb-2">Master NumPy arrays, vectorization, broadcasting, and linear algebra operations—the foundation of Python data science.</p>
                            <a href="../12/python-data-science-numpy-foundations.html" class="text-decoration-none">Read Article <i class="fas fa-arrow-right ms-1"></i></a>
                        </div>
                    </div>

            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer id="social-media" class="bg-dark text-light py-5">
        <div class="container py-5">
            <div class="row mb-4">
                <div class="col-lg-6 mb-4 mb-lg-0">
                    <h5 class="fw-bold mb-3">Let's Connect</h5>
                    <p class="text-light">
                        I'm always interested in sharing content about my interests on different topics. Read disclaimer and feel free to share further.
                    </p>
                </div>
                <div class="col-lg-6">
                    <h5 class="fw-bold mb-3">Follow Me</h5>
                    <div class="social-links d-flex gap-2 flex-wrap">
                        <a href="https://www.facebook.com/wasil.zafar/" target="_blank" class="social-icon" title="Facebook">
                            <i class="fab fa-facebook-f"></i>
                        </a>
                        <a href="https://twitter.com/wasilzafar" target="_blank" class="social-icon" title="Twitter">
                            <i class="fab fa-twitter"></i>
                        </a>
                        <a href="https://www.linkedin.com/in/wasilzafar" target="_blank" class="social-icon" title="LinkedIn">
                            <i class="fab fa-linkedin-in"></i>
                        </a>
                        <a href="https://www.youtube.com/@wasilzafar" target="_blank" class="social-icon" title="YouTube">
                            <i class="fab fa-youtube"></i>
                        </a>
                        <a href="https://www.instagram.com/itswzee/" target="_blank" class="social-icon" title="Instagram">
                            <i class="fab fa-instagram"></i>
                        </a>
                        <a href="https://in.pinterest.com/wasilz/" target="_blank" class="social-icon" title="Pinterest">
                            <i class="fab fa-pinterest-p"></i>
                        </a>
                        <a href="mailto:wasil.zafar@gmail.com" class="social-icon" title="Email">
                            <i class="fas fa-envelope"></i>
                        </a>
                    </div>
                </div>
            </div>

            <hr class="bg-secondary">

            <div class="row mt-4">
                <div class="col-md-6">
                    <p class="small mb-2">
                        <i class="fas fa-camera me-2"></i>Background photo by Max Andrey from <a href="https://www.pexels.com/" target="_blank" class="text-light">Pexels</a>
                    </p>
                    <p class="small">
                        <i class="fas fa-icons me-2"></i>Icons from <a href="https://www.flaticon.com/" target="_blank" class="text-light">Flaticon</a> &amp; <a href="https://fontawesome.com/" target="_blank" class="text-light">Font Awesome</a>
                    </p>
                    <p class="small mt-3">
                        <a href="/" class="text-light text-decoration-none">Home</a> | 
                        <a href="/disclaimer.html" class="text-light text-decoration-none">Disclaimer</a> | 
                        <a href="/privacy-policy.html" class="text-light text-decoration-none">Privacy Policy</a>
                    </p>
                </div>
                <div class="col-md-6 text-md-end">
                    <p class="small">
                        Updated by <strong>Wasil Zafar</strong> | <time>January 1, 2026</time>
                    </p>
                </div>
            </div>
        </div>
    </footer>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    
    <!-- Scroll-to-Top Button -->
    <button id="scrollToTop" class="scroll-to-top" title="Back to Top">
        <i class="fas fa-arrow-up"></i>
    </button>
    
    <!-- Cookie Consent JS -->
    <script src="../../../js/cookie-consent.js"></script>
    
    <!-- Main JS -->
    <script src="../../../js/main.js"></script>
    
    <!-- Prism.js for Syntax Highlighting -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/toolbar/prism-toolbar.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/copy-to-clipboard/prism-copy-to-clipboard.min.js"></script>

    <!-- Scroll-to-Top Script -->
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const scrollToTopBtn = document.getElementById('scrollToTop');
            
            // Show/hide button on scroll
            window.addEventListener('scroll', function() {
                if (window.scrollY > 300) {
                    scrollToTopBtn.classList.add('show');
                } else {
                    scrollToTopBtn.classList.remove('show');
                }
            });
            
            // Smooth scroll to top on click
            scrollToTopBtn.addEventListener('click', function() {
                window.scrollTo({ top: 0, behavior: 'smooth' });
            });
        });
    </script>

    <!-- Prism Theme Switcher -->
    <script>
        // Available themes with display names
        const themes = {
            'prism-theme': 'Tomorrow Night',
            'prism-default': 'Default',
            'prism-dark': 'Dark',
            'prism-twilight': 'Twilight',
            'prism-okaidia': 'Okaidia',
            'prism-solarizedlight': 'Solarized Light'
        };

        // Load saved theme from localStorage or use default
        const savedTheme = localStorage.getItem('prism-theme') || 'prism-theme';

        // Function to switch theme
        function switchTheme(themeId) {
            // Disable all themes
            Object.keys(themes).forEach(id => {
                const link = document.getElementById(id);
                if (link) {
                    link.disabled = true;
                }
            });
            
            // Enable selected theme
            const selectedLink = document.getElementById(themeId);
            if (selectedLink) {
                selectedLink.disabled = false;
                localStorage.setItem('prism-theme', themeId);
            }

            // Update all dropdowns on the page to match selected theme
            document.querySelectorAll('div.code-toolbar select').forEach(dropdown => {
                dropdown.value = themeId;
            });

            // Re-apply syntax highlighting with new theme
            setTimeout(() => {
                Prism.highlightAll();
            }, 10);
        }

        // Apply saved theme on page load
        document.addEventListener('DOMContentLoaded', function() {
            switchTheme(savedTheme);
        });

        // Add theme switcher to Prism toolbar
        Prism.plugins.toolbar.registerButton('theme-switcher', function(env) {
            const select = document.createElement('select');
            select.setAttribute('aria-label', 'Select code theme');
            select.className = 'prism-theme-selector';
            
            // Populate dropdown with themes
            Object.keys(themes).forEach(themeId => {
                const option = document.createElement('option');
                option.value = themeId;
                option.textContent = themes[themeId];
                if (themeId === savedTheme) {
                    option.selected = true;
                }
                select.appendChild(option);
            });
            
            // Handle theme change
            select.addEventListener('change', function(e) {
                switchTheme(e.target.value);
            });
            
            return select;
        });
    </script>
</body>
</html>